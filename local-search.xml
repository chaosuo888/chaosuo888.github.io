<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>资料合集</title>
    <link href="/2022/08/13/%E8%B5%84%E6%96%99%E5%90%88%E9%9B%86/"/>
    <url>/2022/08/13/%E8%B5%84%E6%96%99%E5%90%88%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>真诚而实事求是地</p><p>只收录了个人喜好觉得品味好的网站，</p><p>如果有其他好的建议也欢迎提出，非常感谢。</p><p>不定期更新</p><p><strong>基础素质要求（自勉用，参考NJUPA内的要求）</strong></p><p>提问的艺术</p><p><a href="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/main/README-zh_CN.md">https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/main/README-zh_CN.md</a></p><p>不像弱智一样提问</p><p><a href="https://github.com/tangx/Stop-Ask-Questions-The-Stupid-Ways/blob/master/README.md">https://github.com/tangx/Stop-Ask-Questions-The-Stupid-Ways/blob/master/README.md</a></p><p><strong>部分内容出自以下参考网站，也欢迎关注他们</strong></p><p>PPRP：</p><p><a href="https://www.cnblogs.com/pprp/p/8880493.html">https://www.cnblogs.com/pprp/p/8880493.html</a></p><p><strong>如需转载请注释原出处即可，谢谢</strong></p><h2 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h2><p>机器学习相关数学基础</p><p><a href="https://www.bilibili.com/video/BV1iW411T781?p=34&share_medium=iphone&share_plat=ios&share_session_id=918760D9-B272-4504-8DD6-82E44AFA8672&share_source=WEIXIN&share_tag=s_i&timestamp=1641652920&unique_k=aGspGLd">直观理解机器学习的数学过程</a></p><p><a href="https://www.bilibili.com/video/BV1xk4y1B7RQ?p=1&share_medium=iphone&share_plat=ios&share_session_id=1F101D5C-2880-4C53-A556-3D2777F6AFC8&share_source=WEIXIN&share_tag=s_i&timestamp=1641653070&unique_k=GcJNM2u">矩阵求导入门</a> 可以配合文档里NTU的矩阵求导食用或者数学参考那本书。</p><p><a href="https://www.bilibili.com/video/BV1o5411p7H2?p=8&share_medium=iphone&share_plat=ios&share_session_id=3AD6E589-C577-4D7A-88C6-6A3FAB1E41F1&share_source=WEIXIN&share_tag=s_i&timestamp=1641653147&unique_k=abvhCWL">李航统计学习基础第一章补数学基础</a> 只需要第一张 补基础，其他有问题再找</p><p><a href="https://www.deeplearningbook.org/">Deep Learning An MIT Press book</a>参考第一章即可，<a href="https://github.com/exacity/deeplearningbook-chinese/releases">中文版在这</a>或者直接下载附件中dlbook_cn_v0.5-beta。</p><h3 id="概率论与数理统计"><a href="#概率论与数理统计" class="headerlink" title="概率论与数理统计"></a>概率论与数理统计</h3><p>陈希孺 概率论与数理统计基础 <a href="https://www.bilibili.com/video/BV12k4y1m78w">参考课程视频地址</a></p><p>【概率统计课程学习总结】1. 台大概率与台湾交通大学统计课 - 奶油煎蛋红烧肉的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/86071634">https://zhuanlan.zhihu.com/p/86071634</a></p><p><a href="https://www.bilibili.com/video/BV1nK4y1U7QM">台湾大学 - 頑想學概率：機率一 (Probability (1))</a></p><p><a href="https://www.bilibili.com/video/BV1CX4y1V7oN?p=23">台湾大学 - 頑想學概率：機率二 (Probability (2))</a></p><p><a href="https://ocw.nctu.edu.tw/course_detail-v.php?bgid=1&gid=1&nid=270">台湾交通大学 - 統計學 Statistics</a></p><p><a href="https://ocw.nctu.edu.tw/course_detail-v.php?bgid=1&gid=4&nid=536">台湾交通大学 - 高等統計學 Advanced Statistics</a></p><p>其他</p><p>线代启示录（一位掌握了线代灵魂的老师）</p><p><a href="https://ccjou.wordpress.com/">https://ccjou.wordpress.com/</a></p><p>immersive linear algebra 线性代数可视化</p><p><a href="http://immersivemath.com/ila/index.html">http://immersivemath.com/ila/index.html</a></p><h2 id="CS大类"><a href="#CS大类" class="headerlink" title="CS大类"></a>CS大类</h2><p>CS自学指南【必看】</p><p><a href="https://csdiy.wiki/">https://csdiy.wiki/</a></p><p>【北美名校CS课程集锦】2.加州大学伯克利分校CS课程全集 - 文兄的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/102083014">https://zhuanlan.zhihu.com/p/102083014</a></p><p>GDB、VIM、GIT、SHELL等常见linux操作基础（慢慢来，在使用中学</p><p>The Missing Semester of Your CS Education 中文版（强烈推荐）</p><p>  官方中文站点：<a href="https://missing-semester-cn.github.io/">https://missing-semester-cn.github.io/</a></p><p>  B站：<a href="https://www.bilibili.com/video/BV1x7411H7wa?t=2829">https://www.bilibili.com/video/BV1x7411H7wa?t=2829</a></p><p>南大PA教程最下面的一些简单入门和材料</p><p><a href="https://nju-projectn.github.io/ics-pa-gitbook/ics2021/index.html">https://nju-projectn.github.io/ics-pa-gitbook/ics2021/index.html</a></p><p>不知道变量怎么命名就可以看看：</p><p><a href="https://unbug.github.io/codelf/">https://unbug.github.io/codelf/</a></p><p>有关linux的基础讲解，有配图和自己的理解，推荐一读。</p><p><a href="https://segmentfault.com/u/public0821">https://segmentfault.com/u/public0821</a></p><p>有关win家的镜像源以及VS等的纯净安装文件，以及各种网络工程师能用到的软件程序安装包</p><p><a href="https://msdn.itellyou.cn/">https://msdn.itellyou.cn/</a></p><p>一个对cpu和网络了解都非常深入的工程师</p><p><a href="https://plantegg.github.io/">https://plantegg.github.io/</a></p><p>其中最好的一类文章（有关cpu的讲解）<a href="https://plantegg.github.io/2021/06/01/CPU%E7%9A%84%E5%88%B6%E9%80%A0%E5%92%8C%E6%A6%82%E5%BF%B5/">https://plantegg.github.io/2021/06/01/CPU的制造和概念/</a></p><p>正则表达式可视化浏览</p><p><a href="https://regexr.com/">https://regexr.com/</a></p><h3 id="操作系统学习"><a href="#操作系统学习" class="headerlink" title="操作系统学习"></a>操作系统学习</h3><p>南京大学计算机基础（袁春风）CSAPP的青春版，但比csapp好懂得多（强烈不建议一开始就读csapp</p><p>赶时间可以直接看配套书。</p><p><a href="https://www.icourse163.org/course/nju-1001625001#/info">https://www.icourse163.org/course/nju-1001625001#/info</a></p><p>前置：南京大学计算机基础实验（做了能让你真的变强）</p><p>  <a href="https://nju-projectn.github.io/ics-pa-gitbook/ics2021/index.html">https://nju-projectn.github.io/ics-pa-gitbook/ics2021/index.html</a></p><p>2022 南京大学拔尖计划《操作系统：设计与实现》</p><p>  课程主页：<a href="http://jyywiki.cn/OS/2022/">http://jyywiki.cn/OS/2022/</a> (slides、示例代码)</p><p>  视频地址： <a href="https://www.bilibili.com/video/BV1Cm4y1d7Ur/">https://www.bilibili.com/video/BV1Cm4y1d7Ur/</a> </p><p>操作系统（哈工大李治军老师）课件可在下方链接获取。</p><p>  慕课网: <a href="http://www.feemic.cn/mooc/icourse163/1002692015#%E3%80%82">http://www.feemic.cn/mooc/icourse163/1002692015#。</a></p><p>  百度云链接：<a href="https://pan.baidu.com/s/1h2aEk6A_DGpXkZvRtNmeUw">https://pan.baidu.com/s/1h2aEk6A_DGpXkZvRtNmeUw</a> 提取码：qoll</p><p>  配套实验课：<a href="https://www.shiyanlou.com/courses/115">https://www.shiyanlou.com/courses/115</a></p><h3 id="计算机网络学习"><a href="#计算机网络学习" class="headerlink" title="计算机网络学习"></a>计算机网络学习</h3><p>待补充</p><h3 id="数据结构与算法"><a href="#数据结构与算法" class="headerlink" title="数据结构与算法"></a>数据结构与算法</h3><p>程序员如何准备面试中的算法</p><p><a href="https://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/00.01.html">https://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/00.01.html</a></p><h3 id="深度学习相关"><a href="#深度学习相关" class="headerlink" title="深度学习相关"></a>深度学习相关</h3><h4 id="有关理论基础（但我还是建议直接看李宏毅）"><a href="#有关理论基础（但我还是建议直接看李宏毅）" class="headerlink" title="有关理论基础（但我还是建议直接看李宏毅）"></a>有关理论基础（但我还是建议直接看李宏毅）</h4><p><strong>周志华</strong></p><p>南瓜书主页</p><p><a href="https://datawhalechina.github.io/pumpkin-book/#/">https://datawhalechina.github.io/pumpkin-book/#/</a></p><p>周志华《机器学习》手推笔记 by Sophia-11</p><p> <a href="https://github.com/Sophia-11/Machine-Learning-Notes">https://github.com/Sophia-11/Machine-Learning-Notes</a></p><p>周志华《机器学习》笔记（主要是文本） by yv.l1.pnn</p><p> <a href="https://zhuanlan.zhihu.com/p/134089340">https://zhuanlan.zhihu.com/p/134089340</a></p><p><strong>李宏毅相关课程</strong></p><p>0. 李宏毅老师的课程主页：</p><p><a href="https://speech.ee.ntu.edu.tw/~hylee/index.php">https://speech.ee.ntu.edu.tw/~hylee&#x2F;index.php</a> 这是李老师的个人主页，可以找到每年ML的课程主页，然后获取作业代码和Kaggle链接  </p><p>1.李宏毅《机器学习》：  </p><p><a href="https://www.bilibili.com/video/BV1Ht411g7Ef">https://www.bilibili.com/video/BV1Ht411g7Ef</a>  </p><p>2.李宏毅机器学习笔记：  </p><p><a href="https://gitee.com/datawhalechina/leeml-notes">https://gitee.com/datawhalechina/leeml-notes</a>  </p><p>3.李宏毅《机器学习&#x2F;深度学习》2021课程：</p><p><a href="https://www.bilibili.com/video/BV1JA411c7VT?p=34">https://www.bilibili.com/video/BV1JA411c7VT?p=34</a>  </p><p>4.李宏毅2022课程：  </p><p><a href="https://www.bilibili.com/video/BV1JK4y1D7Wb/">https://www.bilibili.com/video/BV1JK4y1D7Wb/</a></p><p>李沐动手学深度学习（适合速成，打基础建议李宏毅）</p><p><a href="https://zh.d2l.ai/index.html">https://zh.d2l.ai/index.html</a></p><p>这个网站给出了不同模型的排名及其开源代码</p><p><a href="https://paperswithcode.com/">https://paperswithcode.com/</a></p><h4 id="开源库-x2F-项目"><a href="#开源库-x2F-项目" class="headerlink" title="开源库&#x2F;项目"></a>开源库&#x2F;项目</h4><p>OpenMMLab</p><p><a href="https://openmmlab.com/">https://openmmlab.com/</a></p><p><a href="https://github.com/open-mmlab">https://github.com/open-mmlab</a></p><p>paddle</p><p><a href="https://github.com/PaddlePaddle">https://github.com/PaddlePaddle</a></p><p>Deep Learning Paper Implementations</p><p><a href="https://github.com/labmlai/annotated_deep_learning_paper_implementations">https://github.com/labmlai/annotated_deep_learning_paper_implementations</a></p><p>Awesome Machine Learning</p><p><a href="https://github.com/josephmisiti/awesome-machine-learning">https://github.com/josephmisiti/awesome-machine-learning</a></p><p>Awesome Deep Learning</p><p><a href="https://github.com/ChristosChristofidis/awesome-deep-learning">https://github.com/ChristosChristofidis/awesome-deep-learning</a></p><p>【杂谈】GitHub上的机器学习&#x2F;深度学习综述项目合集 - 言有三的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/60245227">https://zhuanlan.zhihu.com/p/60245227</a></p><h4 id="手写深度学习项目"><a href="#手写深度学习项目" class="headerlink" title="手写深度学习项目"></a>手写深度学习项目</h4><p>小土堆 pytorch学习</p><p><a href="https://space.bilibili.com/203989554?spm_id_from=333.337.search-card.all.click">https://space.bilibili.com/203989554</a></p><p>霹雳吧啦Wz 图像分类篇章 以及目标检测</p><p><a href="https://space.bilibili.com/18161609/channel/collectiondetail?sid=48290">https://space.bilibili.com/18161609/channel/collectiondetail?sid=48290</a></p><p>手写YOLO系列和fast rcnn系列：</p><p><a href="https://www.bilibili.com/video/BV1JR4y1g77H?spm_id_from=333.999.0.0&vd_source=a6509cab8ccb8b81d6a70af693cc008f">https://www.bilibili.com/video/BV1JR4y1g77H</a></p><p><a href="https://space.bilibili.com/472467171">https://space.bilibili.com/472467171</a></p><h4 id="深度学习的杂物间"><a href="#深度学习的杂物间" class="headerlink" title="深度学习的杂物间"></a>深度学习的杂物间</h4><p>孪生神经网络的相关实现：</p><p><a href="https://blog.csdn.net/weixin_44791964/article/details/107406072">https://blog.csdn.net/weixin_44791964&#x2F;article&#x2F;details&#x2F;107406072</a></p><p><a href="https://blog.csdn.net/lx_ros/article/details/124439120">https://blog.csdn.net/lx_ros&#x2F;article&#x2F;details&#x2F;124439120</a></p><h2 id="C"><a href="#C" class="headerlink" title="C"></a>C</h2><p>翁恺的相关视频(入门和进阶)</p><p><a href="https://www.icourse163.org/u/wengkai?userId=318013">https://www.icourse163.org/u/wengkai?userId=318013</a></p><p>100个GDB小技巧：</p><p><a href="https://wizardforcel.gitbooks.io/100-gdb-tips/content/part1.html">https://wizardforcel.gitbooks.io/100-gdb-tips/content/part1.html</a></p><p>标准库收录网站</p><p><a href="https://www.cplusplus.com/reference/">https://www.cplusplus.com/reference/</a></p><h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p>anaconda与Jupyter notebook安装教程</p><p><a href="https://zhuanlan.zhihu.com/p/37093476">https://zhuanlan.zhihu.com/p/37093476</a></p><p>国内的anaconda镜像下载</p><p><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a></p><p>anaconda更新与下载包的镜像源更换</p><p><a href="https://zhuanlan.zhihu.com/p/35985834">https://zhuanlan.zhihu.com/p/35985834</a></p><p>awesome项目（包含了绝大部分的python相关资源）</p><p><a href="https://github.com/vinta/awesome-python">https://github.com/vinta/awesome-python</a></p><p><a href="http://jobbole.github.io/awesome-python-cn/">http://jobbole.github.io/awesome-python-cn/</a></p><p>Python Cookbook 3rd Edition</p><p><a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/index.html">https://python3-cookbook.readthedocs.io/zh_CN&#x2F;latest&#x2F;index.html</a></p><p>Python并行编程</p><p><a href="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/index.html">https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN&#x2F;latest&#x2F;index.html</a></p><p>pandas教程</p><p><a href="https://pandas.pydata.org/docs/getting_started/install.html">https://pandas.pydata.org/docs/getting_started&#x2F;install.html</a></p><p>或者可以看看datawhale的教程</p><p>Scipy Lecture Notes&#x2F;&#x2F;Advanced Python Constructs&#x2F;&#x2F;Advanced NumP</p><p><a href="http://scipy-lectures.org/index.html">http://scipy-lectures.org/index.html</a></p><h2 id="C-1"><a href="#C-1" class="headerlink" title="C++"></a>C++</h2><p>c++入门学习（建议直接看书加上翁恺或侯捷）</p><p>可以b站搜索翁恺的c++</p><p>awesome项目（包含了绝大部分的c++相关资源）</p><p><a href="https://github.com/fffaraz/awesome-cpp">https://github.com/fffaraz/awesome-cpp</a></p><p><a href="http://jobbole.github.io/awesome-python-cn/">http://jobbole.github.io/awesome-python-cn/</a></p><p>c++并发编程</p><p><a href="https://paul.pub/cpp-concurrency/">https://paul.pub/cpp-concurrency/</a></p><p>双笙子佯谬    图形学大佬，Zeno和Taichi Blend的作者</p><p><a href="https://space.bilibili.com/263032155">https://space.bilibili.com/263032155</a></p><h3 id="C-的杂物间"><a href="#C-的杂物间" class="headerlink" title="C++的杂物间"></a>C++的杂物间</h3><p>DJI thermal analysis tool  相关教程（日文</p><p><a href="https://qiita.com/tutu/items/b5cf2b39dd30786d9064">https://qiita.com/tutu/items/b5cf2b39dd30786d9064</a></p><h2 id="学术论文"><a href="#学术论文" class="headerlink" title="学术论文"></a>学术论文</h2><p>查询接受率的网站:</p><p><a href="https://www.openresearch.org/wiki/Main_Page">https://www.openresearch.org/wiki/Main_Page</a></p><p>LaTeX 图片转代码</p><p><a href="https://mathf.itewqq.cn/">点这里mathF</a></p><p><a href="https://web.baimiaoapp.com/image-to-latex">https://web.baimiaoapp.com/image-to-latex</a></p><p>论文翻译</p><p><a href="https://tongtianta.site/">https://tongtianta.site/</a></p><h2 id="其他日常使用网站"><a href="#其他日常使用网站" class="headerlink" title="其他日常使用网站"></a>其他日常使用网站</h2><p>有关思维导图的代码（类似markdown）生成：</p><p><a href="https://xzmind.xuanzi.ltd/apps.html">https://xzmind.xuanzi.ltd/apps.html</a></p><p>流程图绘制：</p><p><a href="https://app.diagrams.net/">https://app.diagrams.net/</a></p><p>快速文件传输（随意分享给人不用网盘）</p><p><a href="https://www.wenshushu.cn/">https://www.wenshushu.cn/</a></p><h2 id="心理健康建设"><a href="#心理健康建设" class="headerlink" title="心理健康建设"></a>心理健康建设</h2><p>如何在工作中学习（好的方法论）</p><p><a href="https://plantegg.github.io/2018/05/24/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%AD%A6%E4%B9%A0V1.1/">https://plantegg.github.io/2018/05/24/如何在工作中学习V1.1/</a></p><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><h3 id="英文语法在线修改"><a href="#英文语法在线修改" class="headerlink" title="英文语法在线修改"></a>英文语法在线修改</h3><p><a href="https://www.grammarly.com/">https://www.grammarly.com/</a></p><p><a href="https://www.nounplus.net/grammarcheck/">https://www.nounplus.net/grammarcheck/</a></p><p><a href="https://virtualwritingtutor.com/">https://virtualwritingtutor.com/</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>资料工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习面试</title>
    <link href="/2022/07/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95/"/>
    <url>/2022/07/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>机器学习问题</title>
    <link href="/2022/07/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98/"/>
    <url>/2022/07/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p><strong>特征工程</strong><br><strong>特征工程</strong>，顾名思义，是对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。从本质上来讲，特征工程是一个表示和展现数 据的过程。<strong>在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更 高效的特征以刻画求解的问题与预测模型之间的关系。</strong></p><p><strong>特征归一化</strong><br><strong>为什么需要对数值类型的特征做归一化？</strong><br><strong>对数值类型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内。</strong><br>最常用的方法主要有以下两种。</p><p><strong>图像数据不足时的处理方法?</strong><br>一个模型所能提供的信息一般来源于两个方面，</p><ol><li>一是<strong>训练数据中蕴含的信息</strong>；</li><li>二是在模型的形成过程中（包括构造、学习、推理等），<strong>人们提供的先验信息</strong>。当训练数据不足时，说明模型从原始数据中获取的信息比较少，这种情况下 要想保证模型的效果，就需要更多先验信息。<strong>先验信息可以作用在模型上</strong>，例如让模型采用特定的内在结构、条件假设或添加其他一些约束条件；先验信息也<strong>可以直接施加在数据集上</strong>，即根据特定的先验假设去调整、变换或扩展训练数据， 让其展现出更多的、更有用的信息，以利于后续模型的训练和学习。</li></ol><p>具体到图像分类任务上，<strong>训练数据不足带来的问题主要表现在过拟合方面</strong>， 即模型在训练样本上的效果可能不错，但在测试集上的泛化效果不佳。根据上述讨论，对应的处理方法大致也可以分两类，</p><ol><li>一是<strong>基于模型的方法</strong>，主要是采用降低过拟合风险的措施，包括<strong>简化模型</strong>（如将非线性模型简化为线性模型）、<strong>添加约束项以缩小假设空间</strong>（如L1&#x2F;L2正则项）、<strong>集成学习</strong>、<strong>Dropout超参数等</strong>；</li><li>二是<strong>基于数据的方法</strong>，主要通过<strong>数据扩充</strong>（Data Augmentation），即根据一些先验知识，在保持特定信息的前提下，对原始数据进行适当变换以达到扩充数据集的效果。具体到图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的 每幅图像进行以下变换。</li></ol><ul><li>（1）一定程度内的<strong>随机旋转、平移、缩放、裁剪、填充、左右翻转</strong>等，这些变换对应着同一个目标在不同角度的观察结果。 </li><li>（2）对图像中的像素添加<strong>噪声扰动</strong>，比如椒盐噪声、高斯白噪声等。 </li><li>（3）<strong>颜色变换</strong>。例如，在图像的RGB颜色空间上进行主成分分析，得到3个主成分的特征向量p1,p2,p3及其对应的特征值 λ1,λ2,λ3，然后在每个像素的RGB值上 添加增量[p1,p2,p3]•[α1λ1,α2λ2,α3λ3]T，其中 α1,α2,α3是均值为0、方差较小的高斯分布随 机数。</li><li>（4）改变图像的<strong>亮度、清晰度、对比度、锐度</strong>等。</li><li>(5)使用生成模型也可以合成一些新样本，例如当今非常流行的<strong>生成式对抗网络模型</strong>。</li><li>(6)其他模型或数据来<strong>进行迁移学习</strong>在深度学习中也十分常见。。例如，对于大部分图像分类任务，并不需要从头开始训练模型，而是借用一个在大规模数据集上预训练好的通用模型，并在针对目标任务的小数据集上进行微调（fine-tune），这种微调操作就可以看成是一种简单的迁移学习。</li></ul><p><strong>准确率的局限性</strong><br>$$acc &#x3D; n_correct&#x2F;n_total$$<br>其中n_correct为被正确分类的样本个数，n_total为总样本的个数。<br>当<strong>不同类别的样本比例非常不均衡</strong>时，占比大的类别往往成为影响准确率的最主要因素。<br><strong>解决方式</strong>：可以使用更为有效的平均准确率（每个类别下的样本准确率的算术平均）作为模型评估的指标。<br><strong>标准答案</strong>其实也不限于指标的选择，即使评估指标选择对了，<strong>仍会存在模型过拟合或欠拟合、测试集和训练集划分不合理、线下评估与线上测试的样本分布存在差异等一系列问题</strong>，但评估指标的选择是最容易被发现，也是最可能影响评估结果的因素。</p><p><strong>精确率和召回率</strong><br>精确率是指<strong>分类正确的正样本个数</strong>占<strong>分类器判定为正样本的样本个数</strong>的比例。<br>召回率是指<strong>分类正确的正样本个数</strong>占<strong>真正的正样本个数</strong>的比例。</p><p>Precision值和Recall值<strong>是既矛盾又统一的两个指标</strong>，为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致Recall值降低。</p><p><strong>P-R曲线的横轴是召回率，纵轴是精确率。</strong>对于一个排序模型来说，其P-R曲线上的一个点代表着，在某一阈值下，模型将大于该阈值的结果判定为正样本， 小于该阈值的结果判定为负样本，此时返回结果对应的召回率和精确率。<strong>整条P-R 曲线是通过将阈值从高到低移动而生成的。</strong>图2.1是P-R曲线样例图，其中实线代表 模型A的P-R曲线，虚线代表模型B的P-R曲线。原点附近代表当阈值最大时模型的 精确率和召回率。</p><p><strong>平方根误差的“意外”。</strong><br>一般情况下，RMSE能够很好地反映回归模型预测值与真实值的偏离程度。但在实际问题中，<strong>如果存在个别偏离程度非常大的离群点（Outlier）时，即使离群点数量非常少，也会让RMSE指标变得很差。</strong></p><p><strong>什么是ROC曲线？</strong><br>ROC曲线是Receiver Operating Characteristic Curve的简称，中文名为“<strong>受试者工作特征曲线</strong>”。ROC曲线源于军事领域，而后在医学领域应用甚广，“受试者工作特征曲线”这一名称也正是来自于医学领域。<br>ROC曲线的横坐标为<strong>假阳性率</strong>（False Positive Rate，FPR）；纵坐标为<strong>真阳性率</strong>（True Positive Rate，TPR）。<br><strong>TP是P个正样本中被分类器预测为正样本的个数</strong>，<strong>FP是N个负样本中被分类器预测为正样本的个数</strong>。<br>只看定义确实有点绕，为了更直观地说明这个问题，我们举一个医院诊断病 人的例子。假设有10位疑似癌症患者，其中有3位很不幸确实患了癌症（P&#x3D;3）， 另外7位不是癌症患者（N&#x3D;7）。医院对这10位疑似患者做了诊断，诊断出3位癌症患者，其中有2位确实是真正的患者（TP&#x3D;2）。那么真阳性率TPR&#x3D;TP&#x2F;P&#x3D;2&#x2F;3。对 于7位非癌症患者来说，有一位很不幸被误诊为癌症患者（FP&#x3D;1），那么假阳性率 FPR&#x3D;FP&#x2F;N&#x3D;1&#x2F;7。对于“该医院”这个分类器来说，这组分类结果就对应ROC曲线上的一个点（1&#x2F;7，2&#x2F;3）。</p><p><strong>如何绘制ROC曲线？</strong>(两种方法的绘制)<br>通过动态地调整截断点，从最高的得分开始（实际上是从正无穷开始，对应着ROC曲线的零点），逐渐调整到最低得分，每一个截断点都会对应一个FPR和 TPR，在ROC图上绘制出每个截断点对应的位置，再连接所有点就得到最终的ROC曲线。</p><p>其实，还有一种更直观地绘制ROC曲线的方法。首先，根据样本标签统计出 正负样本的数量，假设正样本数量为P，负样本数量为N；接下来，把横轴的刻度间隔设置为1&#x2F;N，纵轴的刻度间隔设置为1&#x2F;P；再根据模型输出的预测概率对样本进 行排序（从高到低）；依次遍历样本，同时从零点开始绘制ROC曲线，每遇到一 个正样本就沿纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿横轴方向绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停在（1,1）这个 点，整个ROC曲线绘制完成。</p><p><strong>ROC曲线相比P-R曲线有什么特点？</strong><br>相比 P-R曲线，ROC曲线有一个特点，<strong>当正负样本的分布发生变化时，ROC曲线的形状能够基本保持不变，而P-R曲线的形状一般会发生较剧烈的变化。</strong><br>可以看出，P-R曲线发生了明显的变化，而ROC曲线形状基本不变。<strong>这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能</strong>。</p><p><strong>余弦距离的应用</strong><br>在机器学习问题中，通常将特征表示为向量的形式，所以在分析两个特征向量之间的相似性时，常使用余弦相似度来表示。<strong>余弦相似度的取值范围是[−1,1]， 相同的两个向量之间的相似度为1。</strong>如果希望得到类似于距离的表示，<strong>将1减去余 弦相似度即为余弦距离。因此，余弦距离的取值范围为[0,2]，相同的两个向量余弦距离为0。</strong></p><p><strong>结合你的学习和研究经历，探讨为什么在一些场景中要使用余弦相似度而不是欧氏距离？</strong><br>对于两个向量A和B，其余弦相似度定义为<img src="/2022/07/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98/1.png">，即两个向量夹角的余弦，关注的是向量之间的角度关系，并不关心它们的绝对大小，其取值 范围是[−1,1]。<br>余弦相似度在高维情况下依然保持“相同时为1，正交时为0，相反时为−1”的性质，而欧氏距离的数值则受维度的影响，范围不固定，并且含义也比较模糊。<br><strong>总体来说，欧氏距离体现数值上的绝对差异，而余弦距离体现方向上的相对差异。</strong></p><p><strong>超参数有哪些调优方法？</strong><br>为了进行超参数调优，我们一般会采用<strong>网格搜索、随机搜索、贝叶斯优化</strong>等算法。在具体介绍算法之前，需要明确超参数搜索算法一般包括哪几个要素。</p><ol><li>目标函数，即算法需要最大化&#x2F;最小化的目标；</li><li>搜索范围，一般通过上限和 下限来确定；</li><li>算法的其他参数，如搜索步长。</li></ol><p>网格搜索可能是最简单、应用最广泛的超参数搜索算法，它通过查找搜索范 围内的所有的点来确定最优值。如果采用较大的搜索范围以及较小的步长，网格 搜索有很大概率找到全局最优值。然而，这种搜索方案十分消耗计算资源和时间，特别是需要调优的超参数比较多的时候。因此，<strong>在实际应用中，网格搜索法 一般会先使用较广的搜索范围和较大的步长，来寻找全局最优值可能的位置；然 后会逐渐缩小搜索范围和步长，来寻找更精确的最优值。这种操作方案可以降低 所需的时间和计算量，但由于目标函数一般是非凸的，所以很可能会错过全局最 优值。</strong></p><p>随机搜索的思想与网格搜索比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点。它的理论依据是，如果样本点集足够大，那么通过随机采样也能大概率地找到全局最优值，或其近似值。随机搜索一 般会比网格搜索要快一些，但是和网格搜索的快速版一样，它的结果也是没法保证的。</p><p>贝叶斯优化算法在寻找最优最值参数时，采用了与网格搜索、随机搜索完全 不同的方法。网格搜索和随机搜索在测试一个新点时，会忽略前一个点的信息； 而贝叶斯优化算法则充分利用了之前的信息。贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。具体来说，它学习目标函数形状的方法是，首<strong>先根据先验分布，假设一个搜集函数；然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布；最后，算法测试由后验分布给出的全局最值最可能出现的位置的点。对于贝叶斯优 化算法，有一个需要注意的地方，一旦找到了一个局部最优值，它会在该区域不断采样，所以很容易陷入局部最优值。</strong>为了弥补这个缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，“探索”就是在还未取样的区域获取采样点； 而“利用”则是根据后验分布在最可能出现全局最值的区域进行采样。</p><p><strong>过拟合与欠拟合</strong><br><strong>在模型评估过程中，过拟合和欠拟合具体是指什么现象？</strong><br><strong>过拟合</strong>是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是模型在训练集上的表现很好，但在测试集和新数据上的表现较差。<br><strong>欠拟合</strong>指的是模型在训练和预测时表现都不好的情况。<br>模型过于复杂，把噪声数据的特征也学习到模型中，导致模型泛化能力下降，在后期应用过程中很容易输出错误的预测结果。</p><p><strong>能否说出几种降低过拟合和欠拟合风险的方法？</strong><br>（1）<strong>从数据入手，获得更多的训练数据。使用更多的训练数据是解决过拟合问题最有效的手段</strong>，因为更多的样本能够让模型学习到更多更有效的特征，减小噪声的影响。当然，直接增加实验数据一般是很困难的，但是可以通过一定的规则来扩充训练数据。比如，在图像分类的问题上，可以通过图像的平移、旋转、 缩放等方式扩充数据；更进一步地，可以使用生成式对抗网络来合成大量的新训练数据。<br>（2）<strong>降低模型复杂度</strong>。在数据较少时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。例如，在神经网络模型中减少网络层数、神经元个数等；在决策树模型中降低树的深度、进行剪枝等。<br>（3）<strong>正则化方法</strong>。给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。以L2正则化为例：<br>（4）<strong>集成学习方法</strong>。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险，如Bagging方法。</p><p><strong>降低“欠拟合”风险的方法</strong><br>（1）<strong>添加新特征</strong>。当特征不足或者现有特征与样本标签的相关性不强时，模型容易出现欠拟合。通过挖掘“上下文特征”“ID类特征”“组合特征”等新的特征，往往能够取得更好的效果。在深度学习潮流中，有很多模型可以帮助完成特征工程，如因子分解机、梯度提升决策树、Deep-crossing等都可以成为丰富特征的方法。<br>（2）<strong>增加模型复杂度</strong>。简单模型的学习能力较差，通过增加模型的复杂度可 以使模型拥有更强的拟合能力。例如，在线性模型中添加高次项，在神经网络模型中增加网络层数或神经元个数等。<br>（3）<strong>减小正则化系数</strong>。正则化是用来防止过拟合的，但当模型出现欠拟合现象时，则需要有针对性地减小正则化系数。</p>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习</title>
    <link href="/2022/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2022/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="逻辑回归（LR）"><a href="#逻辑回归（LR）" class="headerlink" title="逻辑回归（LR）"></a>逻辑回归（LR）</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p><a href="https://en.wikipedia.org/wiki/Logistic_regression">逻辑回归（Logistic Regression，LR）</a>也称为”对数几率回归”，又称为”逻辑斯谛”回归。</p><p><strong>知识点提炼</strong></p><ul><li><strong>分类</strong>，经典的二分类算法！</li><li>逻辑回归就是这样的一个过程：面对一个回归或者分类问题，建立代价函数，然后通过优化方法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。</li><li>Logistic 回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别）</li><li>回归模型中，y 是一个定性变量，比如 y &#x3D; 0 或 1，logistic 方法主要应用于研究某些事件发生的概率。</li><li>逻辑回归的本质：极大似然估计</li><li>逻辑回归的激活函数：Sigmoid</li><li>逻辑回归的代价函数：交叉熵</li></ul><p><strong>逻辑回归的优缺点</strong></p><p>优点： </p><p>1）速度快，适合二分类问题 </p><p>2）简单易于理解，直接看到各个特征的权重 </p><p>3）能容易地更新模型吸收新的数据 </p><p>缺点： </p><p>对数据和场景的适应能力有局限性，不如决策树算法适应性那么强</p><p>**逻辑回归中最核心的概念是 <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid 函数</a>**，Sigmoid函数可以看成逻辑回归的激活函数。</p><p>下图是逻辑回归网络：</p><p><img src="/2022/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/DLIB-0001.png" alt="Logistic Regression.png"></p><p>对数几率函数（Sigmoid）：$y &#x3D; \sigma (z) &#x3D; \frac{1}{1+e^{-z}}$</p><p><img src="/2022/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/DLIB-0002.png"></p><p>通过对数几率函数的作用，我们可以将输出的值限制在区间[0，1]上，p(x) 则可以用来表示概率 p(y&#x3D;1|x)，即当一个x发生时，y被分到1那一组的概率。可是，等等，我们上面说 y 只有两种取值，但是这里却出现了一个区间[0, 1]，这是什么鬼？？其实在真实情况下，我们最终得到的y的值是在 [0, 1] 这个区间上的一个数，然后我们可以选择一个阈值，通常是 0.5，当 y &gt; 0.5 时，就将这个 x 归到 1 这一类，如果 y&lt; 0.5 就将 x 归到 0 这一类。但是阈值是可以调整的，比如说一个比较保守的人，可能将阈值设为 0.9，也就是说有超过90%的把握，才相信这个x属于 1这一类。了解一个算法，最好的办法就是自己从头实现一次。下面是逻辑回归的具体实现。</p><p><strong>Regression 常规步骤</strong></p><ol><li>寻找h函数（即预测函数）</li><li>构造J函数（损失函数）</li><li>想办法（迭代）使得J函数最小并求得回归参数（θ）</li></ol><p>函数h(x)的值有特殊的含义，它表示结果取1的概率，于是可以看成类1的后验估计。因此对于输入x分类结果为类别1和类别0的概率分别为： </p><p>P(y&#x3D;1│x;θ)&#x3D;hθ (x) </p><p>P(y&#x3D;0│x;θ)&#x3D;1-hθ (x)</p><p><strong>代价函数</strong></p><p><strong>逻辑回归一般使用交叉熵作为代价函数</strong>。关于<a href="https://en.wikipedia.org/wiki/Loss_function">代价函数</a>的具体细节，请参考<a href="http://www.cnblogs.com/Belter/p/6653773.html">代价函数</a>。</p><p>交叉熵是对「出乎意料」（译者注：原文使用suprise）的度量。神经元的目标是去计算函数 y, 且 y &#x3D; y(x)。但是我们让它取而代之计算函数 a, 且 a &#x3D; a(x) 。假设我们把 a 当作 y 等于 1 的概率，1−a 是 y 等于 0 的概率。那么，交叉熵衡量的是我们在知道 y 的真实值时的平均「出乎意料」程度。当输出是我们期望的值，我们的「出乎意料」程度比较低；当输出不是我们期望的，我们的「出乎意料」程度就比较高。</p><p>交叉熵代价函数如下所示：</p><p>$$J(w)&#x3D;-l(w)&#x3D;-\sum_{i &#x3D; 1}^n y^{(i)}ln(\phi(z^{(i)})) + (1 - y^{(i)})ln(1-\phi(z^{(i)}))$$</p><p>$$J(\phi(z),y;w)&#x3D;-yln(\phi(z))-(1-y)ln(1-\phi(z))$$</p><p>注：为什么要使用交叉熵函数作为代价函数，而不是平方误差函数？请参考：<a href="https://blog.csdn.net/syyyy712/article/details/78252722">逻辑回归算法之交叉熵函数理解</a></p><p><strong>逻辑回归伪代码</strong></p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs gams">初始化线性函数参数为<span class="hljs-number">1</span><br>构造<span class="hljs-built_in">sigmoid</span>函数<br>重复循环I次<br>计算数据集梯度<br>更新线性函数参数<br>确定最终的<span class="hljs-built_in">sigmoid</span>函数<br>输入训练（测试）数据集<br>运用最终<span class="hljs-built_in">sigmoid</span>函数求解分类<br></code></pre></td></tr></table></figure><p><strong>逻辑回归算法之Python实现</strong></p><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a></li><li>《统计学习方法》 (蓝书)  第6章  P77页</li><li>《机器学习》 (西瓜书) 第3章  P57页</li><li><a href="https://d19vezwu8eufl6.cloudfront.net/ml/docs%2Fslides%2FLecture6.pdf">《Machine Learning》 吴恩达 Logistic Regression</a></li><li><a href="https://blog.csdn.net/pakko/article/details/37878837">逻辑回归 - 理论篇</a></li><li><a href="https://blog.csdn.net/zjuPeco/article/details/77165974">逻辑回归(logistic regression)的本质——极大似然估计</a></li><li><a href="https://www.cnblogs.com/zhizhan/p/4868555.html">机器学习算法与Python实践之（七）逻辑回归（Logistic Regression）</a></li><li><a href="https://blog.csdn.net/moxigandashu/article/details/72779856">机器学习之Logistic回归与Python实现</a></li><li><a href="https://www.cnblogs.com/Belter/p/6128644.html">【机器学习】逻辑回归（Logistic Regression）</a></li><li><a href="https://blog.csdn.net/chibangyuxun/article/details/53148005">机器学习算法–逻辑回归原理介绍</a></li><li><a href="https://zhuanlan.zhihu.com/p/46591702">逻辑回归算法面经</a></li><li><a href="https://tech.meituan.com/2015/05/08/intro-to-logistic-regression.html">Logistic Regression 模型简介</a></li></ul><h3 id="为什么-LR-要使用-sigmoid-函数？"><a href="#为什么-LR-要使用-sigmoid-函数？" class="headerlink" title="为什么 LR 要使用 sigmoid 函数？"></a>为什么 LR 要使用 sigmoid 函数？</h3><p>1.广义模型推导所得<br>2.满足统计的最大熵模型<br>3.性质优秀，方便使用（Sigmoid函数是平滑的，而且任意阶可导，一阶二阶导数可以直接由函数值得到不用进行求导，这在实现中很实用）</p><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/weixin_39881922/article/details/80366324">为什么逻辑回归 模型要使用 sigmoid 函数</a></li></ul><h3 id="LR-可以用核函数么？"><a href="#LR-可以用核函数么？" class="headerlink" title="LR 可以用核函数么？"></a>LR 可以用核函数么？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="为什么-LR-用交叉熵损失而不是平方损失？"><a href="#为什么-LR-用交叉熵损失而不是平方损失？" class="headerlink" title="为什么 LR 用交叉熵损失而不是平方损失？"></a>为什么 LR 用交叉熵损失而不是平方损失？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="LR-能否解决非线性分类问题？"><a href="#LR-能否解决非线性分类问题？" class="headerlink" title="LR 能否解决非线性分类问题？"></a>LR 能否解决非线性分类问题？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/29385169">逻辑斯蒂回归能否解决非线性分类问题？</a></li></ul><h3 id="LR为什么要离散特征？"><a href="#LR为什么要离散特征？" class="headerlink" title="LR为什么要离散特征？"></a>LR为什么要离散特征？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="逻辑回归是处理线性问题还是非线性问题的？"><a href="#逻辑回归是处理线性问题还是非线性问题的？" class="headerlink" title="逻辑回归是处理线性问题还是非线性问题的？"></a>逻辑回归是处理线性问题还是非线性问题的？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="基本原理-1"><a href="#基本原理-1" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/alw_123/article/details/82193535">通俗理解线性回归（一）</a></li></ul><h3 id="线性回归与逻辑回归（LR）的区别"><a href="#线性回归与逻辑回归（LR）的区别" class="headerlink" title="线性回归与逻辑回归（LR）的区别"></a>线性回归与逻辑回归（LR）的区别</h3><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/ddydavie/article/details/82668141">线性回归和逻辑回归的比较</a></li></ul><h2 id="支持向量机（SVM）"><a href="#支持向量机（SVM）" class="headerlink" title="支持向量机（SVM）"></a>支持向量机（SVM）</h2><h3 id="基本原理-2"><a href="#基本原理-2" class="headerlink" title="基本原理"></a>基本原理</h3><p><a href="https://en.wikipedia.org/wiki/Support-vector_machine">支持向量机（supporr vector machine，SVM）</a>是一种二类分类模型，该模型是定义在特征空间上的间隔最大的线性分类器。间隔最大使它有区别于感知机；支持向量机还包括核技巧，这使它成为实质上的非线性分类器。支持向量机的学习策略就是<strong>间隔最大化</strong>，可形式化为一个求解凸二次规划的最小化问题。</p><p><strong>知识点提炼：</strong></p><ul><li>SVM核函数<ul><li>多项式核函数</li><li>高斯核函数</li><li>字符串核函数</li></ul></li><li>SMO</li><li>SVM损失函数</li></ul><p>支持向量机的学习算法是求解凸二次规划的最优化算法。</p><p>支持向量机学习方法包含构建由简至繁的模型：</p><ul><li>线性可分支持向量机</li><li>线性支持向量机</li><li>非线性支持向量机（使用核函数）</li></ul><p>当训练数据线性可分时，通过硬间隔最大化（hard margin maximization）学习一个线性的分类器，即线性可分支持向量机，又成为硬间隔支持向量机；</p><p>当训练数据近似线性可分时，通过软间隔最大化（soft margin maximization）也学习一个线性的分类器，即线性支持向量机，又称为软间隔支持向量机；</p><p>当训练数据不可分时，通过核技巧（kernel trick）及软间隔最大化，学习非线性支持向量机。</p><p>注：以上各SVM的数学推导应该熟悉：硬间隔最大化（几何间隔）—学习的对偶问题—软间隔最大化（引入松弛变量）—非线性支持向量机（核技巧）。</p><p><strong>SVM的主要特点</strong></p><p>（1）非线性映射-理论基础 </p><p>（2）最大化分类边界-方法核心 </p><p>（3）支持向量-计算结果 </p><p>（4）小样本学习方法 </p><p>（5）最终的决策函数只有少量支持向量决定，避免了“维数灾难” </p><p>（6）少数支持向量决定最终结果—-&gt;可“剔除”大量冗余样本+算法简单+具有鲁棒性（体现在3个方面） </p><p>（7）学习问题可表示为凸优化问题—-&gt;全局最小值 </p><p>（8）可自动通过最大化边界控制模型，但需要用户指定核函数类型和引入松弛变量 </p><p>（9）适合于小样本，优秀泛化能力（因为结构风险最小） </p><p>（10）泛化错误率低，分类速度快，结果易解释</p><p><strong>SVM为什么采用间隔最大化？</strong></p><p>当训练数据线性可分时，存在无穷个分离超平面可以将两类数据正确分开。</p><p>感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。</p><p>线性可分支持向量机利用间隔最大化求得最优分离超平面，这时，解是唯一的。另一方面，此时的分隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。</p><p>然后应该借此阐述，几何间隔，函数间隔，及从函数间隔—&gt;求解最小化1&#x2F;2 ||w||^2 时的w和b。即线性可分支持向量机学习算法—最大间隔法的由来。</p><p><strong>为什么要将求解SVM的原始问题转换为其对偶问题？</strong></p><ol><li>对偶问题往往更易求解（当我们寻找约束存在时的最优点的时候，约束的存在虽然减小了需要搜寻的范围，但是却使问题变得更加复杂。为了使问题变得易于处理，我们的方法是把目标函数和约束全部融入一个新的函数，即拉格朗日函数，再通过这个函数来寻找最优点。）</li><li>自然引入核函数，进而推广到非线性分类问题</li></ol><p><strong>为什么SVM要引入核函数？</strong></p><p>当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。</p><p><strong>SVM核函数有哪些？</strong></p><ul><li>线性（Linear）核函数：主要用于线性可分的情形。参数少，速度快。</li><li>多项式核函数</li><li>高斯（RBF）核函数：主要用于线性不可分的情形。参数多，分类结果非常依赖于参数。</li><li>Sigmoid核函数</li><li>拉普拉斯（Laplac）核函数</li></ul><p>注：如果feature数量很大，跟样本数量差不多，建议使用LR或者Linear kernel的SVM。如果feature数量较少，样本数量一般，建议使用Gaussian Kernel的SVM。</p><p><strong>SVM如何处理多分类问题？</strong></p><p>一般有两种做法：</p><ol><li><p>直接法：直接在目标函数上修改，将多个分类面的参数求解合并到一个最优化问题里面。看似简单但是计算量却非常的大。</p></li><li><p>间接法：对训练器进行组合。其中比较典型的有一对一，和一对多。</p><ul><li>一对多：对每个类都训练出一个分类器，由svm是二分类，所以将此而分类器的两类设定为目标类为一类，其余类为另外一类。这样针对k个类可以训练出k个分类器，当有一个新的样本来的时候，用这k个分类器来测试，那个分类器的概率高，那么这个样本就属于哪一类。这种方法效果不太好，bias比较高。</li><li>一对一：针对任意两个类训练出一个分类器，如果有k类，一共训练出C(2,k) 个分类器，这样当有一个新的样本要来的时候，用这C(2,k) 个分类器来测试，每当被判定属于某一类的时候，该类就加一，最后票数最多的类别被认定为该样本的类。</li></ul></li></ol><p><strong>SVM中硬间隔和软间隔</strong></p><p>硬间隔分类即线性可分支持向量机，软间隔分类即线性不可分支持向量机，利用软间隔分类时是因为存在一些训练集样本不满足函数间隔（泛函间隔）大于等于1的条件，于是加入一个非负的参数 ζ （松弛变量），让得出的函数间隔加上 ζ 满足条件。于是软间隔分类法对应的拉格朗日方程对比于硬间隔分类法的方程就多了两个参数（一个ζ ，一个 β），但是当我们求出对偶问题的方程时惊奇的发现这两种情况下的方程是一致的。下面我说下自己对这个问题的理解。</p><p>我们可以先考虑软间隔分类法为什么会加入ζ 这个参数呢？硬间隔的分类法其结果容易受少数点的控制，这是很危险的，由于一定要满足函数间隔大于等于1的条件，而存在的少数离群点会让算法无法得到最优解，于是引入松弛变量，从字面就可以看出这个变量是为了缓和判定条件，所以当存在一些离群点时我们只要对应给他一个ζi，就可以在不变更最优分类超平面的情况下让这个离群点满足分类条件。</p><p>综上，我们可以看出来软间隔分类法加入ζ 参数，使得最优分类超平面不会受到离群点的影响，不会向离群点靠近或远离，相当于我们去求解排除了离群点之后，样本点已经线性可分的情况下的硬间隔分类问题，所以两者的对偶问题是一致的。</p><h3 id="支持向量中的向量是指什么？"><a href="#支持向量中的向量是指什么？" class="headerlink" title="支持向量中的向量是指什么？"></a>支持向量中的向量是指什么？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="手推SVM"><a href="#手推SVM" class="headerlink" title="手推SVM"></a>手推SVM</h3><p><strong>参考资料</strong></p><ul><li><a href="https://en.wikipedia.org/wiki/Support-vector_machine">Support-vector machine</a></li><li><a href="https://blog.csdn.net/v_july_v/article/details/7624837">支持向量机通俗导论（理解SVM的三层境界）</a></li><li><a href="https://blog.csdn.net/szlcw1/article/details/52259668">数据挖掘（机器学习）面试–SVM面试常考问题</a></li><li><a href="http://cuijiahua.com/blog/2017/11/ml_8_svm_1.html">机器学习实战教程（八）：支持向量机原理篇之手撕线性SVM</a></li><li><a href="https://blog.csdn.net/sinat_20177327/article/details/79729551">支持向量机（SVM）入门理解与推导</a></li><li><a href="https://blog.csdn.net/fuqiuai/article/details/79483057">数据挖掘领域十大经典算法之—SVM算法（超详细附代码）</a></li></ul><h3 id="LR-与-SVM的区别和联系"><a href="#LR-与-SVM的区别和联系" class="headerlink" title="LR 与 SVM的区别和联系"></a>LR 与 SVM的区别和联系</h3><p><strong>相同点</strong></p><p>第一，LR和SVM都是分类算法。</p><p>看到这里很多人就不会认同了，因为在很大一部分人眼里，LR是回归算法。我是非常不赞同这一点的，因为我认为判断一个算法是分类还是回归算法的唯一标准就是样本label的类型，如果label是离散的，就是分类算法，如果label是连续的，就是回归算法。很明显，LR的训练数据的label是“0或者1”，当然是分类算法。其实这样不重要啦，暂且迁就我认为它是分类算法吧，再说了，SVM也可以回归用呢。</p><p>第二，如果不考虑核函数，LR和SVM都是线性分类算法，也就是说他们的分类决策面都是线性的。</p><p>这里要先说明一点，那就是LR也是可以用核函数的，至于为什么通常在SVM中运用核函数而不在LR中运用，后面讲到他们之间区别的时候会重点分析。总之，原始的LR和SVM都是线性分类器，这也是为什么通常没人问你决策树和LR什么区别，决策树和SVM什么区别，你说一个非线性分类器和一个线性分类器有什么区别？</p><p>第三，LR和SVM都是监督学习算法。</p><p>这个就不赘述什么是监督学习，什么是半监督学习，什么是非监督学习了。</p><p>第四，LR和SVM都是判别模型。</p><p>判别模型会生成一个表示P(Y|X)的判别函数（或预测模型），而生成模型先计算联合概率p(Y,X)然后通过贝叶斯公式转化为条件概率。简单来说，在计算判别模型时，不会计算联合概率，而在计算生成模型时，必须先计算联合概率。或者这样理解：生成算法尝试去找到底这个数据是怎么生成的（产生的），然后再对一个信号进行分类。基于你的生成假设，那么那个类别最有可能产生这个信号，这个信号就属于那个类别。判别模型不关心数据是怎么生成的，它只关心信号之间的差别，然后用差别来简单对给定的一个信号进行分类。常见的判别模型有：KNN、SVM、LR，常见的生成模型有：朴素贝叶斯，隐马尔可夫模型。当然，这也是为什么很少有人问你朴素贝叶斯和LR以及朴素贝叶斯和SVM有什么区别（哈哈，废话是不是太多）。</p><p><strong>不同点</strong></p><p>第一，本质上是其损失函数（loss function）不同。</p><p>注：lr的损失函数是 cross entropy loss， adaboost的损失函数是 expotional loss ,svm是hinge loss，常见的回归模型通常用 均方误差 loss。</p><p>逻辑回归的损失函数</p><p><img src="http://s10.sinaimg.cn/mw690/002n6ruKgy6WWsUQfxf29"></p><p>SVM的目标函数</p><p><img src="http://s4.sinaimg.cn/mw690/002n6ruKgy6WWtjCmm793"></p><p>不同的loss function代表了不同的假设前提，也就代表了不同的分类原理，也就代表了一切！！！简单来说，​逻辑回归方法基于概率理论，假设样本为1的概率可以用sigmoid函数来表示，然后通过极大似然估计的方法估计出参数的值，具体细节参考<a href="http://blog.csdn.net/pakko/article/details/37878837">逻辑回归</a>。支持向量机​基于几何间隔最大化原理，认为存在最大几何间隔的分类面为最优分类面，具体细节参考<a href="http://blog.csdn.net/macyang/article/details/38782399">支持向量机通俗导论（理解SVM的三层境界）</a></p><p>第二，支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局（远离的点对边界线的确定也起作用）。</p><p>当​你读完上面两个网址的内容，深入了解了LR和SVM的原理过后，会发现影响SVM决策面的样本点只有少数的结构支持向量，当在支持向量外添加或减少任何样本点对分类决策面没有任何影响；而在LR中，每个样本点都会影响决策面的结果。用下图进行说明：</p><p>支持向量机改变非支持向量样本并不会引起决策面的变化</p><p><img src="http://s1.sinaimg.cn/mw690/002n6ruKgy6WWvMHbGgb0"></p><p>逻辑回归中改变任何样本都会引起决策面的变化</p><p><img src="http://s5.sinaimg.cn/mw690/002n6ruKgy6WWw74KqM04"></p><p>理解了这一点，有可能你会问，然后呢？有什么用呢？有什么意义吗？对使用两种算法有什么帮助么？一句话回答：</p><p>因为上面的原因，得知：线性SVM不直接依赖于数据分布，分类平面不受一类点影响；LR则受所有数据点的影响，如果数据不同类别strongly unbalance，一般需要先对数据做balancing。​（引自<a href="http://www.zhihu.com/question/26768865/answer/34078149%EF%BC%89">http://www.zhihu.com/question/26768865/answer/34078149）</a></p><p>第三，在解决非线性问题时，支持向量机采用核函数的机制，而LR通常不采用核函数的方法。</p><p>这个问题理解起来非常简单。分类模型的结果就是计算决策面，模型训练的过程就是决策面的计算过程。通过上面的第二点不同点可以了解，在计算决策面时，SVM算法里只有少数几个代表支持向量的样本参与了计算，也就是只有少数几个样本需要参与核计算（即kernal machine解的系数是稀疏的）。然而，LR算法里，每个样本点都必须参与决策面的计算过程，也就是说，假设我们在LR里也运用核函数的原理，那么每个样本点都必须参与核计算，这带来的计算复杂度是相当高的。所以，在具体应用时，LR很少运用核函数机制。​</p><p>第四，​线性SVM依赖数据表达的距离测度，所以需要对数据先做normalization，LR不受其影响。（引自<a href="http://www.zhihu.com/question/26768865/answer/34078149%EF%BC%89">http://www.zhihu.com/question/26768865/answer/34078149）</a></p><p>一个机遇概率，一个机遇距离！​</p><p>第五，SVM的损失函数就自带正则！！！（损失函数中的1&#x2F;2||w||^2项），这就是为什么SVM是结构风险最小化算法的原因！！！而LR必须另外在损失函数上添加正则项！！！</p><p>以前一直不理解为什么SVM叫做结构风险最小化算法，<strong>所谓结构风险最小化，意思就是在训练误差和模型复杂度之间寻求平衡，防止过拟合，从而达到真实误差的最小化</strong>。未达到结构风险最小化的目的，最常用的方法就是添加正则项，后面的博客我会具体分析各种正则因子的不同，这里就不扯远了。但是，你发现没，SVM的目标函数里居然自带正则项！！！再看一下上面提到过的SVM目标函数：</p><p>SVM目标函数</p><p><img src="http://s9.sinaimg.cn/mw690/002n6ruKgy6WWxdRoxy08"></p><p>有木有，那不就是L2正则项吗？</p><p>不用多说了，如果不明白看看L1正则与L2正则吧，参考<a href="http://www.mamicode.com/info-detail-517504.html">http://www.mamicode.com/info-detail-517504.html</a></p><p><a href="http://www.zhihu.com/question/26768865/answer/34078149">http://www.zhihu.com/question/26768865/answer/34078149</a></p><p><strong>快速理解LR和SVM的区别</strong></p><p>两种方法都是常见的分类算法，从目标函数来看，区别在于逻辑回归采用的是logistical loss，svm采用的是hinge loss。这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。两者的根本目的都是一样的。此外，根据需要，两个方法都可以增加不同的正则化项，如l1,l2等等。所以在很多实验中，两种算法的结果是很接近的。但是逻辑回归相对来说模型更简单，好理解，实现起来，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些。但是SVM的理论基础更加牢固，有一套结构化风险最小化的理论基础，虽然一般使用的人不太会去关注。还有很重要的一点，SVM转化为对偶问题后，分类只需要计算与少数几个支持向量的距离，这个在进行复杂核函数计算时优势很明显，能够大大简化模型和计算量。</p><p><strong>SVM与LR的区别与联系</strong></p><p>联系：（1）分类（二分类） （2）可加入正则化项 </p><p>区别：（1）LR–参数模型；SVM–非参数模型？（2）目标函数：LR—logistical loss；SVM–hinge loss （3）SVM–support vectors；LR–减少较远点的权重 （4）LR–模型简单，好理解，精度低，可能局部最优；SVM–理解、优化复杂，精度高，全局最优，转化为对偶问题—&gt;简化模型和计算 （5）LR可以做的SVM可以做（线性可分），SVM能做的LR不一定能做（线性不可分）</p><p><strong>总结一下</strong></p><ul><li>Linear SVM和LR都是线性分类器</li><li>Linear SVM不直接依赖数据分布，分类平面不受一类点影响；LR则受所有数据点的影响，如果数据不同类别strongly unbalance，一般需要对数据先做balancing。</li><li>Linear SVM依赖数据表打对距离测度，所以需要对数据先做normalization；LR不受影响</li><li>Linear SVM依赖penalty的系数，实验中需要做validation</li><li>Linear SVM的LR的performance都会收到outlier的影响，就敏感程度而言，无法给出明确结论。</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/zhizhan/p/5038747.html">LR与SVM的异同</a></li><li><a href="https://www.zhihu.com/question/21704547/answer/20293255">SVM和logistic回归分别在什么情况下使用？</a></li><li><a href="https://www.zhihu.com/question/26768865/answer/34078149">Linear SVM 和 LR 有什么异同？</a></li></ul><h3 id="SVM-中有哪些核函数？"><a href="#SVM-中有哪些核函数？" class="headerlink" title="SVM 中有哪些核函数？"></a>SVM 中有哪些核函数？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/ningyanggege/article/details/84072842">svm常用核函数及选择核函数的方法</a></li><li><a href="https://www.jianshu.com/p/e07932472257?utm_campaign">SVM由浅入深的尝试（五）核函数的理解</a></li></ul><h3 id="SVM-的对偶问题"><a href="#SVM-的对偶问题" class="headerlink" title="SVM 的对偶问题"></a>SVM 的对偶问题</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="SMO-算法原理"><a href="#SMO-算法原理" class="headerlink" title="SMO 算法原理"></a>SMO 算法原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p>SVM 为什么可以处理非线性问题？</p><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="SVM-中的优化技术有哪些？"><a href="#SVM-中的优化技术有哪些？" class="headerlink" title="SVM 中的优化技术有哪些？"></a>SVM 中的优化技术有哪些？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="SVM-的惩罚系数如何确定？"><a href="#SVM-的惩罚系数如何确定？" class="headerlink" title="SVM 的惩罚系数如何确定？"></a>SVM 的惩罚系数如何确定？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="正则化参数对支持向量数的影响"><a href="#正则化参数对支持向量数的影响" class="headerlink" title="正则化参数对支持向量数的影响"></a>正则化参数对支持向量数的影响</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="如何解决线性不可分问题？"><a href="#如何解决线性不可分问题？" class="headerlink" title="如何解决线性不可分问题？"></a>如何解决线性不可分问题？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="软间隔和硬间隔"><a href="#软间隔和硬间隔" class="headerlink" title="软间隔和硬间隔"></a>软间隔和硬间隔</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="梯度提升树（GBDT）"><a href="#梯度提升树（GBDT）" class="headerlink" title="梯度提升树（GBDT）"></a>梯度提升树（GBDT）</h2><h3 id="基本原理-3"><a href="#基本原理-3" class="headerlink" title="基本原理"></a>基本原理</h3><p>下面关于GBDT的理解来自论文greedy function approximation: a gradient boosting machine</p><ol><li>损失函数的数值优化可以看成是在函数空间，而不是在参数空间。</li><li>损失函数L(y,F)包含平方损失(y−F)2，绝对值损失|y−F|用于回归问题，负二项对数似然log(1+e−2yF),y∈{-1,1}用于分类。</li><li>关注点是预测函数的加性扩展。</li></ol><p>最关键的点在于损失函数的数值优化可以看成是在函数空间而不是参数空间。</p><p>GBDT对分类问题基学习器是二叉分类树，对回归问题基学习器是二叉决策树。</p><p><strong>参考资料</strong></p><ul><li><p><a href="https://blog.csdn.net/google19890102/article/details/51746402/">简单易学的机器学习算法——梯度提升决策树GBDT</a></p></li><li><p><a href="https://www.cnblogs.com/ScorpioLu/p/8296994.html">GBDT原理详解</a></p></li></ul><h2 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h2><h3 id="基本原理-4"><a href="#基本原理-4" class="headerlink" title="基本原理"></a>基本原理</h3><p>Adaboost算法基本原理就是将多个弱分类器（弱分类器一般选用单层决策树）进行合理的结合，使其成为一个强分类器。</p><p>Adaboost采用迭代的思想，每次迭代只训练一个弱分类器，训练好的弱分类器将参与下一次迭代的使用。也就是说，在第N次迭代中，一共就有N个弱分类器，其中N-1个是以前训练好的，其各种参数都不再改变，本次训练第N个分类器。其中弱分类器的关系是第N个弱分类器更可能分对前N-1个弱分类器没分对的数据，最终分类输出要看这N个分类器的综合效果。</p><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/px_528/article/details/72963977">Adaboost入门教程——最通俗易懂的原理介绍（图文实例）</a></li><li><a href="https://www.cnblogs.com/ScorpioLu/p/8295990.html">AdaBoost原理详解</a></li><li><a href="https://blog.csdn.net/fuqiuai/article/details/79482487">数据挖掘领域十大经典算法之—AdaBoost算法（超详细附代码）</a></li><li><a href="https://zhuanlan.zhihu.com/p/62037189">聊聊Adaboost，从理念到硬核推导</a></li></ul><h3 id="GBDT-和-AdaBoost-区别"><a href="#GBDT-和-AdaBoost-区别" class="headerlink" title="GBDT 和 AdaBoost 区别"></a>GBDT 和 AdaBoost 区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><h3 id="基本原理-5"><a href="#基本原理-5" class="headerlink" title="基本原理"></a>基本原理</h3><p><strong>XGBoost全名叫（eXtreme Gradient Boosting）极端梯度提升</strong>，经常被用在一些比赛中，其效果显著。它是大规模并行boosted tree的工具，它是目前最快最好的开源boosted tree工具包。下面我们将XGBoost的学习分为3步：</p><p>① 集成思想 </p><p>② 损失函数分析 </p><p>③ 求解</p><p>我们知道机器学习三要素：模型、策略、算法。对于集成思想的介绍，XGBoost算法本身就是以集成思想为基础的。所以理解清楚集成学习方法对XGBoost是必要的，它能让我们更好的理解其预测函数模型。在第二部分，我们将详细分析损失函数，这就是我们将要介绍策略。第三部分，对于目标损失函数求解，也就是算法了。</p><p><strong>参考资料</strong></p><ul><li><a href="https://xgboost.readthedocs.io/en/latest/">XGBoost Documentation</a></li><li><a href="https://blog.csdn.net/github_38414650/article/details/76061893">通俗、有逻辑的写一篇说下Xgboost的原理，供讨论参考</a></li><li><a href="https://www.jianshu.com/p/7467e616f227">xgboost的原理没你想像的那么难</a></li></ul><h3 id="XGBoost里处理缺失值的方法"><a href="#XGBoost里处理缺失值的方法" class="headerlink" title="XGBoost里处理缺失值的方法"></a>XGBoost里处理缺失值的方法</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="XGBoost-和-GBDT-的区别"><a href="#XGBoost-和-GBDT-的区别" class="headerlink" title="XGBoost 和 GBDT 的区别"></a>XGBoost 和 GBDT 的区别</h3><ul><li><p>传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。</p></li><li><p>传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。</p></li><li><p>xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。</p></li><li><p>Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率）</p></li><li><p>列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。</p></li><li><p>对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。</p></li><li><p>xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p></li><li><p>可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</p></li></ul><h3 id="XGBoost-如何做到自定义损失函数？"><a href="#XGBoost-如何做到自定义损失函数？" class="headerlink" title="XGBoost 如何做到自定义损失函数？"></a>XGBoost 如何做到自定义损失函数？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="XGBoost-如何防止过拟合？"><a href="#XGBoost-如何防止过拟合？" class="headerlink" title="XGBoost 如何防止过拟合？"></a>XGBoost 如何防止过拟合？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="XGBoost-为什么不用后剪枝？"><a href="#XGBoost-为什么不用后剪枝？" class="headerlink" title="XGBoost 为什么不用后剪枝？"></a>XGBoost 为什么不用后剪枝？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="XGBoost-是如何实现并行的？"><a href="#XGBoost-是如何实现并行的？" class="headerlink" title="XGBoost 是如何实现并行的？"></a>XGBoost 是如何实现并行的？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="XGBoost-有哪些参数，取指范围，各代表什么意思？"><a href="#XGBoost-有哪些参数，取指范围，各代表什么意思？" class="headerlink" title="XGBoost 有哪些参数，取指范围，各代表什么意思？"></a>XGBoost 有哪些参数，取指范围，各代表什么意思？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/huacha__/article/details/81029680">XGBoost——机器学习（理论+图解+安装方法+python代码）</a></li><li><a href="http://blog.itpub.net/31542119/viewspace-2199549/">一文读懂机器学习大杀器 XGBoost 原理</a></li></ul><h3 id="XGBoost-如何进行并行加速的？"><a href="#XGBoost-如何进行并行加速的？" class="headerlink" title="XGBoost 如何进行并行加速的？"></a>XGBoost 如何进行并行加速的？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="每次分裂叶子节点是怎么决定特征和分裂点的？"><a href="#每次分裂叶子节点是怎么决定特征和分裂点的？" class="headerlink" title="每次分裂叶子节点是怎么决定特征和分裂点的？"></a>每次分裂叶子节点是怎么决定特征和分裂点的？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="Adaboost、GBDT与XGBoost的区别"><a href="#Adaboost、GBDT与XGBoost的区别" class="headerlink" title="Adaboost、GBDT与XGBoost的区别"></a>Adaboost、GBDT与XGBoost的区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/hellozhxy/article/details/82143554">Adaboost、GBDT与XGBoost的区别</a></li></ul><h2 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h2><h3 id="基本原理-6"><a href="#基本原理-6" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="LightGBM-与-XGBoost-的区别"><a href="#LightGBM-与-XGBoost-的区别" class="headerlink" title="LightGBM 与 XGBoost 的区别"></a>LightGBM 与 XGBoost 的区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="GBDT、LightGBM-和-XGBoost-区别"><a href="#GBDT、LightGBM-和-XGBoost-区别" class="headerlink" title="GBDT、LightGBM 和 XGBoost 区别"></a>GBDT、LightGBM 和 XGBoost 区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="基本原理-7"><a href="#基本原理-7" class="headerlink" title="基本原理"></a>基本原理</h3><p>1、KNN算法概述</p><p>　　kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。<br>　　<br>2、KNN算法介绍</p><p> 　　最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。</p><p>KNN是通过测量不同特征值之间的距离进行分类。它的的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。</p><p>下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K&#x3D;3，由于红色三角形所占比例为2&#x2F;3，绿色圆将被赋予红色三角形那个类，如果K&#x3D;5，由于蓝色四方形比例为3&#x2F;5，因此绿色圆被赋予蓝色四方形类。</p><p><img src="https://images0.cnblogs.com/blog2015/771535/201508/041623504236939.jpg"><br>　<br>接下来对KNN算法的思想总结一下：就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：</p><p>1）计算测试数据与各个训练数据之间的距离；</p><p>2）按照距离的递增关系进行排序；</p><p>3）选取距离最小的K个点；</p><p>4）确定前K个点所在类别的出现频率；</p><p>5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。　</p><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/sxron/p/5451923.html">KNN算法原理及实现</a></li><li><a href="https://www.cnblogs.com/apachecnxy/p/7462628.html">第2章 k-近邻算法</a></li><li><a href="https://blog.csdn.net/fuqiuai/article/details/79458648">数据挖掘领域十大经典算法之—K-邻近算法&#x2F;kNN（超详细附代码）</a></li></ul><h2 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h2><h3 id="基本原理-8"><a href="#基本原理-8" class="headerlink" title="基本原理"></a>基本原理</h3><p>算法思想：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs applescript">选择K个点作为初始质心  <br><span class="hljs-keyword">repeat</span>  <br>    将每个点指派到最近的质心，形成K个簇  <br>    重新计算每个簇的质心  <br><span class="hljs-keyword">until</span> 簇不发生变化或达到最大迭代次数  <br></code></pre></td></tr></table></figure><p>这里的重新计算每个簇的质心，如何计算的是根据目标函数得来的，因此在开始时我们要考虑距离度量和目标函数。</p><p>考虑欧几里得距离的数据，使用误差平方和（Sum of the Squared Error,SSE）作为聚类的目标函数，两次运行K均值产生的两个不同的簇集，我们更喜欢SSE最小的那个。</p><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/taoyanqi8932/article/details/53727841">深入理解K-Means聚类算法</a></li><li><a href="https://blog.csdn.net/fuqiuai/article/details/79458331">数据挖掘领域十大经典算法之—K-Means算法（超详细附代码）</a></li></ul><h3 id="手撕-K-Means"><a href="#手撕-K-Means" class="headerlink" title="手撕 K-Means"></a>手撕 K-Means</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="K-Means-与-KNN-的区别"><a href="#K-Means-与-KNN-的区别" class="headerlink" title="K-Means 与 KNN 的区别"></a>K-Means 与 KNN 的区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/peizhe123/p/4619066.html">Kmeans算法与KNN算法的区别</a></li></ul><h3 id="K-Means-中的-K-怎么确定？"><a href="#K-Means-中的-K-怎么确定？" class="headerlink" title="K-Means 中的 K 怎么确定？"></a>K-Means 中的 K 怎么确定？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="K-Means-的迭代循环停止条件"><a href="#K-Means-的迭代循环停止条件" class="headerlink" title="K-Means 的迭代循环停止条件"></a>K-Means 的迭代循环停止条件</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="评判聚类效果准则"><a href="#评判聚类效果准则" class="headerlink" title="评判聚类效果准则"></a>评判聚类效果准则</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><h3 id="基本原理-9"><a href="#基本原理-9" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/fontthrone/article/details/79074296">集成算法中的Bagging</a></li></ul><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><h3 id="基本原理-10"><a href="#基本原理-10" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/starter_____/article/details/79328749">机器学习 —— Boosting算法</a></li></ul><h3 id="Bagging-和-Boosting-的区别"><a href="#Bagging-和-Boosting-的区别" class="headerlink" title="Bagging 和 Boosting 的区别"></a>Bagging 和 Boosting 的区别</h3><p>1）样本选择上：</p><p>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的.</p><p>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化.而权值是根据上一轮的分类结果进行调整.</p><p>2）样例权重：</p><p>Bagging：使用均匀取样，每个样例的权重相等</p><p>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大.</p><p>3）预测函数：</p><p>Bagging：所有预测函数的权重相等.</p><p>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重.</p><p>4）并行计算：</p><p>Bagging：各个预测函数可以并行生成</p><p>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果.</p><p><strong>参考资料</strong></p><ul><li><p><a href="https://www.cnblogs.com/earendil/p/8872001.html">Bagging和Boosting的区别（面试准备）</a></p></li><li><p><a href="https://www.cnblogs.com/liuwu265/p/4690486.html">Bagging和Boosting 概念及区别</a></p></li><li><p><a href="https://www.cnblogs.com/onemorepoint/p/9264782.html">Bagging和Boosting的概念与区别</a></p></li></ul><h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><h3 id="基本原理-11"><a href="#基本原理-11" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/apachecnxy/p/7471634.html">第4章 基于概率论的分类方法：朴素贝叶斯</a></li><li><a href="https://blog.csdn.net/fuqiuai/article/details/79458943">数据挖掘领域十大经典算法之—朴素贝叶斯算法（超详细附代码）</a></li></ul><h3 id="为什么朴素贝叶斯被称为“朴素”？"><a href="#为什么朴素贝叶斯被称为“朴素”？" class="headerlink" title="为什么朴素贝叶斯被称为“朴素”？"></a>为什么朴素贝叶斯被称为“朴素”？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="EM-算法"><a href="#EM-算法" class="headerlink" title="EM 算法"></a>EM 算法</h2><h3 id="基本原理-12"><a href="#基本原理-12" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/fuqiuai/article/details/79484421">数据挖掘领域十大经典算法之—EM算法</a></li></ul><h3 id="E-步和-M-步的具体步骤"><a href="#E-步和-M-步的具体步骤" class="headerlink" title="E 步和 M 步的具体步骤"></a>E 步和 M 步的具体步骤</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="E-中的期望是什么？"><a href="#E-中的期望是什么？" class="headerlink" title="E 中的期望是什么？"></a>E 中的期望是什么？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><h3 id="基本原理-13"><a href="#基本原理-13" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="决策树如何剪枝？"><a href="#决策树如何剪枝？" class="headerlink" title="决策树如何剪枝？"></a>决策树如何剪枝？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="决策树先剪枝还是后剪枝好？"><a href="#决策树先剪枝还是后剪枝好？" class="headerlink" title="决策树先剪枝还是后剪枝好？"></a>决策树先剪枝还是后剪枝好？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="决策树能否有非数值型变量？"><a href="#决策树能否有非数值型变量？" class="headerlink" title="决策树能否有非数值型变量？"></a>决策树能否有非数值型变量？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="决策树如何防止过拟合？"><a href="#决策树如何防止过拟合？" class="headerlink" title="决策树如何防止过拟合？"></a>决策树如何防止过拟合？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://shuwoom.com/?p=1452">机器学习之-常见决策树算法(ID3、C4.5、CART)</a></li><li><a href="https://blog.csdn.net/jiaoyangwm/article/details/79525237">机器学习实战（三）——决策树</a></li><li><a href="https://www.jianshu.com/p/655d8e555494">决策树基本概念及算法优缺点</a></li></ul><h3 id="决策树的ID3和C4-5介绍一下"><a href="#决策树的ID3和C4-5介绍一下" class="headerlink" title="决策树的ID3和C4.5介绍一下"></a>决策树的ID3和C4.5介绍一下</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="随机森林（RF）"><a href="#随机森林（RF）" class="headerlink" title="随机森林（RF）"></a>随机森林（RF）</h2><h3 id="基本原理-14"><a href="#基本原理-14" class="headerlink" title="基本原理"></a>基本原理</h3><p>随机森林属于集成学习（Ensemble Learning）中的bagging算法。在集成学习中，主要分为bagging算法和boosting算法。我们先看看这两种方法的特点和区别。</p><p><strong>Bagging（套袋法）</strong></p><p>bagging的算法过程如下：</p><p>从原始样本集中使用Bootstraping方法随机抽取n个训练样本，共进行k轮抽取，得到k个训练集。（k个训练集之间相互独立，元素可以有重复）<br>对于k个训练集，我们训练k个模型（这k个模型可以根据具体问题而定，比如决策树，knn等）<br>对于分类问题：由投票表决产生分类结果；对于回归问题：由k个模型预测结果的均值作为最后预测结果。（所有模型的重要性相同）</p><p><strong>Boosting（提升法）</strong></p><p>boosting的算法过程如下：</p><p>对于训练集中的每个样本建立权值wi，表示对每个样本的关注度。当某个样本被误分类的概率很高时，需要加大对该样本的权值。</p><p>进行迭代的过程中，每一步迭代都是一个弱分类器。我们需要用某种策略将其组合，作为最终模型。（例如AdaBoost给每个弱分类器一个权值，将其线性组合最为最终分类器。误差越小的弱分类器，权值越大）<br>Bagging，Boosting的主要区别</p><p>样本选择上：Bagging采用的是Bootstrap随机有放回抽样；而Boosting每一轮的训练集是不变的，改变的只是每一个样本的权重。</p><p>样本权重：Bagging使用的是均匀取样，每个样本权重相等；Boosting根据错误率调整样本权重，错误率越大的样本权重越大。</p><p>预测函数：Bagging所有的预测函数的权重相等；Boosting中误差越小的预测函数其权重越大。</p><p>并行计算：Bagging各个预测函数可以并行生成；Boosting各个预测函数必须按顺序迭代生成。</p><p>下面是将决策树与这些算法框架进行结合所得到的新的算法：</p><p>1）Bagging + 决策树 &#x3D; 随机森林</p><p>2）AdaBoost + 决策树 &#x3D; 提升树</p><p>3）Gradient Boosting + 决策树 &#x3D; GBDT</p><p><strong>决策树</strong></p><p>常用的决策树算法有ID3，C4.5，CART三种。3种算法的模型构建思想都十分类似，只是采用了不同的指标。决策树模型的构建过程大致如下：</p><p><strong>ID3，C4.5决策树的生成</strong></p><p>输入：训练集D，特征集A，阈值eps 输出：决策树T</p><p>若D中所有样本属于同一类Ck，则T为单节点树，将类Ck作为该结点的类标记，返回T</p><p>若A为空集，即没有特征作为划分依据，则T为单节点树，并将D中实例数最大的类Ck作为该结点的类标记，返回T<br>否则，计算A中各特征对D的信息增益(ID3)&#x2F;信息增益比(C4.5)，选择信息增益最大的特征Ag</p><p>若Ag的信息增益（比）小于阈值eps，则置T为单节点树，并将D中实例数最大的类Ck作为该结点的类标记，返回T<br>否则，依照特征Ag将D划分为若干非空子集Di，将Di中实例数最大的类作为标记，构建子节点，由结点及其子节点构成树T，返回T</p><p>对第i个子节点，以Di为训练集，以A-{Ag}为特征集，递归地调用1~5，得到子树Ti，返回Ti</p><p><strong>CART决策树的生成</strong></p><p>这里只简单介绍下CART与ID3和C4.5的区别。</p><p>CART树是二叉树，而ID3和C4.5可以是多叉树<br>CART在生成子树时，是选择一个特征一个取值作为切分点，生成两个子树<br>选择特征和切分点的依据是基尼指数，选择基尼指数最小的特征及切分点生成子树</p><p><strong>随机森林</strong></p><p>随机森林是一种重要的基于Bagging的集成学习方法，可以用来做分类、回归等问题。</p><p>随机森林有许多优点：</p><ul><li>具有极高的准确率</li><li>随机性的引入，使得随机森林不容易过拟合</li><li>随机性的引入，使得随机森林有很好的抗噪声能力</li><li>能处理很高维度的数据，并且不用做特征选择</li><li>既能处理离散型数据，也能处理连续型数据，数据集无需规范化</li><li>训练速度快，可以得到变量重要性排序</li><li>容易实现并行化</li></ul><p><strong>随机森林的缺点：</strong></p><p>当随机森林中的决策树个数很多时，训练时需要的空间和时间会较大</p><p>随机森林模型还有许多不好解释的地方，有点算个黑盒模型</p><p>与上面介绍的Bagging过程相似，随机森林的构建过程大致如下：</p><p>从原始训练集中使用Bootstraping方法随机有放回采样选出m个样本，共进行n_tree次采样，生成n_tree个训练集<br>对于n_tree个训练集，我们分别训练n_tree个决策树模型</p><p>对于单个决策树模型，假设训练样本特征的个数为n，那么每次分裂时根据信息增益&#x2F;信息增益比&#x2F;基尼指数选择最好的特征进行分裂</p><p>每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类。在决策树的分裂过程中不需要剪枝<br>将生成的多棵决策树组成随机森林。对于分类问题，按多棵树分类器投票决定最终分类结果；对于回归问题，由多棵树预测值的均值决定最终预测结果</p><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/qq547276542/article/details/78304454">随机森林算法学习(Random Forest)</a></li><li><a href="https://blog.csdn.net/edogawachia/article/details/79357844">随机森林（Random Forest）算法原理</a></li><li><a href="https://www.cnblogs.com/maybe2030/p/4585705.html">随机森林（Random Forest）</a></li><li><a href="http://www.elecfans.com/d/647463.html">机器学习算法之随机森林算法详解及工作原理图解</a></li></ul><h3 id="随机森林中的“随机”指什么？"><a href="#随机森林中的“随机”指什么？" class="headerlink" title="随机森林中的“随机”指什么？"></a>随机森林中的“随机”指什么？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="随机森林处理缺失值的方法"><a href="#随机森林处理缺失值的方法" class="headerlink" title="随机森林处理缺失值的方法"></a>随机森林处理缺失值的方法</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="随机森林和-GBDT-的区别"><a href="#随机森林和-GBDT-的区别" class="headerlink" title="随机森林和 GBDT 的区别"></a>随机森林和 GBDT 的区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="随机森林与决策树关系"><a href="#随机森林与决策树关系" class="headerlink" title="随机森林与决策树关系"></a>随机森林与决策树关系</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="CART回归树是怎么实现的？"><a href="#CART回归树是怎么实现的？" class="headerlink" title="CART回归树是怎么实现的？"></a>CART回归树是怎么实现的？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="CART分类树和ID3以及C4-5有什么区别？"><a href="#CART分类树和ID3以及C4-5有什么区别？" class="headerlink" title="CART分类树和ID3以及C4.5有什么区别？"></a>CART分类树和ID3以及C4.5有什么区别？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="机器学习中的分类、回归和聚类模型有哪些？"><a href="#机器学习中的分类、回归和聚类模型有哪些？" class="headerlink" title="机器学习中的分类、回归和聚类模型有哪些？"></a>机器学习中的分类、回归和聚类模型有哪些？</h2><p>分类：LR、SVM、KNN、决策树、RandomForest、GBDT  </p><p>回归：non-Linear regression、SVR（支持向量回归–&gt;可用线性或高斯核（RBF））、随机森林  </p><p>聚类：Kmeans、层次聚类、GMM（高斯混合模型）、谱聚类</p><h2 id="高斯混合模型（GMM）"><a href="#高斯混合模型（GMM）" class="headerlink" title="高斯混合模型（GMM）"></a>高斯混合模型（GMM）</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="http://blog.sina.com.cn/s/blog_a36a563e0102y2ec.html">深度理解高斯混合模型（GMM）</a></li><li><a href="https://blog.csdn.net/m_buddy/article/details/80432384">高斯混合模型（GMM）</a></li></ul><h2 id="马尔科夫随机场（MRF）"><a href="#马尔科夫随机场（MRF）" class="headerlink" title="马尔科夫随机场（MRF）"></a>马尔科夫随机场（MRF）</h2><h3 id="基本原理-15"><a href="#基本原理-15" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/pipisorry/article/details/78396503">马尔可夫随机场 MRF</a></li></ul><h2 id="隐马尔科夫模型（HMM）"><a href="#隐马尔科夫模型（HMM）" class="headerlink" title="隐马尔科夫模型（HMM）"></a>隐马尔科夫模型（HMM）</h2><h3 id="基本原理-16"><a href="#基本原理-16" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/skyme/p/4651331.html">一文搞懂HMM（隐马尔可夫模型）</a></li><li><a href="https://blog.csdn.net/baimafujinji/article/details/51285082">机器学习中的隐马尔科夫模型（HMM）详解</a></li></ul><h3 id="发射概率和状态转移概率"><a href="#发射概率和状态转移概率" class="headerlink" title="发射概率和状态转移概率"></a>发射概率和状态转移概率</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="每层要记住所有路径吗？"><a href="#每层要记住所有路径吗？" class="headerlink" title="每层要记住所有路径吗？"></a>每层要记住所有路径吗？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="条件随机场（CRF）"><a href="#条件随机场（CRF）" class="headerlink" title="条件随机场（CRF）"></a>条件随机场（CRF）</h2><h3 id="基本原理-17"><a href="#基本原理-17" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="CRF-的损失函数是什么？"><a href="#CRF-的损失函数是什么？" class="headerlink" title="CRF 的损失函数是什么？"></a>CRF 的损失函数是什么？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/wangyangzhizhou/article/details/78489593">机器学习之条件随机场（CRF）</a></li><li><a href="https://www.jianshu.com/p/55755fc649b1">如何轻松愉快地理解条件随机场（CRF）？</a></li><li><a href="https://zhuanlan.zhihu.com/p/70067113">一文理解条件随机场CRF</a></li></ul><h3 id="HMM、MEMM-vs-CRF-对比？"><a href="#HMM、MEMM-vs-CRF-对比？" class="headerlink" title="HMM、MEMM vs CRF 对比？"></a>HMM、MEMM vs CRF 对比？</h3><p>1）HMM是有向图模型，是生成模型；HMM有两个假设：一阶马尔科夫假设和观测独立性假设；但对于序列标注问题不仅和单个词相关，而且和观察序列的长度，单词的上下文，等等相关。</p><p>2）MEMM（最大熵马尔科夫模型）是有向图模型，是判别模型；MEMM打破了HMM的观测独立性假设，MEMM考虑到相邻状态之间依赖关系，且考虑整个观察序列，因此MEMM的表达能力更强；但MEMM会带来标注偏置问题：由于局部归一化问题，MEMM倾向于选择拥有更少转移的状态。这就是标记偏置问题。</p><p><img src="https://pic3.zhimg.com/80/v2-7a5e998530e0d9c5f146d27603e6e496_hd.jpg" alt="img">最大熵模型（MEMM）</p><p><img src="https://pic3.zhimg.com/80/v2-610ca7a9b504936bfba136c464ebe81a_hd.jpg" alt="img"></p><p>3）CRF模型解决了标注偏置问题，去除了HMM中两个不合理的假设，当然，模型相应得也变复杂了。</p><p>HMM、MEMM和CRF的优缺点比较：</p><p>a）与HMM比较。CRF没有HMM那样严格的独立性假设条件，因而可以容纳任意的上下文信息。特征设计灵活（与ME一样）</p><p>b）与MEMM比较。由于CRF计算全局最优输出节点的条件概率，它还克服了最大熵马尔可夫模型标记偏置（Label-bias）的缺点。</p><p>c）与ME比较。CRF是在给定需要标记的观察序列的条件下，计算整个标记序列的联合概率分布，而不是在给定当前状态条件下，定义下一个状态的状态分布.</p><blockquote><p>首先，CRF，HMM(隐马模型)，MEMM(最大熵隐马模型)都常用来做序列标注的建模，像分词、词性标注，以及命名实体标注<br>隐马模型一个最大的缺点就是由于其输出独立性假设，导致其不能考虑上下文的特征，限制了特征的选择<br>最大熵隐马模型则解决了隐马的问题，可以任意选择特征，但由于其在每一节点都要进行归一化，所以只能找到局部的最优值，同时也带来了标记偏见的问题，即凡是训练语料中未出现的情况全都忽略掉。<br>条件随机场则很好的解决了这一问题，他并不在每一个节点进行归一化，而是所有特征进行全局归一化，因此可以求得全局的最优值。</p></blockquote><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/57153934">HMM、MEMM vs CRF 对比？</a></li></ul><h2 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h2><h3 id="基本原理-18"><a href="#基本原理-18" class="headerlink" title="基本原理"></a>基本原理</h3><p>PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。网上关于PCA的文章有很多，但是大多数只描述了PCA的分析过程，而没有讲述其中的原理。这篇文章的目的是介绍PCA的基本数学原理，帮助读者了解PCA的工作机制是什么。</p><p>当然我并不打算把文章写成纯数学文章，而是希望用直观和易懂的方式叙述PCA的数学原理，所以整个文章不会引入严格的数学推导。希望读者在看完这篇文章后能更好的明白PCA的工作原理。</p><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/mikewolf2002/p/3429711.html">PCA的数学原理</a></li><li><a href="https://zhuanlan.zhihu.com/p/21580949">PCA的数学原理(转)</a></li><li><a href="https://www.cnblogs.com/apachecnxy/p/7640976.html">第13章 利用 PCA 来简化数据</a></li><li><a href="https://zhuanlan.zhihu.com/p/84946694">PCA（主成分分析）原理推导</a></li></ul><h2 id="线性判别分析（LDA）"><a href="#线性判别分析（LDA）" class="headerlink" title="线性判别分析（LDA）"></a>线性判别分析（LDA）</h2><p>TODO</p><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/pinard/p/6244265.html">线性判别分析LDA原理总结</a></li><li><a href="https://blog.csdn.net/qq_16137569/article/details/82385050">LDA原理小结</a></li></ul><h2 id="奇异值分解（SVD）"><a href="#奇异值分解（SVD）" class="headerlink" title="奇异值分解（SVD）"></a>奇异值分解（SVD）</h2><h3 id="基本原理-19"><a href="#基本原理-19" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">Singular_value_decomposition</a></li><li><a href="https://www.cnblogs.com/tgycoder/p/6266786.html">关于SVD(Singular Value Decomposition)的那些事儿</a></li><li><a href="https://www.cnblogs.com/pinard/p/6251584.html">奇异值分解(SVD)原理与在降维中的应用</a></li><li><a href="https://www.cnblogs.com/apachecnxy/p/7640987.html">第14章 利用SVD简化数据</a></li></ul><h3 id="手撕-SVD"><a href="#手撕-SVD" class="headerlink" title="手撕 SVD"></a>手撕 SVD</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="特征值和SVD的区别"><a href="#特征值和SVD的区别" class="headerlink" title="特征值和SVD的区别"></a>特征值和SVD的区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/u012380663/article/details/36629951">特征值和奇异值（svd）</a></li></ul><h2 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h2><h3 id="基本原理-20"><a href="#基本原理-20" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.cnblogs.com/harvey888/p/7100815.html">关于凸优化的一些简单概念</a></li><li><a href="https://blog.csdn.net/qq_39422642/article/details/78816637">最优化理论与凸优化到底是干嘛的？</a></li><li><a href="https://blog.csdn.net/xbinworld/article/details/79113218">深度学习&#x2F;机器学习入门基础数学知识整理（三）：凸优化，Hessian，牛顿法</a></li></ul><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p>注：建议放在深度学习中介绍，这里可以简单介绍</p><h2 id="Accuracy、Precision、Recall和-F1-Score"><a href="#Accuracy、Precision、Recall和-F1-Score" class="headerlink" title="Accuracy、Precision、Recall和 F1 Score"></a>Accuracy、Precision、Recall和 F1 Score</h2><p>在学习机器学习、深度学习，甚至做自己项目的时候，经过看到上述名词。然而因为名词容易搞混，所以经常会忘记相关的含义。</p><p>这里做一次最全最清晰的介绍，若之后再次忘记相关知识点，本文可以帮助快速回顾。</p><p>首先，列出一个清单：</p><ul><li><p>TP（true positive，真正）: 预测为正，实际为正</p></li><li><p>FP（false positive，假正）: 预测为正，实际为负</p></li><li><p>TN（true negative，真负）：预测为负，实际为负</p></li><li><p>FN（false negative，假负）: 预测为负，实际为正</p></li><li><p>ACC（accuracy，准确率）：ACC &#x3D; (TP+TN)&#x2F;(TP+TN+FN+FP)</p></li><li><p>P（precision精确率、精准率、查准率P &#x3D; TP&#x2F; (TP+FP)</p></li><li><p>R（recall，召回率、查全率）： R &#x3D; TP&#x2F; (TP+FN)</p></li><li><p>TPR（true positive rate，，真正类率同召回率、查全率）：TPR &#x3D; TP&#x2F; (TP+FN)</p><p>注：Recall &#x3D; TPR</p></li><li><p>FPR（false positive rate，假正类率）：FPR &#x3D;FP&#x2F; (FP+TN)</p></li><li><p>F-Score: F-Score &#x3D; (1+β^2) x (PxR) &#x2F; (β^2x(P+R)) &#x3D; 2xTP&#x2F;(2xTP + FP + FN)</p></li><li><p>当β&#x3D;1是，F1-score &#x3D; 2xPxR&#x2F;(P+R)</p></li><li><p>P-R曲线（precision-recall，查准率-查全率曲线）</p></li><li><p>ROC曲线（receiver operating characteristic，接收者操作特征曲线）</p></li><li><p>AUC（area under curve）值</p></li></ul><p>中文博大精深，为了不搞混，下面统一用英文全称或简称作为名词标识。</p><p>正式介绍一下前四个名词：</p><p><strong>True positives（TP，真正）</strong> : 预测为正，实际为正</p><p><strong>True negatives（TN，真负）</strong>：预测为负，实际为负</p><p><strong>False positives（FP，假正</strong>）: 预测为正，实际为负 </p><p><strong>False negatives（FN，假负）</strong>: 预测为负，实际为正</p><p>为了更好的理解，这里二元分类问题的例子：</p><p>假设，我们要对某一封邮件做出一个判定，判定这封邮件是垃圾邮件、还是这封邮件不是垃圾邮件？</p><p>如果判定是垃圾邮件，那就是做出（Positive）的判定； </p><p>如果判定不是垃圾邮件，那就做出（Negative）的判定。</p><p>True Positive（TP）意思表示做出Positive的判定，而且判定是正确的。</p><p>因此，TP的数值表示正确的Positive判定的个数。 </p><p>同理，False Positive（TP）数值表示错误的Positive判定的个数。 </p><p>依此，True Negative（TN）数值表示正确的Negative判定个数。 </p><p>False Negative（FN）数值表示错误的Negative判定个数。</p><p><strong>TPR、FPR和TNR</strong></p><p><strong>TPR（true positive rate，真正类率）</strong></p><p>TPR &#x3D; TP&#x2F;(TP+FN)</p><p>真正类率TPR代表分类器预测的正类中实际正实例占所有正实例的比例。</p><p><strong>FPR（false positive rate，假正类率）</strong></p><p>FPR &#x3D; FP&#x2F;(FP+TN)</p><p>假正类率FPR代表分类器预测的正类中实际负实例占所有负实例的比例。</p><p><strong>TNR（ture negative rate，真负类率）</strong></p><p>TNR &#x3D; TN&#x2F;(FP+TN)</p><p>真负类率TNR代表分类器预测的负类中实际负实例占所有负实例的比例。</p><p><strong>Accuracy</strong></p><p>准确率（accuracy，ACC）</p><p>ACC &#x3D; (TP+TN)&#x2F;(TP+TN+FN+FP)</p><p><strong>Precision &amp; Recall</strong></p><p><a href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision精确率</a>：</p><p>P &#x3D; TP&#x2F;(TP+FP)</p><p>表示当前划分到正样本类别中，被正确分类的比例（正确正样本所占比例）。</p><p><a href="https://en.wikipedia.org/wiki/Precision_and_recall">Recall召回率</a>：</p><p>R &#x3D; TP&#x2F;(TP+FN)</p><p>表示当前划分到正样本类别中，真实正样本占所有正样本的比例。</p><p><strong>F-Score</strong></p><p>F-Score 是精确率Precision和召回率Recall的加权调和平均值。该值是为了综合衡量Precision和Recall而设定的。</p><p>F-Score &#x3D; (1+β^2) x (PxR) &#x2F; (β^2x(P+R)) &#x3D; 2xTP&#x2F;(2xTP + FP + FN)</p><p>当β&#x3D;1时，F1-score &#x3D; 2xPxR&#x2F;(P+R)。这时，Precision和Recall都很重要，权重相同。</p><p>当有些情况下，我们认为Precision更重要，那就调整β的值小于1；如果我们认为Recall更加重要，那就调整β的值大于1。</p><p>一般来说，当F-Score或F1-score较高</p><p><strong>P-R曲线</strong></p><p><strong>ROC曲线</strong></p><p>横轴：负正类率(false postive rate FPR)</p><p>纵轴：真正类率(true postive rate TPR)</p><p><img src="https://upload-images.jianshu.io/upload_images/2394427-5f11fd1e6af07393?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt="ROC Curve"></p><p><strong>AUC值</strong></p><p>上面都是理论，看起来很迷糊，这里举个真实应用的实例，加强理解。</p><p>对于那些不熟悉的人，我将解释精确度和召回率，对于那些熟悉的人，我将在比较精确召回曲线时解释文献中的一些混淆。</p><p>下面从图像分类的角度举个例子：</p><p>假设现在有这样一个测试集，测试集中的图片只由大雁和飞机两种图片组成，如下图所示： </p><p><img src="https://sanchom.files.wordpress.com/2011/08/collection.png"></p><p>假设你的分类系统最终的目的是：能取出测试集中所有飞机的图片，而不是大雁的图片。</p><p>现在做如下的定义： </p><p>True positives（TP，真正） : 飞机的图片被正确的识别成了飞机。 </p><p>True negatives（TN，真负）: 大雁的图片没有被识别出来，系统正确地认为它们是大雁。 </p><p>False positives（FP，假正）: 大雁的图片被错误地识别成了飞机。 </p><p>False negatives（FN，假负）: 飞机的图片没有被识别出来，系统错误地认为它们是大雁。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/440px-Precisionrecall.svg.png" alt="Precision and recall"></p><p><strong>实战</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&#x27;&#x27;&#x27;In binary classification settings&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment">######### Create simple data ##########</span><br><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm, datasets<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>iris = datasets.load_iris()<br>X = iris.data<br>y = iris.target<br><br><span class="hljs-comment"># Add noisy features</span><br>random_state = np.random.RandomState(<span class="hljs-number">0</span>)<br>n_samples, n_features = X.shape<br>X = np.c_[X, random_state.randn(n_samples, <span class="hljs-number">200</span> * n_features)]<br><br><span class="hljs-comment"># Limit to the two first classes, and split into training and test</span><br>X_train, X_test, y_train, y_test = train_test_split(X[y &lt; <span class="hljs-number">2</span>], y[y &lt; <span class="hljs-number">2</span>],<br>                                                    test_size=<span class="hljs-number">.5</span>,<br>                                                    random_state=random_state)<br><br><span class="hljs-comment"># Create a simple classifier</span><br>classifier = svm.LinearSVC(random_state=random_state)<br>classifier.fit(X_train, y_train)<br>y_score = classifier.decision_function(X_test)<br><br><br><span class="hljs-comment">######## Compute the average precision score ######## </span><br><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> average_precision_score<br>average_precision = average_precision_score(y_test, y_score)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Average precision-recall score: &#123;0:0.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>      average_precision))<br>  <br><br><span class="hljs-comment">######## Plot the Precision-Recall curve   ######</span><br>  <br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_recall_curve<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>precision, recall, _ = precision_recall_curve(y_test, y_score)<br><br>plt.step(recall, precision, color=<span class="hljs-string">&#x27;b&#x27;</span>, alpha=<span class="hljs-number">0.2</span>,<br>         where=<span class="hljs-string">&#x27;post&#x27;</span>)<br>plt.fill_between(recall, precision, step=<span class="hljs-string">&#x27;post&#x27;</span>, alpha=<span class="hljs-number">0.2</span>,<br>                 color=<span class="hljs-string">&#x27;b&#x27;</span>)<br><br>plt.xlabel(<span class="hljs-string">&#x27;Recall&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Precision&#x27;</span>)<br>plt.ylim([<span class="hljs-number">0.0</span>, <span class="hljs-number">1.05</span>])<br>plt.xlim([<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>])<br>plt.title(<span class="hljs-string">&#x27;2-class Precision-Recall curve: AP=&#123;0:0.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>          average_precision))<br>plt.show()<br></code></pre></td></tr></table></figure><p><strong>参考资料</strong></p><ul><li><p><a href="http://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/">Accuracy, Precision, Recall &amp; F1 Score: Interpretation of Performance Measures</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision and recall</a></p></li><li><p><a href="https://sanchom.wordpress.com/tag/average-precision/">average precision</a></p></li><li><p><a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html">Precision-Recall</a></p></li><li><p><a href="https://blog.csdn.net/hysteric314/article/details/54093734">【YOLO学习】召回率（Recall），精确率（Precision），平均正确率（Average_precision(AP) ），交除并（Intersection-over-Union（IoU））</a></p></li><li><p><a href="https://blog.csdn.net/u014380165/article/details/77493978">Precision，Recall，F1score，Accuracy的理解</a></p></li><li><p><a href="https://www.jianshu.com/p/be2e037900a1">ROC、Precision、Recall、TPR、FPR理解</a></p></li><li><p><a href="http://bookshadow.com/weblog/2014/06/10/precision-recall-f-measure/">推荐系统评测指标—准确率(Precision)、召回率(Recall)、F值(F-Measure) </a></p></li><li><p><a href="http://www.cnblogs.com/dlml/p/4403482.html">机器学习之分类器性能指标之ROC曲线、AUC值</a></p></li></ul><h2 id="正则化方法"><a href="#正则化方法" class="headerlink" title="正则化方法"></a>正则化方法</h2><ul><li><p>L1 范数</p></li><li><p>L2 范数</p></li><li><p>数据集增广</p></li><li><p>Dropout</p></li><li><p>Batch Normaliztion</p></li></ul><p><strong>参考资料</strong></p><ul><li>[<a href="https://www.cnblogs.com/maybe2030/p/9231231.html">Deep Learning] 正则化</a></li></ul><h3 id="L1和L2正则化"><a href="#L1和L2正则化" class="headerlink" title="L1和L2正则化"></a>L1和L2正则化</h3><p>目的：降低损失函数</p><p>机器学习中几乎都可以看到损失函数后面会添加一个额外项，常用的额外项一般有两种，一般英文称作ℓ1-norm和ℓ2-norm，中文称作L1正则化和L2正则化，或者L1范数和L2范数。</p><p>L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓『惩罚』是指对损失函数中的某些参数做一些限制。对于线性回归模型，使用L1正则化的模型建叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）。下图是Python中Lasso回归的损失函数，式中加号后面一项α||w||1即为L1正则化项。</p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0003.png" alt="Logistic Regression.png"></p><p>下图是Python中Ridge回归的损失函数，式中加号后面一项即为L2正则化项。</p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0004.png" alt="Logistic Regression.png"></p><p>一般回归分析中回归w表示特征的系数，从上式可以看到正则化项是对系数做了处理（限制）。L1正则化和L2正则化的说明如下：</p><ul><li>L1正则化是指权值向量w中各个元素的绝对值之和，通常表示为||w||1</li><li>L2正则化是指权值向量w中各个元素的平方和然后再求平方根（可以看到Ridge回归的L2正则化项有平方符号），通常表示为||w||2<br>一般都会在正则化项之前添加一个系数，Python中用α表示，一些文章也用λ表示。这个系数需要用户指定。</li></ul><p>那添加L1和L2正则化有什么用？下面是L1正则化和L2正则化的作用，这些表述可以在很多文章中找到。</p><ul><li>L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择</li><li>L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合</li></ul><p><strong>稀疏模型与特征选择</strong></p><p>上面提到L1正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择。为什么要生成一个稀疏矩阵？</p><p>稀疏矩阵指的是很多元素为0，只有少数元素是非零值的矩阵，即得到的线性回归模型的大部分系数都是0. 通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，或者贡献微小（因为它们前面的系数是0或者是很小的值，即使去掉对模型也没有什么影响），此时我们就可以只关注系数是非零值的特征。这就是稀疏模型与特征选择的关系。</p><p><strong>L1和L2正则化的直观理解</strong></p><p>这部分内容将解释为什么L1正则化可以产生稀疏模型（L1是怎么让系数等于零的），以及为什么L2正则化可以防止过拟合。</p><p>L1正则化和特征选择<br>假设有如下带L1正则化的损失函数：</p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0010.png" alt="Logistic Regression.png"></p><p>其中J0是原始的损失函数，加号后面的一项是L1正则化项，α是正则化系数。注意到L1正则化是权值的绝对值之和，J是带有绝对值符号的函数，因此J是不完全可微的。机器学习的任务就是要通过一些方法（比如梯度下降）求出损失函数的最小值。当我们在原始损失函数J0后添加L1正则化项时，相当于对J0做了一个约束。令L&#x3D;α∑w|w|，则J&#x3D;J0+L，此时我们的任务变成在L约束下求出J0取最小值的解。考虑二维的情况，即只有两个权值w1和w2，此时L&#x3D;|w1|+|w2|对于梯度下降法，求解J0的过程可以画出等值线，同时L1正则化的函数L也可以在w1w2的二维平面上画出来。如下图：</p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0005.png" alt="Logistic Regression.png"><br>图1 L1正则化</p><p>图中等值线是J0的等值线，黑色方形是L函数的图形。在图中，当J0等值线与L图形首次相交的地方就是最优解。上图中J0与L在L的一个顶点处相交，这个顶点就是最优解。注意到这个顶点的值是(w1,w2)&#x3D;(0,w)。可以直观想象，因为L函数有很多『突出的角』（二维情况下四个，多维情况下更多），J0与这些角接触的机率会远大于与L其它部位接触的机率，而在这些角上，会有很多权值等于0，这就是为什么L1正则化可以产生稀疏模型，进而可以用于特征选择。</p><p>而正则化前面的系数α，可以控制L图形的大小。α越小，L的图形越大（上图中的黑色方框）；α越大，L的图形就越小，可以小到黑色方框只超出原点范围一点点，这是最优点的值(w1,w2)&#x3D;(0,w)中的w可以取到很小的值。</p><p>类似，假设有如下带L2正则化的损失函数： </p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0011.png" alt="Logistic Regression.png"></p><p>同样可以画出它们在二维平面上的图形，如下：</p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0006.png" alt="Logistic Regression.png"><br>图2 L2正则化</p><p>二维平面下L2正则化的函数图形是个圆，与方形相比，被磨去了棱角。因此J0与L相交时使得w1或w2等于零的机率小了许多，这就是为什么L2正则化不具有稀疏性的原因。</p><p>注：以二维平面举例，借助可视化L1和L2，可知L1正则化具有稀疏性。</p><p><strong>L2正则化和过拟合</strong></p><p>拟合过程中通常都倾向于让权值尽可能小，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，专业一点的说法是『抗扰动能力强』。</p><p>那为什么L2正则化可以获得值很小的参数？</p><p>以线性回归中的梯度下降法为例。假设要求的参数为θ，hθ(x)是我们的假设函数，那么线性回归的代价函数如下： </p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0007.png" alt="Logistic Regression.png"></p><p>那么在梯度下降法中，最终用于迭代计算参数θ的迭代式为： </p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0008.png" alt="Logistic Regression.png"></p><p>其中α是learning rate. 上式是没有添加L2正则化项的迭代公式，如果在原始代价函数之后添加L2正则化，则迭代公式会变成下面的样子： </p><p><img src="F:/Projects/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%E8%B5%84%E6%96%99%E5%A4%A7%E5%85%A8/Deep-Learning-Interview-Book/docs/imgs/DLIB-0009.png" alt="Logistic Regression.png"></p><p>其中λ就是正则化参数。从上式可以看到，与未添加L2正则化的迭代公式相比，每一次迭代，θj都要先乘以一个小于1的因子，从而使得θj不断减小，因此总得来看，θ是不断减小的。<br>最开始也提到L1正则化一定程度上也可以防止过拟合。之前做了解释，当L1的正则化系数很小时，得到的最优解会很小，可以达到和L2正则化类似的效果。</p><p>L2正则化参数</p><p>从上述公式可以看到，λ越大，θj衰减得越快。另一个理解可以参考图2，λ越大，L2圆的半径越小，最后求得代价函数最值时各参数也会变得很小。</p><h3 id="L1-和-L2-正则化的区别"><a href="#L1-和-L2-正则化的区别" class="headerlink" title="L1 和 L2 正则化的区别"></a>L1 和 L2 正则化的区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="机器学习中常常提到的正则化到底是什么意思？"><a href="#机器学习中常常提到的正则化到底是什么意思？" class="headerlink" title="机器学习中常常提到的正则化到底是什么意思？"></a>机器学习中常常提到的正则化到底是什么意思？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/20924039">机器学习中常常提到的正则化到底是什么意思？</a></li></ul><h3 id="为什么-L2-正则化可以防止过拟合？"><a href="#为什么-L2-正则化可以防止过拟合？" class="headerlink" title="为什么 L2 正则化可以防止过拟合？"></a>为什么 L2 正则化可以防止过拟合？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h2><h3 id="基本原理-21"><a href="#基本原理-21" class="headerlink" title="基本原理"></a>基本原理</h3><p><strong>过拟合（Over-Fitting）</strong></p><p>高方差</p><p>在训练集上误差小，但在测试集上误差大，我们将这种情况称为高方差（high variance），也叫过拟合。</p><p><strong>欠拟合（Under-Fitting）</strong></p><p>在训练集上训练效果不好（测试集上也不好），准确率不高，我们将这种情况称为高偏差（high bias），也叫欠拟合。</p><p><img src="https://testerhome.com/uploads/photo/2017/ba5ebeb8-1af7-4dfa-aeba-6bb36c056aff.png!large"></p><h3 id="如何防止过拟合？"><a href="#如何防止过拟合？" class="headerlink" title="如何防止过拟合？"></a>如何防止过拟合？</h3><ul><li>数据增广（Data Augmentation）</li><li>正则化（L0正则、L1正则和L2正则），也叫限制权值Weight-decay</li><li>Dropout</li><li>Early Stopping</li><li>简化模型</li><li>增加噪声</li><li>Bagging</li><li>贝叶斯方法</li><li>决策树剪枝</li><li>集成方法，随机森林</li><li>Batch Normalization</li></ul><h3 id="如何防止欠拟合？"><a href="#如何防止欠拟合？" class="headerlink" title="如何防止欠拟合？"></a>如何防止欠拟合？</h3><ul><li>添加新特征</li><li>添加多项式特征</li><li>减少正则化参数</li><li>增加网络复杂度</li><li>使用集成学习方法，如Bagging</li></ul><h2 id="精确率（Precision）和召回率（Recall）"><a href="#精确率（Precision）和召回率（Recall）" class="headerlink" title="精确率（Precision）和召回率（Recall）"></a>精确率（Precision）和召回率（Recall）</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/19645541">如何解释召回率与精确率？</a></li><li><a href="https://www.cnblogs.com/taro/p/8643335.html">分类–精确率和召回率</a></li></ul><h2 id="AUC-和-ROC"><a href="#AUC-和-ROC" class="headerlink" title="AUC 和 ROC"></a>AUC 和 ROC</h2><h3 id="基本原理-22"><a href="#基本原理-22" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="如何绘制ROC曲线？"><a href="#如何绘制ROC曲线？" class="headerlink" title="如何绘制ROC曲线？"></a>如何绘制ROC曲线？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="ROC曲线下面积表示什么？"><a href="#ROC曲线下面积表示什么？" class="headerlink" title="ROC曲线下面积表示什么？"></a>ROC曲线下面积表示什么？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="手撕-AUC-曲面面积代码"><a href="#手撕-AUC-曲面面积代码" class="headerlink" title="手撕 AUC 曲面面积代码"></a>手撕 AUC 曲面面积代码</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="梯度弥散和梯度爆炸"><a href="#梯度弥散和梯度爆炸" class="headerlink" title="梯度弥散和梯度爆炸"></a>梯度弥散和梯度爆炸</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="什么是参数范数惩罚？"><a href="#什么是参数范数惩罚？" class="headerlink" title="什么是参数范数惩罚？"></a>什么是参数范数惩罚？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="为什么要进行归一化？优点？"><a href="#为什么要进行归一化？优点？" class="headerlink" title="为什么要进行归一化？优点？"></a>为什么要进行归一化？优点？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="CCA和PCA的区别"><a href="#CCA和PCA的区别" class="headerlink" title="CCA和PCA的区别"></a>CCA和PCA的区别</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h2><h3 id="基本原理-23"><a href="#基本原理-23" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="Softmax是和什么loss-function配合使用？"><a href="#Softmax是和什么loss-function配合使用？" class="headerlink" title="Softmax是和什么loss function配合使用？"></a>Softmax是和什么loss function配合使用？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="Softmax代码实现"><a href="#Softmax代码实现" class="headerlink" title="Softmax代码实现"></a>Softmax代码实现</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="通俗解释一下信息熵"><a href="#通俗解释一下信息熵" class="headerlink" title="通俗解释一下信息熵"></a>通俗解释一下信息熵</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="如何加快梯度下降收敛速度？"><a href="#如何加快梯度下降收敛速度？" class="headerlink" title="如何加快梯度下降收敛速度？"></a>如何加快梯度下降收敛速度？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="如何解决正负样本数量不均衡？"><a href="#如何解决正负样本数量不均衡？" class="headerlink" title="如何解决正负样本数量不均衡？"></a>如何解决正负样本数量不均衡？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="如何解决异常值问题？"><a href="#如何解决异常值问题？" class="headerlink" title="如何解决异常值问题？"></a>如何解决异常值问题？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="机器学习中使用正则化来防止过拟合是什么原理？"><a href="#机器学习中使用正则化来防止过拟合是什么原理？" class="headerlink" title="机器学习中使用正则化来防止过拟合是什么原理？"></a>机器学习中使用正则化来防止过拟合是什么原理？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/20700829">机器学习中使用正则化来防止过拟合是什么原理？</a></li></ul><h2 id="机器学习中常常提到的正则化到底是什么意思？-1"><a href="#机器学习中常常提到的正则化到底是什么意思？-1" class="headerlink" title="机器学习中常常提到的正则化到底是什么意思？"></a>机器学习中常常提到的正则化到底是什么意思？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/20924039">机器学习中常常提到的正则化到底是什么意思？</a></li></ul><h2 id="梯度下降陷入局部最优有什么解决办法"><a href="#梯度下降陷入局部最优有什么解决办法" class="headerlink" title="梯度下降陷入局部最优有什么解决办法"></a>梯度下降陷入局部最优有什么解决办法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="聚类算法中的距离度量有哪些？"><a href="#聚类算法中的距离度量有哪些？" class="headerlink" title="聚类算法中的距离度量有哪些？"></a>聚类算法中的距离度量有哪些？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p>常见的距离度量：欧氏距离、曼哈顿距离、夹角余弦、切比雪夫距离、汉明距离</p><h2 id="KL-散度和交叉熵的区别"><a href="#KL-散度和交叉熵的区别" class="headerlink" title="KL 散度和交叉熵的区别"></a>KL 散度和交叉熵的区别</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="降维的方法都有哪些？"><a href="#降维的方法都有哪些？" class="headerlink" title="降维的方法都有哪些？"></a>降维的方法都有哪些？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计算机视觉</title>
    <link href="/2022/07/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    <url>/2022/07/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</url>
    
    <content type="html"><![CDATA[<h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><h2 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h2><p>IoU（Intersection over Union），又称重叠度&#x2F;交并比。</p><p><strong>1 NMS</strong>：当在图像中预测多个proposals、pred bboxes时，由于预测的结果间可能存在高冗余（即同一个目标可能被预测多个矩形框），因此可以过滤掉一些彼此间高重合度的结果；具体操作就是根据各个bbox的score降序排序，剔除与高score bbox有较高重合度的低score bbox，那么重合度的度量指标就是IoU；</p><p><strong>2 mAP</strong>：得到检测算法的预测结果后，需要对pred bbox与gt bbox一起评估检测算法的性能，涉及到的评估指标为mAP，那么当一个pred bbox与gt bbox的重合度较高（如IoU score &gt; 0.5），且分类结果也正确时，就可以认为是该pred bbox预测正确，这里也同样涉及到IoU的概念；</p><p>提到IoU，大家都知道怎么回事，讲起来也都头头是道，我拿两个图示意下（以下两张图都不是本人绘制）：</p><p><img src="https://pic2.zhimg.com/80/v2-8fb0aa2eebc1931432eb0ed92059d2c1_hd.jpg" alt="img"></p><p>绿框：gt bbox；</p><p>红框：pred bbox；</p><p>那么IoU的计算如下：</p><p><img src="https://pic2.zhimg.com/80/v2-215e95291d2e4129206da27e7f5de6e9_hd.jpg" alt="img"></p><p>简单点说，就是<strong>gt bbox、pred bbox交集的面积 &#x2F; 二者并集的面积</strong>；</p><p>好了，现在理解IoU的原理和计算方法了，就应该思考如何函数实现了，这也是我写本笔记的原因；</p><p>有次面试实习生的时候，一位同学讲各类目标检测算法头头是道，说到自己复现某某算法的mAP高达多少多少，问完他做的各种改进后，觉得小伙子还是挺不错的；</p><p>后来我是想着问问mAP的概念吧，但又觉得有点太复杂，不容易一下讲清楚细节，那就问问IoU吧，结果那位小朋友像傻逼一样看着我，说就是两个bbox的交并比啊，我说那要不你写段伪代码实现下吧，既然简单的话，应该实现起来还是很快的（一般我们也都会有这么个写伪代码的面试步骤，考考动手能力和思考能力吧）；然后那位自信满满的小伙子就立马下手开始写了，一般听完题目直接写代码的面试者，有两种可能性：</p><p>1 确实写过类似的代码，已经知道里面有哪些坑了，直接信手拈来；</p><p>2 没写过类似的代码，且把问题考虑简单化了；</p><p>我说你不用着急写，可以先想想两个bbox出现交集的各种情况，如两个bbox如何摆放，位置，以及二者不存在交集的情况等等（看到IoU的具体代码后，你会发现虽然只有寥寥几行代码，但其实已经处理好此类情况了），然后他画了几个图，瞬间表情严肃起来，然后我继续说你还得考虑一个bbox包围另一个bbox；两bbox并不是边角相交，而是两条边相交的特殊情况等等（说到这里我觉得自己也坏坏滴，故意把人家往歪路上牵。。。但主要是看得出来他确实不熟悉IoU的实现了），他就又画了若干种情况，最后开始写代码，刚开始还ok，写了十几行，后来越加越多，草稿纸上也涂涂改改越来越夸张，脸也越胀越红；我看了下他的代码，觉得他思路还行，考虑的还挺周全的，就给了他一个提示：你有没有考虑到你列举的这些情况，有一些可以合并的？他看了下，觉得是可以合并一些情况，就删减了部分代码，稿纸上就更乱了，然后又问他：可不可以继续合并；他就又继续思考了。。。大概是后来越想越复杂，就给我说这个原理他懂的，代码也看过，但现在确实是没能写出来；然后我安慰他，说如果没写过的话，确实是会把问题考虑简单化 &#x2F; 复杂化，不过我并不是专门考个题目刁难你，而是因为你一直都在做目标检测，所以以为IoU的原理、实现你应该会比较熟悉的，写起代码也应该没问题的；而且你的思路也挺好的，先考虑各种复杂情况，再慢慢合并一些情况，先从1到N，再回到1就行，只不过可能到了N，没考虑到如何再回到1了；</p><p>再后来，也面试过其他实习生同学，问到了IoU的实现，很可惜，好像还没有一位同学能圆满写出来的。。。当然了，可能是我有时候过于抠细节了，不利于他们的发挥吧。。。</p><p>好了，以上都是废话，看看如何实现吧；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># This is the python code for calculating bbox IoU,</span><br><span class="hljs-comment"># By running the script, we can get the IoU score between pred / gt bboxes</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Author: hzhumeng01 2018-10-19</span><br><span class="hljs-comment"># copyright @ netease, AI group</span><br><br><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function, absolute_import<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_IoU</span>(<span class="hljs-params">pred_bbox, gt_bbox</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    return iou score between pred / gt bboxes</span><br><span class="hljs-string">    :param pred_bbox: predict bbox coordinate</span><br><span class="hljs-string">    :param gt_bbox: ground truth bbox coordinate</span><br><span class="hljs-string">    :return: iou score</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># bbox should be valid, actually we should add more judgements, just ignore here...</span><br>    <span class="hljs-comment"># assert ((abs(pred_bbox[2] - pred_bbox[0]) &gt; 0) and</span><br>    <span class="hljs-comment">#         (abs(pred_bbox[3] - pred_bbox[1]) &gt; 0))</span><br>    <span class="hljs-comment"># assert ((abs(gt_bbox[2] - gt_bbox[0]) &gt; 0) and</span><br>    <span class="hljs-comment">#         (abs(gt_bbox[3] - gt_bbox[1]) &gt; 0))</span><br><br>    <span class="hljs-comment"># -----0---- get coordinates of inters</span><br>    ixmin = <span class="hljs-built_in">max</span>(pred_bbox[<span class="hljs-number">0</span>], gt_bbox[<span class="hljs-number">0</span>])<br>    iymin = <span class="hljs-built_in">max</span>(pred_bbox[<span class="hljs-number">1</span>], gt_bbox[<span class="hljs-number">1</span>])<br>    ixmax = <span class="hljs-built_in">min</span>(pred_bbox[<span class="hljs-number">2</span>], gt_bbox[<span class="hljs-number">2</span>])<br>    iymax = <span class="hljs-built_in">min</span>(pred_bbox[<span class="hljs-number">3</span>], gt_bbox[<span class="hljs-number">3</span>])<br>    iw = np.maximum(ixmax - ixmin + <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>)<br>    ih = np.maximum(iymax - iymin + <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>)<br><br>    <span class="hljs-comment"># -----1----- intersection</span><br>    inters = iw * ih<br><br>    <span class="hljs-comment"># -----2----- union, uni = S1 + S2 - inters</span><br>    uni = ((pred_bbox[<span class="hljs-number">2</span>] - pred_bbox[<span class="hljs-number">0</span>] + <span class="hljs-number">1.</span>) * (pred_bbox[<span class="hljs-number">3</span>] - pred_bbox[<span class="hljs-number">1</span>] + <span class="hljs-number">1.</span>) +<br>           (gt_bbox[<span class="hljs-number">2</span>] - gt_bbox[<span class="hljs-number">0</span>] + <span class="hljs-number">1.</span>) * (gt_bbox[<span class="hljs-number">3</span>] - gt_bbox[<span class="hljs-number">1</span>] + <span class="hljs-number">1.</span>) -<br>           inters)<br><br>    <span class="hljs-comment"># -----3----- iou</span><br>    overlaps = inters / uni<br><br>    <span class="hljs-keyword">return</span> overlaps<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_max_IoU</span>(<span class="hljs-params">pred_bboxes, gt_bbox</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    given 1 gt bbox, &gt;1 pred bboxes, return max iou score for the given gt bbox and pred_bboxes</span><br><span class="hljs-string">    :param pred_bbox: predict bboxes coordinates, we need to find the max iou score with gt bbox for these pred bboxes</span><br><span class="hljs-string">    :param gt_bbox: ground truth bbox coordinate</span><br><span class="hljs-string">    :return: max iou score</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># bbox should be valid, actually we should add more judgements, just ignore here...</span><br>    <span class="hljs-comment"># assert ((abs(gt_bbox[2] - gt_bbox[0]) &gt; 0) and</span><br>    <span class="hljs-comment">#         (abs(gt_bbox[3] - gt_bbox[1]) &gt; 0))</span><br><br>    <span class="hljs-keyword">if</span> pred_bboxes.shape[<span class="hljs-number">0</span>] &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-comment"># -----0---- get coordinates of inters, but with multiple predict bboxes</span><br>        ixmin = np.maximum(pred_bboxes[:, <span class="hljs-number">0</span>], gt_bbox[<span class="hljs-number">0</span>])<br>        iymin = np.maximum(pred_bboxes[:, <span class="hljs-number">1</span>], gt_bbox[<span class="hljs-number">1</span>])<br>        ixmax = np.minimum(pred_bboxes[:, <span class="hljs-number">2</span>], gt_bbox[<span class="hljs-number">2</span>])<br>        iymax = np.minimum(pred_bboxes[:, <span class="hljs-number">3</span>], gt_bbox[<span class="hljs-number">3</span>])<br>        iw = np.maximum(ixmax - ixmin + <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>)<br>        ih = np.maximum(iymax - iymin + <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>)<br><br>        <span class="hljs-comment"># -----1----- intersection</span><br>        inters = iw * ih<br><br>        <span class="hljs-comment"># -----2----- union, uni = S1 + S2 - inters</span><br>        uni = ((gt_bbox[<span class="hljs-number">2</span>] - gt_bbox[<span class="hljs-number">0</span>] + <span class="hljs-number">1.</span>) * (gt_bbox[<span class="hljs-number">3</span>] - gt_bbox[<span class="hljs-number">1</span>] + <span class="hljs-number">1.</span>) +<br>               (pred_bboxes[:, <span class="hljs-number">2</span>] - pred_bboxes[:, <span class="hljs-number">0</span>] + <span class="hljs-number">1.</span>) * (pred_bboxes[:, <span class="hljs-number">3</span>] - pred_bboxes[:, <span class="hljs-number">1</span>] + <span class="hljs-number">1.</span>) -<br>               inters)<br><br>        <span class="hljs-comment"># -----3----- iou, get max score and max iou index</span><br>        overlaps = inters / uni<br>        ovmax = np.<span class="hljs-built_in">max</span>(overlaps)<br>        jmax = np.argmax(overlaps)<br><br>    <span class="hljs-keyword">return</span> overlaps, ovmax, jmax<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br><br>    <span class="hljs-comment"># test1</span><br>    pred_bbox = np.array([<span class="hljs-number">50</span>, <span class="hljs-number">50</span>, <span class="hljs-number">90</span>, <span class="hljs-number">100</span>])   <span class="hljs-comment"># top-left: &lt;50, 50&gt;, bottom-down: &lt;90, 100&gt;, &lt;x-axis, y-axis&gt;</span><br>    gt_bbox = np.array([<span class="hljs-number">70</span>, <span class="hljs-number">80</span>, <span class="hljs-number">120</span>, <span class="hljs-number">150</span>])<br>    <span class="hljs-built_in">print</span> (get_IoU(pred_bbox, gt_bbox))<br>    <br>    <span class="hljs-comment"># test2</span><br>    pred_bboxes = np.array([[<span class="hljs-number">15</span>, <span class="hljs-number">18</span>, <span class="hljs-number">47</span>, <span class="hljs-number">60</span>],<br>                          [<span class="hljs-number">50</span>, <span class="hljs-number">50</span>, <span class="hljs-number">90</span>, <span class="hljs-number">100</span>],<br>                          [<span class="hljs-number">70</span>, <span class="hljs-number">80</span>, <span class="hljs-number">120</span>, <span class="hljs-number">145</span>],<br>                          [<span class="hljs-number">130</span>, <span class="hljs-number">160</span>, <span class="hljs-number">250</span>, <span class="hljs-number">280</span>],<br>                          [<span class="hljs-number">25.6</span>, <span class="hljs-number">66.1</span>, <span class="hljs-number">113.3</span>, <span class="hljs-number">147.8</span>]])<br>    gt_bbox = np.array([<span class="hljs-number">70</span>, <span class="hljs-number">80</span>, <span class="hljs-number">120</span>, <span class="hljs-number">150</span>])<br>    <span class="hljs-built_in">print</span> (get_max_IoU(pred_bboxes, gt_bbox))<br></code></pre></td></tr></table></figure><p>其实计算bbox间IoU唯一的难点就在计算intersection，代码的实现很简单：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">ixmin = <span class="hljs-built_in">max</span>(pred_bbox[<span class="hljs-number">0</span>], gt_bbox[<span class="hljs-number">0</span>])<br>iymin = <span class="hljs-built_in">max</span>(pred_bbox[<span class="hljs-number">1</span>], gt_bbox[<span class="hljs-number">1</span>])<br>ixmax = <span class="hljs-built_in">min</span>(pred_bbox[<span class="hljs-number">2</span>], gt_bbox[<span class="hljs-number">2</span>])<br>iymax = <span class="hljs-built_in">min</span>(pred_bbox[<span class="hljs-number">3</span>], gt_bbox[<span class="hljs-number">3</span>])<br>iw = np.maximum(ixmax - ixmin + <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>)<br>ih = np.maximum(iymax - iymin + <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>)<br></code></pre></td></tr></table></figure><p>比较厉害的就是，以上短短六行代码就可以囊括所有pred bbox与gt bbox间的关系，不管是bboxes间相交 &#x2F; 不相交，各种相交形式等等；我们在画图分析两个bbox间的关系时，会考虑各种情况，动手实践时会发现很复杂，是因为我们<strong>陷入了一种先入为主的思维</strong>，就是pred bbox与gt bbox有一个先后顺序，即我们认定了pred bbox为画图中的第一个bbox，gt bbox为第二个，这样在二者有不同位置关系时，就得考虑各种坐标判断情况，但若此时交换二者位置，其实并不影响我们计算IoU；</p><p>以上六行代码也印证了这个观点，直接计算两个bbox的相交边框坐标即可，若不相交得到的结果中，必有ixmax &lt; ixmin、iymax - iymin其一成立，此时iw、ih就为0了；</p><p>好了，以上就是IoU的计算，原理比较简单，具体分析比较复杂，实现却异常简单，但通过对问题的深入分析，也能加深我们对知识的理解；</p><p>代码我传到github上了，比较简单：<a href="https://github.com/humengdoudou/object_detection_mAP/blob/master/IoU_demo.py">IoU_demo.py</a></p><p><strong>参考资料</strong></p><ul><li><p><a href="https://zhuanlan.zhihu.com/p/47189358">目标检测番外篇(1)_IoU</a></p></li><li><p><a href="https://blog.csdn.net/u014061630/article/details/82818112">目标检测之 IoU</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/70768666">Detection基础模块之（一）IoU</a></p></li></ul><h3 id="如何计算-mIoU？"><a href="#如何计算-mIoU？" class="headerlink" title="如何计算 mIoU？"></a>如何计算 mIoU？</h3><p>Mean Intersection over Union(MIoU，均交并比)，为语义分割的标准度量。其计算两个集合的交集和并集之比，在语义分割问题中，这两个集合为真实值（ground truth）和预测值（predicted segmentation）。这个比例可以变形为TP（交集）比上TP、FP、FN之和（并集）。在每个类上计算IoU，然后取平均。<br>$$<br>MIoU&#x3D;\frac{1}{k+1}\sum^{k}<em>{i&#x3D;0}{\frac{p</em>{ii}}{\sum_{j&#x3D;0}^{k}{p_{ij}+\sum_{j&#x3D;0}^{k}{p_{ji}-p_{ii}}}}}<br>$$<br>pij表示真实值为i，被预测为j的数量。</p><p><strong>直观理解</strong></p><p><img src="/2022/07/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/DLIB-0020.png"></p><p>红色圆代表真实值，黄色圆代表预测值。橙色部分为两圆交集部分。</p><ul><li>MPA（Mean Pixel Accuracy，均像素精度）：计算橙色与红色圆的比例；</li><li>MIoU：计算两圆交集（橙色部分）与两圆并集（红色+橙色+黄色）之间的比例，理想情况下两圆重合，比例为1。</li></ul><p><strong>Tensorflow源码解析</strong></p><p>Tensorflow主要用<code>tf.metrics.mean_iou</code>来计算mIoU，下面解析源码：</p><p><strong>第一步：计算混淆矩阵</strong></p><p>混淆矩阵例子</p><p><img src="/2022/07/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/DLIB-0021.jpg" alt="img"></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 主要代码</span><br>def confusion_matrix(labels, predictions, <span class="hljs-attribute">num_classes</span>=None, <span class="hljs-attribute">dtype</span>=dtypes.int32,<br>                     <span class="hljs-attribute">name</span>=None, <span class="hljs-attribute">weights</span>=None): <br>    # 例子：labels =     [0, 1, 2, 0, 3]<br>    #      predictions =[0, 1, 1, 3, 3]<br>    <span class="hljs-keyword">if</span> num_classes is None: # 不指定类别个数，就以labels或者predictions最大的指定,即4<br>      num_classes = math_ops.maximum(math_ops.reduce_max(predictions),<br>                                     math_ops.reduce_max(labels)) + 1 <br>    <span class="hljs-keyword">else</span>:<br>      num_classes_int64 = math_ops.cast(num_classes, dtypes.int64)<br>      labels = control_flow_ops.with_dependencies(<br>          [check_ops.assert_less(<br>              labels, num_classes_int64, <span class="hljs-attribute">message</span>=<span class="hljs-string">&#x27;`labels` out of bound&#x27;</span>)],<br>          labels)<br>      predictions = control_flow_ops.with_dependencies(<br>          [check_ops.assert_less(<br>              predictions, num_classes_int64,<br>              <span class="hljs-attribute">message</span>=<span class="hljs-string">&#x27;`predictions` out of bound&#x27;</span>)],<br>          predictions)<br><br>    <span class="hljs-keyword">if</span> weights is <span class="hljs-keyword">not</span> None:<br>      predictions.get_shape().assert_is_compatible_with(weights.get_shape())<br>      weights = math_ops.cast(weights, dtype)<br><br>    shape = array_ops.stack([num_classes, num_classes])<br>    indices = array_ops.stack([labels, predictions], <span class="hljs-attribute">axis</span>=1) <br>    # indices = [[0,0],[1,1],[2,1],[0,3],[3,3]]<br>    values = (array_ops.ones_like(predictions, dtype)<br>              <span class="hljs-keyword">if</span> weights is None <span class="hljs-keyword">else</span> weights)<br>    # 对应位置的values，若不指定，则全为1<br>    cm_sparse = sparse_tensor.SparseTensor(<br>        <span class="hljs-attribute">indices</span>=indices, <span class="hljs-attribute">values</span>=values, <span class="hljs-attribute">dense_shape</span>=math_ops.to_int64(shape))<br>    # 稀疏张量，指定indices位置为指定value，其他位置为0<br>    # 多次指定一个位置，value为多次相加的结果<br>    zero_matrix = array_ops.zeros(math_ops.to_int32(shape), dtype)<br><br>    return sparse_ops.sparse_add(zero_matrix, cm_sparse)<br></code></pre></td></tr></table></figure><p>SparseTensor例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br>a = tf.SparseTensor(indices=[[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], values=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], dense_shape=[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>zero_m = array_ops.zeros(math_ops.to_int32([<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]),dtype=tf.int32) <br>r = sparse_ops.sparse_add(zero_m, a)<br>sess = tf.Session(config=tf.ConfigProto(device_count=&#123;<span class="hljs-string">&#x27;cpu&#x27;</span>:<span class="hljs-number">0</span>&#125;))<br>sess.run(r) <br><span class="hljs-comment"># array([[2, 0, 0, 0],</span><br><span class="hljs-comment">#       [0, 0, 1, 0],</span><br><span class="hljs-comment">#       [0, 0, 0, 0]], dtype=int32)</span><br></code></pre></td></tr></table></figure><p><strong>第二步：计算mIoU</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_mean_iou</span>(<span class="hljs-params">total_cm, name</span>):<br>  <span class="hljs-string">&quot;&quot;&quot;Compute the mean intersection-over-union via the confusion matrix.&quot;&quot;&quot;</span><br>  sum_over_row = math_ops.to_float(math_ops.reduce_sum(total_cm, <span class="hljs-number">0</span>))<br>  sum_over_col = math_ops.to_float(math_ops.reduce_sum(total_cm, <span class="hljs-number">1</span>))<br>  cm_diag = math_ops.to_float(array_ops.diag_part(total_cm)) <span class="hljs-comment"># 交集</span><br>  denominator = sum_over_row + sum_over_col - cm_diag <span class="hljs-comment"># 分母，即并集</span><br><br>  <span class="hljs-comment"># The mean is only computed over classes that appear in the</span><br>  <span class="hljs-comment"># label or prediction tensor. If the denominator is 0, we need to</span><br>  <span class="hljs-comment"># ignore the class.</span><br>  num_valid_entries = math_ops.reduce_sum(<br>      math_ops.cast(<br>          math_ops.not_equal(denominator, <span class="hljs-number">0</span>), dtype=dtypes.float32)) <span class="hljs-comment"># 类别个数</span><br><br>  <span class="hljs-comment"># If the value of the denominator is 0, set it to 1 to avoid</span><br>  <span class="hljs-comment"># zero division.</span><br>  denominator = array_ops.where(<br>      math_ops.greater(denominator, <span class="hljs-number">0</span>), denominator,<br>      array_ops.ones_like(denominator))<br>  iou = math_ops.div(cm_diag, denominator) <span class="hljs-comment"># 各类IoU</span><br><br>  <span class="hljs-comment"># If the number of valid entries is 0 (no classes) we return 0.</span><br>  result = array_ops.where(<br>      math_ops.greater(num_valid_entries, <span class="hljs-number">0</span>),<br>      math_ops.reduce_sum(iou, name=name) / num_valid_entries, <span class="hljs-number">0</span>) <span class="hljs-comment">#mIoU</span><br>  <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><p>通过<code>tf.metrics.mean_iou</code>的API可以得到mIoU，但并没有把各类IoU释放出来，为了计算各类IoU，可以修改上面的代码，获取IoU中间结果，也可以用weight的方式变相计算。</p><p>基本思路就是把只保留一类的IoU，其他类IoU置零，然后最后将<code>mIoU * num_classes</code>就可以了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">tp_position = tf.equal(tf.to_int32(labels), tf.to_int32(predictions))<br>label_0_weight = tf.where((tp_position &amp; tf.not_equal(labels, <span class="hljs-number">0</span>)), tf.zeros_like(labels),<br>                                  tf.ones_like(labels))<br><span class="hljs-comment">## 混淆矩阵对角线上只保留一类非0，其他类都置0</span><br>metric_map[<span class="hljs-string">&#x27;IOU/class_0_iou&#x27;</span>] = tf.metrics.mean_iou(<br>            predictions, labels, dataset.num_classes, weights=label_0_weight)<br><span class="hljs-comment">## 结果是0类IoU/num_classes</span><br></code></pre></td></tr></table></figure><p><strong>Pytorch源码解析</strong></p><p>Pytorch基本计算思路和上面是一样的，代码很简洁，就不过多介绍了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">IOUMetric</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Class to calculate mean-iou using fast_hist method</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes</span>):<br>        self.num_classes = num_classes<br>        self.hist = np.zeros((num_classes, num_classes))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_fast_hist</span>(<span class="hljs-params">self, label_pred, label_true</span>):<br>        mask = (label_true &gt;= <span class="hljs-number">0</span>) &amp; (label_true &lt; self.num_classes)<br>        hist = np.bincount(<br>            self.num_classes * label_true[mask].astype(<span class="hljs-built_in">int</span>) +<br>            label_pred[mask], minlength=self.num_classes ** <span class="hljs-number">2</span>).reshape(self.num_classes, self.num_classes)<br>        <span class="hljs-keyword">return</span> hist<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add_batch</span>(<span class="hljs-params">self, predictions, gts</span>):<br>        <span class="hljs-keyword">for</span> lp, lt <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, gts):<br>            self.hist += self._fast_hist(lp.flatten(), lt.flatten())<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">self</span>):<br>        acc = np.diag(self.hist).<span class="hljs-built_in">sum</span>() / self.hist.<span class="hljs-built_in">sum</span>()<br>        acc_cls = np.diag(self.hist) / self.hist.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br>        acc_cls = np.nanmean(acc_cls)<br>        iu = np.diag(self.hist) / (self.hist.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>) + self.hist.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>) - np.diag(self.hist))<br>        mean_iu = np.nanmean(iu)<br>        freq = self.hist.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>) / self.hist.<span class="hljs-built_in">sum</span>()<br>        fwavacc = (freq[freq &gt; <span class="hljs-number">0</span>] * iu[freq &gt; <span class="hljs-number">0</span>]).<span class="hljs-built_in">sum</span>()<br>        <span class="hljs-keyword">return</span> acc, acc_cls, iu, mean_iu, fwavacc<br></code></pre></td></tr></table></figure><p><strong>Python 简版实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#RT:RightTop</span><br><span class="hljs-comment">#LB:LeftBottom</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">IOU</span>(<span class="hljs-params">rectangle A, rectangleB</span>):<br>    W = <span class="hljs-built_in">min</span>(A.RT.x, B.RT.x) - <span class="hljs-built_in">max</span>(A.LB.x, B.LB.x)<br>    H = <span class="hljs-built_in">min</span>(A.RT.y, B.RT.y) - <span class="hljs-built_in">max</span>(A.LB.y, B.LB.y)<br>    <span class="hljs-keyword">if</span> W &lt;= <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> H &lt;= <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    SA = (A.RT.x - A.LB.x) * (A.RT.y - A.LB.y)<br>    SB = (B.RT.x - B.LB.x) * (B.RT.y - B.LB.y)<br>    cross = W * H<br>    <span class="hljs-keyword">return</span> cross/(SA + SB - cross)<br></code></pre></td></tr></table></figure><p><strong>参考资料</strong></p><ul><li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">https://github.com/rafaelpadilla/Object-Detection-Metrics</a></li><li><a href="https://blog.csdn.net/jiongnima/article/details/84750819">mIoU（平均交并比）计算代码与逐行解析</a></li><li><a href="https://github.com/wasidennis/AdaptSegNet/blob/master/compute_iou.py">https://github.com/wasidennis/AdaptSegNet/blob/master/compute_iou.py</a></li><li><a href="https://tianws.github.io/skill/2018/10/30/miou/">mIoU源码解析</a></li></ul><h2 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h2><p>mAP定义及相关概念</p><ul><li>mAP: mean Average Precision, 即各类别AP的平均值</li><li>AP: PR曲线下面积，后文会详细讲解</li><li>PR曲线: Precision-Recall曲线</li><li>Precision: TP &#x2F; (TP + FP)</li><li>Recall: TP &#x2F; (TP + FN)</li><li>TP: IoU&gt;0.5的检测框数量（同一Ground Truth只计算一次）</li><li>FP: IoU&lt;&#x3D;0.5的检测框，或者是检测到同一个GT的多余检测框的数量</li><li>FN: 没有检测到的GT的数量</li></ul><p>本笔记介绍目标检测的一个基本概念：AP、mAP（mean Average Precision），做目标检测的同学想必对这个词语耳熟能详了，不管是Pascal VOC，还是COCO，甚至是人脸检测的wider face数据集，都使用到了AP、mAP的评估方式，那么AP、mAP到底是什么？如何计算的？</p><p>如果希望一篇笔记讲明白目标检测中的mAP，感觉自己表达能力有限，可能搞不定，但如果希望一下能明白mAP含义的，可以参照引用链接；今天主要介绍下mAP的计算方式，假定前提为已经明白了precision、recall、tp、fp等概念，当然了，不明白也没关系，下一篇介绍Pascal VOC评估工具时会再详细介绍；</p><p><strong>1 图像检索mAP</strong></p><p>那么mAP到底是什么东西，如何计算？网上已经有了很多很多资料，但其实很多感觉都讲不清楚，我看到过一个在图像检索里面介绍得最好的示意图，我们先以图像检索中的mAP为例说明，其实目标检测中mAP与之几乎一样：</p><p><img src="https://pic2.zhimg.com/80/v2-7e1dd60163df014ad08ea15388fedd51_hd.jpg" alt="img"></p><p>以上是图像检索中mAP的计算案例，简要说明下：</p><p>1 查询图片1在图像库中检索相似图像，假设图像库中有五张相似图像，表示为图片1、…、图片5，排名不分先后；</p><p>2 检索（过程略），返回了top-10图像，如上图第二行，橙色表示相似的图像，灰色为无关图像；</p><p>3 接下来就是precision、recall的计算过程了，结合上图比较容易理解；</p><p>以返回图片6的节点为例：</p><p>top-6中，有3张图像确实为相似图像，另三张图像为无关图像，因此precision &#x3D; 3 &#x2F; 6；同时，总共五张相似图像，top-6检索出来了三张，因此recall &#x3D; 3 &#x2F; 5；</p><p>4 然后计算AP，可以看右边的计算方式，可以发现是把列出来的查询率(precision)相加取平均，那么最关键的问题来了：为什么选择这几张图像的precision求平均？可惜图中并没有告诉我们原因；</p><p>但其实不难，一句话就是：<strong>选择每个recall区间内对应的最高precision</strong>；</p><p>举个栗子，以上图橙色检索案例为例，当我们只选择top-1作为检索结果返回（也即只返回一个检索结果）时，检索性能为：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs text">top-1：recall = 1 / 5、precision = 1 / 1；# 以下类推；<br>top-2：recall = 1 / 5、precision = 1 / 2；<br>top-3：recall = 2 / 5、precision = 2 / 3；<br>top-4：recall = 2 / 5、precision = 2 / 4；<br>top-5：recall = 2 / 5、precision = 2 / 5；<br>top-6：recall = 3 / 5、precision = 3 / 6；<br>top-7：recall = 3 / 5、precision = 3 / 7；<br>top-8：recall = 3 / 5、precision = 3 / 8；<br>top-9：recall = 4 / 5、precision = 4 / 9；<br>top-10：recall = 5 / 5、precision = 5 / 10；<br></code></pre></td></tr></table></figure><p>结合上面清单，先找找recall &#x3D; 1 &#x2F; 5区间下的最高precision，对应着precision &#x3D; 1 &#x2F; 1；</p><p>同理，recall &#x3D; 2 &#x2F; 5区间下的最高precision，对应着precision &#x3D; 2 &#x2F; 3；</p><p>recall &#x3D; 3 &#x2F; 5区间下的最高precision，对应着precision &#x3D; 3 &#x2F; 6；依次类推；</p><p>这样AP &#x3D; (1 &#x2F; 1 + 2 &#x2F; 3 + 3 &#x2F; 6 + 4 &#x2F; 9 + 5 &#x2F; 10) &#x2F; 5；</p><p>那么mAP是啥？计算所有检索图像返回的AP均值，对应上图就是橙、绿突图像计算AP求均值，对应红色框；</p><p>这样mAP就计算完毕啦~~~是不是很容易理解？目标检测的mAP也是类似操作了；</p><p><strong>2 目标检测中mAP计算流程</strong></p><p>这里面我引用的是一篇博文，以下内容大多参考该博文，做了一些小修改；</p><p>下面的例子也很容易理解，假设检测人脸吧，gt label表示1为人脸，0为bg，某张图像中共检出了20个pred bbox，id：1 ~ 20，并对应了confidence score，gt label也很容易获得，pred bbox与gt bbox算IoU，给定一个threshold，那么就<strong>知道该pred bbox是否为正确的预测结果了，就对应了其gt label</strong>；—- 其实下表不应该这么理解的，但我们还是先这么认为，忽略差异吧，先直捣黄龙，table 1：</p><p><img src="https://pic3.zhimg.com/80/v2-f3d821d5661e41f6bbeddea2a7ce4972_hd.jpg" alt="img"></p><p>接下来对confidence score排序，得到table 2：</p><p><img src="https://pic1.zhimg.com/80/v2-dbcb5bac2c1e97e151cfe756d5cc55e8_hd.jpg" alt="img"></p><p><em>这张表很重要，接下来的precision和recall都是依照这个表计算的﻿，那么这里的confidence score其实就和图像检索中的相似度关联上了，具体地，就是如第一节的图像检索中，虽然我们计算mAP没在乎其检索返回的先后顺序，但top1肯定是与待检索图像最相似的，对应的similarity score最高，对人脸检测而言，pred bbox的confidence score最高，也说明该bbox最有可能是人脸；</em></p><p>然后计算precision和recall，这两个标准的定义如下：</p><p><img src="https://pic1.zhimg.com/80/v2-6b533fc4b307c03992a07b08812a12e4_hd.jpg" alt="img"></p><p>上面的图看看就行，能理解就理解，不理解可以参照第一节图像检索的例子来理解；</p><p>现以返回的top-5结果为例，如table 3：</p><p><img src="https://pic1.zhimg.com/80/v2-30ee6334f6aa93f9d10889fa4a3d1a10_hd.jpg" alt="img"></p><p>在这个例子中，true positives就是指id &#x3D; 4、2的pred bbox，false positives就是指id &#x3D; 13、19、6的pred bbox。方框内圆圈外的元素（false negatives + true negatives）是相对于方框内的元素而言，在这个例子中，是指confidence score排在top-5之外的元素，即table 4：</p><p><img src="https://pic1.zhimg.com/80/v2-e01ddf90fc9862e12ae5ab0d7416bc10_hd.jpg" alt="img"></p><p>其中，false negatives是指id &#x3D; 9、16、7、20的4个pred bbox，true negatives是指id &#x3D; 1、18、5、15、10、17、12、14、8、11、3的11个pred bbox；</p><p>那么，这个例子中Precision &#x3D; 2 &#x2F; 5 &#x3D; 40%，意思是对于人脸检测而言，我们选定了5 pred bbox，其中正确的有2个，即准确率为40%；Recall &#x3D; 2 &#x2F; 6 &#x3D; 33%，意思是该图像中共有6个人脸，但是因为我们只召回了2个，所以召回率为33%；</p><p>实际的目标检测任务中，我们通常不满足只通过top-5来衡量一个模型的好坏，而是需要知道从top-1到top-N（N是所有pred bbox，本文中为20）对应的precision和recall；显然随着我们选定的pred bbox越来也多，recall一定会越来越高，而precision整体上会呈下降趋势；把recall当成横坐标，precision当成纵坐标，即可得到常用的precision-recall曲线，以上例子的precision-recall曲线如fig 1：</p><p><img src="https://pic3.zhimg.com/80/v2-46dbabe907e601580c065aa03ee1a89a_hd.jpg" alt="img"></p><p>以上图像如何计算的？可以参照第一节图像检索中的栗子，还是比较容易理解的吧；</p><p>上面的每个红点，就相当于根据table 2，按照第一节中图像检索的方式计算出来的，也可以直接参照下面的table 5，自己心里算一算；</p><p>那么按照<strong>选择每个recall区间内对应的最高precision</strong>的计算方案，各个recall区间内对应的top-precision，就刚好如fig 1中的绿色框位置，可以进一步结合table 5中的绿色框理解；</p><p>好了，那么对这张图像而言，其AP &#x3D; （1 &#x2F; 1 + 2 &#x2F; 2 + 3 &#x2F; 6 + 4 &#x2F; 7 + 5 &#x2F; 11 + 6 &#x2F; 16）&#x2F; 6；这是针对单张图像而言，所有图像也类似方式计算，那么就可以根据所有图像上的pred bbox，采用同样的方式，就计算出了所有图像上人脸这个类的AP；因为人脸检测只有一个类，如Pascal VOC这种20类的，每类都可以计算出一个AP，那么AP_total &#x2F; 20，就是mAP啦；</p><p>但是等等，有没有发现table 5中，计算方式好像跟我们讲的有一点不一样？我们继续看看；</p><p><strong>3 Pascal VOC的两套mAP评估标准</strong></p><p>Pascal VOC中对mAP的计算经历了两次迭代，一种是VOC07的计算标准，对应绿色框：</p><p>首先设定一组阈值，T &#x3D; [0、0.1、0.2、…、1]，然后对于recall大于每一个阈值Ti（比如recall &gt; 0.3），我们都会在该recall区间内得到一个对应的最大precision，这样我们就计算出了11个precision；—– 这里与上两节介绍的概念是一样的，只不过上面recall的区间是参照gt label来划分的，这里是我们人为划分的11个节点；</p><p>AP即为这11个precision的平均值，这种方法英文叫做11-point interpolated average precision；有了一个类的AP，所有类的AP均值即为mAP；</p><p>另一种是VOC10的计算标准，对应白色框：</p><p>新的计算方法假设N个pred bbox中有M个gt bbox，那么我们会得到M个recall节点（1 &#x2F; M、2 &#x2F; M、…、 M &#x2F; M），对于<strong>每个recall值 r，我们可以计算出对应（r’ &gt; r）的最大precision，然后对这M个precision值取平均即得到最后的AP值</strong>，计算方法如table 5：</p><p><img src="https://pic4.zhimg.com/80/v2-525566cf829e30dcdc4156a3ada7303f_hd.jpg" alt="img"></p><p>从VOC07的绿框、VOC10的白框对比可知，差异主要在recall &#x3D; 3 &#x2F; 6下的precision，可以发现VOC07找的top-precision是在该recall区间段内的，但<strong>VOC10相当于是向后查找的，需确保该recall阈值以后的区间内，对应的是top-precision</strong>，可知4 &#x2F; 7 &gt; 3 &#x2F; 6，因此使用4 &#x2F; 7替换了3 &#x2F; 6，其他recall阈值下的操作方式类似；</p><p><strong>那么代码的实操中，就得从按照recall阈值从后往前计算了，这样就可以一遍就梭哈出所有结果，如果按recall从前往后计算，就有很多重复性计算（不断地重复向后recall区间内查找top-precision），然后呢，就可以使用到动态规划的方式做了，理论结合实践啊有木有~~~</strong></p><p>那么VOC10下，相应的Precision-Recall曲线如fig 2，可以发现这条曲线是单调递减的，剩下的AP计算方式就与VOC07相同了：</p><p>这里还需要继续一点，<strong>VOC07是11点插值的AP方式，等于是卡了11个离散的点，划分10个区间来计算AP</strong>，但VOC10是是<strong>根据recall值变化的区间来计算的</strong>，在这个栗子里，recall只变化了6次，但如果recall变化很多次，如100次、1000次、9999次等，就可以认为是<strong>一种 “伪” 连续的方式计算</strong>了；</p><p><img src="https://pic3.zhimg.com/80/v2-f86ce8588802e5cfee2d2f09303f98d2_hd.jpg" alt="img"></p><p><strong>总结</strong>：</p><p>AP衡量的是模型在每个类别上的好坏，mAP衡量的是模型在所有类别上的好坏，得到AP后mAP的计算就变得很简单了，就是取所有类别AP的平均值。</p><p><strong>3 代码</strong></p><p>直接上代码吧，这个函数假设我们已经得到了排序好的precision、recall的list，对应上图fig 2，进一步可以参照第一节中的清单理解；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># VOC-style mAP，分为两个计算方式，之所有两个计算方式，是因为2010年后VOC更新了评估方法，因此就有了07-metric和else...</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">voc_ap</span>(<span class="hljs-params">rec, prec, use_07_metric=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    average precision calculations</span><br><span class="hljs-string">    [precision integrated to recall]</span><br><span class="hljs-string">    :param rec: recall list</span><br><span class="hljs-string">    :param prec: precision list</span><br><span class="hljs-string">    :param use_07_metric: 2007 metric is 11-recall-point based AP</span><br><span class="hljs-string">    :return: average precision</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> use_07_metric:<br>        <span class="hljs-comment"># 11 point metric</span><br>        ap = <span class="hljs-number">0.</span><br>        <span class="hljs-comment"># VOC07是11点插值的AP方式，等于是卡了11个离散的点，划分10个区间来计算AP</span><br>        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> np.arange(<span class="hljs-number">0.</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">0.1</span>):<br>            <span class="hljs-keyword">if</span> np.<span class="hljs-built_in">sum</span>(rec &gt;= t) == <span class="hljs-number">0</span>:<br>                p = <span class="hljs-number">0</span>    <span class="hljs-comment"># recall卡的阈值到顶了，1.1</span><br>            <span class="hljs-keyword">else</span>:<br>                p = np.<span class="hljs-built_in">max</span>(prec[rec &gt;= t])   <span class="hljs-comment"># VOC07：选择每个recall区间内对应的最高precision的计算方案</span><br>            ap = ap + p / <span class="hljs-number">11.</span>    <span class="hljs-comment"># 11-recall-point based AP</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># correct AP calculation</span><br>        <span class="hljs-comment"># first append sentinel values at the end</span><br>        mrec = np.concatenate(([<span class="hljs-number">0.</span>], rec, [<span class="hljs-number">1.</span>]))<br>        mpre = np.concatenate(([<span class="hljs-number">0.</span>], prec, [<span class="hljs-number">0.</span>]))<br><br>        <span class="hljs-comment"># compute the precision envelope</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(mpre.size - <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>):<br>            mpre[i - <span class="hljs-number">1</span>] = np.maximum(mpre[i - <span class="hljs-number">1</span>], mpre[i])    <span class="hljs-comment"># 这个是不是动态规划？从后往前找之前区间内的top-precision，多么优雅的代码呀~~~</span><br><br>        <span class="hljs-comment"># to calculate area under PR curve, look for points where X axis (recall) changes value</span><br>        <span class="hljs-comment"># 上面的英文，可以结合着fig 2的绿框理解，一目了然</span><br>        <span class="hljs-comment"># VOC10是是根据recall值变化的区间来计算的，如果recall变化很多次，就可以认为是一种 “伪” 连续的方式计算了，以下求的是recall的变化</span><br>        i = np.where(mrec[<span class="hljs-number">1</span>:] != mrec[:-<span class="hljs-number">1</span>])[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-comment"># 计算AP，这个计算方式有点玄乎，是一个积分公式的简化，应该是对应的fig 2中红色曲线以下的面积，之前公式的推导我有看过，现在有点忘了，麻烦各位同学补充一下</span><br>        <span class="hljs-comment"># 现在理解了，不难，公式：sum (\Delta recall) * prec，其实结合fig2和下面的图，不就是算的积分么？如果recall划分得足够细，就可以当做连续数据，然后以下公式就是积分公式，算的precision、recall下面的面积了</span><br>        ap = np.<span class="hljs-built_in">sum</span>((mrec[i + <span class="hljs-number">1</span>] - mrec[i]) * mpre[i + <span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">return</span> ap<br></code></pre></td></tr></table></figure><p>通常VOC10标准下计算的mAP值会高于VOC07，原因如下，我就不详细介绍了：</p><blockquote><p><strong>Interpolated average precision</strong><br>Some authors choose an alternate approximation that is called the <em>interpolated average precision</em>. Often, they still call it average precision. Instead of using <em>P(k)</em>, the precision at a retrieval cutoff of <em>k</em> images, the interpolated average precision uses:</p></blockquote><p><img src="https://pic1.zhimg.com/80/v2-5bf4a2d116d55aa4685df9a10488fce0_hd.jpg" alt="img"></p><blockquote><p>In other words, instead of using the precision that was actually observed at cutoff <em>k</em>, the interpolated average precision uses the maximum precision observed across all cutoffs with higher recall. The full equation for computing the interpolated average precision is:</p></blockquote><p><img src="https://pic3.zhimg.com/80/v2-bce2e48f2913849f4029404cfbde9616_hd.jpg" alt="img"></p><blockquote><p>Visually, here’s how the interpolated average precision compares to the approximated average precision (to show a more interesting plot, this one isn’t from the earlier example):</p></blockquote><p><img src="https://pic1.zhimg.com/80/v2-7e00ce50249def8536978cc12a5cafe0_hd.jpg" alt="img"></p><blockquote><p><em>The approximated average precision closely hugs the actually observed curve. The interpolated average precision over estimates the precision at many points and produces a higher average precision value than the approximated average precision.</em></p><p>Further, there are variations on where to take the samples when computing the interpolated average precision. Some take samples at a fixed 11 points from 0 to 1: {0, 0.1, 0.2, …, 0.9, 1.0}. This is called the 11-point interpolated average precision. Others sample at every <em>k</em> where the recall changes.</p></blockquote><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/48992451">目标检测番外篇(2)_mAP</a></li><li><a href="https://www.zhihu.com/question/53405779">目标检测中的mAP是什么含义？</a></li><li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">Object-Detection-Metrics</a></li><li><a href="https://zhuanlan.zhihu.com/p/67279824">【目标检测】VOC mAP</a></li><li><a href="https://zhuanlan.zhihu.com/p/60834912">白话mAP</a></li><li><a href="https://zhuanlan.zhihu.com/p/60319755">Detection基础模块之（二）mAP</a></li></ul><h3 id="如何计算-mAP？"><a href="#如何计算-mAP？" class="headerlink" title="如何计算 mAP？"></a>如何计算 mAP？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://github.com/Cartucho/mAP">https://github.com/Cartucho/mAP</a></li><li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">https://github.com/rafaelpadilla/Object-Detection-Metrics</a></li><li><a href="https://zhuanlan.zhihu.com/p/67279824">【目标检测】VOC mAP</a></li></ul><h2 id="目标检测度量标准"><a href="#目标检测度量标准" class="headerlink" title="目标检测度量标准"></a>目标检测度量标准</h2><ul><li><p>mAP</p></li><li><p>FPS</p></li><li><p><input disabled="" type="checkbox"> TODO</p></li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">Object-Detection-Metrics</a></li><li><a href="https://zhuanlan.zhihu.com/p/70306015">目标检测的性能评价指标</a></li><li><a href="https://zhuanlan.zhihu.com/p/60794316">【目标检测】基础知识：IoU、NMS、Bounding box regression</a></li></ul><h2 id="图像分割度量标准"><a href="#图像分割度量标准" class="headerlink" title="图像分割度量标准"></a>图像分割度量标准</h2><ul><li><input disabled="" type="checkbox"> TODO</li><li>PA</li><li>MP</li><li>mIoU</li><li>FWIoU</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://arxiv.org/abs/1704.06857">《A Review on Deep Learning Techniques Applied to Semantic Segmentation》</a></li><li><a href="https://zhuanlan.zhihu.com/p/38236530">图像语义分割准确率度量方法总结</a></li><li><a href="https://blog.csdn.net/u014593748/article/details/71698246">论文笔记 |　基于深度学习的图像语义分割技术概述之5.1度量标准</a></li></ul><h2 id="非极大值抑制NMS"><a href="#非极大值抑制NMS" class="headerlink" title="非极大值抑制NMS"></a>非极大值抑制NMS</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="目标检测中的Anchor"><a href="#目标检测中的Anchor" class="headerlink" title="目标检测中的Anchor"></a>目标检测中的Anchor</h2><ul><li><input disabled="" type="checkbox"> </li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/55824651">目标检测中的Anchor</a></li></ul><h2 id="原始图片中的ROI如何映射到到feature-map"><a href="#原始图片中的ROI如何映射到到feature-map" class="headerlink" title="原始图片中的ROI如何映射到到feature map?"></a>原始图片中的ROI如何映射到到feature map?</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/24780433">https://zhuanlan.zhihu.com/p/24780433</a></li><li><a href="http://www.cnblogs.com/objectDetect/p/5947169.html">http://www.cnblogs.com/objectDetect/p/5947169.html</a></li></ul><h2 id="请问Faster-R-CNN和SSD-中为什么用smooth-l1-loss，和l2有什么区别？"><a href="#请问Faster-R-CNN和SSD-中为什么用smooth-l1-loss，和l2有什么区别？" class="headerlink" title="请问Faster R-CNN和SSD 中为什么用smooth l1 loss，和l2有什么区别？"></a>请问Faster R-CNN和SSD 中为什么用smooth l1 loss，和l2有什么区别？</h2><ul><li><input disabled="" type="checkbox"> </li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/58200555/answer/621174180">请问faster rcnn和ssd 中为什么用smooth l1 loss，和l2有什么区别？</a></li></ul><h2 id="给定5个人脸关键点和5个对齐后的点，求怎么变换的？"><a href="#给定5个人脸关键点和5个对齐后的点，求怎么变换的？" class="headerlink" title="给定5个人脸关键点和5个对齐后的点，求怎么变换的？"></a>给定5个人脸关键点和5个对齐后的点，求怎么变换的？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Bounding-boxes-回归原理-x2F-公式"><a href="#Bounding-boxes-回归原理-x2F-公式" class="headerlink" title="Bounding boxes 回归原理&#x2F;公式"></a>Bounding boxes 回归原理&#x2F;公式</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="U-Net-和-FCN的区别"><a href="#U-Net-和-FCN的区别" class="headerlink" title="U-Net 和 FCN的区别"></a>U-Net 和 FCN的区别</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="介绍KCF算法"><a href="#介绍KCF算法" class="headerlink" title="介绍KCF算法"></a>介绍KCF算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="介绍MobileNet-SSD算法"><a href="#介绍MobileNet-SSD算法" class="headerlink" title="介绍MobileNet-SSD算法"></a>介绍MobileNet-SSD算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="目标检测中的多尺度训练-x2F-测试？"><a href="#目标检测中的多尺度训练-x2F-测试？" class="headerlink" title="目标检测中的多尺度训练&#x2F;测试？"></a>目标检测中的多尺度训练&#x2F;测试？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p>多尺度训练对全卷积网络有效，一般设置几种不同尺度的图片，训练时每隔一定iterations随机选取一种尺度训练。这样训练出来的模型鲁棒性强，其可以接受任意大小的图片作为输入，使用尺度小的图片测试速度会快些，但准确度低，用尺度大的图片测试速度慢，但是准确度高。</p><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/271781123">目标检测中的多尺度训练&#x2F;测试？</a></li></ul><h2 id="目标检测中的正负样本不平衡问题"><a href="#目标检测中的正负样本不平衡问题" class="headerlink" title="目标检测中的正负样本不平衡问题"></a>目标检测中的正负样本不平衡问题</h2><ul><li><a href="https://arxiv.org/abs/1604.03540">OHEM</a></li><li><a href="https://arxiv.org/abs/1708.02002">Focal Loss</a></li><li><a href="https://arxiv.org/abs/1811.05181">GHM</a></li><li><a href="https://arxiv.org/abs/1904.04821">PISA</a></li><li><a href="https://arxiv.org/abs/1904.06373">AP-loss</a></li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/55036597">样本贡献不均：Focal Loss和 Gradient Harmonizing Mechanism</a></li><li><a href="https://zhuanlan.zhihu.com/p/62314673">被忽略的Focal Loss变种</a></li><li><a href="https://zhuanlan.zhihu.com/p/63954517">Soft Sampling：探索更有效的采样策略</a>：介绍了<strong>Focal Loss</strong>、<strong>GHM</strong>和<strong>PISA</strong></li></ul><h2 id="目标检测中的类别漏检问题该怎么解决？"><a href="#目标检测中的类别漏检问题该怎么解决？" class="headerlink" title="目标检测中的类别漏检问题该怎么解决？"></a>目标检测中的类别漏检问题该怎么解决？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/372208101">目标检测中的类别漏检问题该怎么解决？</a></li></ul><h2 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h2><h3 id="RPN-的损失函数"><a href="#RPN-的损失函数" class="headerlink" title="RPN 的损失函数"></a>RPN 的损失函数</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="RPN中的anchor-box是怎么选取的？"><a href="#RPN中的anchor-box是怎么选取的？" class="headerlink" title="RPN中的anchor box是怎么选取的？"></a>RPN中的anchor box是怎么选取的？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="RoI-Pooling"><a href="#RoI-Pooling" class="headerlink" title="RoI Pooling"></a>RoI Pooling</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/59692298">你真的学会RoI Pooling了吗?</a></li><li><a href="https://zhuanlan.zhihu.com/p/46927880">IoUNet(5)源码 RoIPooling(1)</a></li></ul><h2 id="RoI-Align"><a href="#RoI-Align" class="headerlink" title="RoI Align"></a>RoI Align</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/46928697">IoUNet(6) 源码 RoIAlign(1)</a></li></ul><h2 id="为什么深度学习中的图像分割要先编码再解码？"><a href="#为什么深度学习中的图像分割要先编码再解码？" class="headerlink" title="为什么深度学习中的图像分割要先编码再解码？"></a>为什么深度学习中的图像分割要先编码再解码？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/322191738">为什么深度学习中的图像分割要先编码再解码？</a></li></ul><h2 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h2><p>本笔记介绍目标检测的另一个基本概念：NMS（non-maximum suppression），做目标检测的同学想必对这个词语耳熟能详了；</p><p>在检测图像中的目标时，不可避免地会检出很多bboxes + cls scores，这些bbox之间有很多是冗余的，一个目标可能会被多个bboxes检出，如果所有bboxes都输出，就很影响体验和美观了（同一个目标输出100个bboxes，想想都后怕~~~），一种方案就是提升cls scores的阈值，减少bbox数量的输出；另一种方案就是使用NMS，将同一目标内的bboxes按照cls score + IoU阈值做筛选，剔除冗余地、低置信度的bbox；</p><p>可能又会问了：为什么目标检测时，会有这么多无效、冗余检测框呢？这个。。。我的理解，是因为图像中没有目标尺度、位置的先验知识，为保证对目标的高召回，就必须使用滑窗、anchor &#x2F; default bbox密集采样的方式，尽管检测模型能对每个anchor &#x2F; default bbox做出 cls + reg，可以一定程度上剔除误检，但没有结合检出bbox的cls score + IoU阈值做筛选，而NMS就可以做到这一点；</p><p><strong>1 NMS操作流程</strong></p><p>NMS用于剔除图像中检出的冗余bbox，标准NMS的具体做法为：</p><p><strong>step-1</strong>：将所有检出的output_bbox按cls score划分（如pascal voc分20个类，也即将output_bbox按照其对应的cls score划分为21个集合，1个bg类，只不过bg类就没必要做NMS而已）；</p><p><strong>step-2</strong>：在每个集合内根据各个bbox的cls score做降序排列，得到一个降序的list_k；</p><p><strong>step-3</strong>：从list_k中top1 cls score开始，计算该bbox_x与list中其他bbox_y的IoU，若IoU大于阈值T，则剔除该bbox_y，最终保留bbox_x，从list_k中取出；</p><p><strong>step-4</strong>：选择list_k中top2 cls score(步骤3取出top 1 bbox_x后，原list_k中的top 2就相当于现list_k中的top 1了，但如果step-3中剔除的bbox_y刚好是原list_k中的top 2，就依次找top 3即可，理解这么个意思就行)，重复step-3中的迭代操作，直至list_k中所有bbox都完成筛选；</p><p><strong>step-5</strong>：对每个集合的list_k，重复step-3、4中的迭代操作，直至所有list_k都完成筛选；</p><p>以上操作写的有点绕，不过如果理解NMS操作流程的话，再结合下图，应该还是非常好理解的；</p><p><img src="https://pic3.zhimg.com/80/v2-44f9d8d3f66e59e407a4edb5a02ea4ea_hd.jpg" alt="img"></p><p><strong>2 代码学习</strong></p><p><strong>2.1 test_RFB.py</strong></p><p>我选择了RFBNet里的代码介绍NMS，因为里面的流程基本上就是按照我说的操作进行了；</p><p>先看看test_RFB.py中的片段，通过以下代码可以发现，其对应着step-1、step5操作，就是说NMS操作是逐类进行的，图像中检出的所有bboxes，按照 cls 做划分，再每个类的bbox进一步做NMS；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">out = net(x)      <span class="hljs-comment"># forward pass，这里相当于将图像 x 输入RFBNet，得到了pred cls + reg</span><br>boxes, scores = detector.forward(out,priors) <span class="hljs-comment"># 结合priors，将pred reg（也即预测的offsets）解码成最终的pred bbox，如果理解anchor / default bbox操作流程，这个应该很好理解的；</span><br>boxes = boxes[<span class="hljs-number">0</span>]<br>scores=scores[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># scale each detection back up to the image</span><br>boxes *= scale   <span class="hljs-comment"># （0，1）区间坐标的bbox做尺度反正则化</span><br>boxes = boxes.cpu().numpy()<br>scores = scores.cpu().numpy()<br><br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_classes):      <span class="hljs-comment"># 对每个类 j 的pred bbox单独做NMS，为什么index从1开始？因为0是bg，做NMS无意义</span><br>    inds = np.where(scores[:, j] &gt; thresh)[<span class="hljs-number">0</span>]     <span class="hljs-comment"># 找到该类 j 下，所有cls score大于thresh的bbox，为什么选择大于thresh的bbox？因为score小于阈值的bbox，直接可以过滤掉，无需劳烦NMS</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(inds) == <span class="hljs-number">0</span>:    <span class="hljs-comment"># 没有满足条件的bbox，返回空，跳过；</span><br>        all_boxes[j][i] = np.empty([<span class="hljs-number">0</span>, <span class="hljs-number">5</span>], dtype=np.float32)<br>        <span class="hljs-keyword">continue</span><br>    c_bboxes = boxes[inds]<br>    c_scores = scores[inds, j]   <span class="hljs-comment"># 找到对应类 j 下的score即可</span><br>    c_dets = np.hstack((c_bboxes, c_scores[:, np.newaxis])).astype(<br>        np.float32, copy=<span class="hljs-literal">False</span>)   <span class="hljs-comment"># 将满足条件的bbox + cls score的bbox通过hstack完成合体</span><br><br>    keep = nms(c_dets, <span class="hljs-number">0.45</span>, force_cpu=args.cpu)    <span class="hljs-comment"># NMS，返回需保存的bbox index：keep</span><br>    c_dets = c_dets[keep, :]<br>    all_boxes[j][i] = c_dets     <span class="hljs-comment"># i 对应每张图像，j 对应图像中类别 j 的bbox清单</span><br></code></pre></td></tr></table></figure><p>介绍以上代码处理流程，<strong>两个目的</strong>：</p><p>1 test_RFB.py的处理流程非常清晰，也很方便我们的理解；</p><p>2 for j in range(1, num_classes)操作表明了，NMS是逐类进行的，也即参与NMS的bbox都属于同一类；</p><p><strong>2.2 py_cpu_nms.py</strong></p><p>代码同样来自于FRBNet，结合注释可以发现引自Fast R-CNN；</p><p>这个代码是最简版的nms，跟第一节中NMS处理流程一致，非常适合学习，可以作为baseline，我加了个简单的main函数做测试；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># --------------------------------------------------------</span><br><span class="hljs-comment"># Fast R-CNN</span><br><span class="hljs-comment"># Copyright (c) 2015 Microsoft</span><br><span class="hljs-comment"># Licensed under The MIT License [see LICENSE for details]</span><br><span class="hljs-comment"># Written by Ross Girshick</span><br><span class="hljs-comment"># --------------------------------------------------------</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">py_cpu_nms</span>(<span class="hljs-params">dets, thresh</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Pure Python NMS baseline.&quot;&quot;&quot;</span><br>    x1 = dets[:, <span class="hljs-number">0</span>]                     <span class="hljs-comment"># pred bbox top_x</span><br>    y1 = dets[:, <span class="hljs-number">1</span>]                     <span class="hljs-comment"># pred bbox top_y</span><br>    x2 = dets[:, <span class="hljs-number">2</span>]                     <span class="hljs-comment"># pred bbox bottom_x</span><br>    y2 = dets[:, <span class="hljs-number">3</span>]                     <span class="hljs-comment"># pred bbox bottom_y</span><br>    scores = dets[:, <span class="hljs-number">4</span>]              <span class="hljs-comment"># pred bbox cls score</span><br><br>    areas = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)    <span class="hljs-comment"># pred bbox areas</span><br>    order = scores.argsort()[::-<span class="hljs-number">1</span>]              <span class="hljs-comment"># 对pred bbox按score做降序排序，对应step-2</span><br><br>    keep = []    <span class="hljs-comment"># NMS后，保留的pred bbox</span><br>    <span class="hljs-keyword">while</span> order.size &gt; <span class="hljs-number">0</span>:<br>        i = order[<span class="hljs-number">0</span>]          <span class="hljs-comment"># top-1 score bbox</span><br>        keep.append(i)   <span class="hljs-comment"># top-1 score的话，自然就保留了</span><br>        xx1 = np.maximum(x1[i], x1[order[<span class="hljs-number">1</span>:]])   <span class="hljs-comment"># top-1 bbox（score最大）与order中剩余bbox计算NMS</span><br>        yy1 = np.maximum(y1[i], y1[order[<span class="hljs-number">1</span>:]])<br>        xx2 = np.minimum(x2[i], x2[order[<span class="hljs-number">1</span>:]])<br>        yy2 = np.minimum(y2[i], y2[order[<span class="hljs-number">1</span>:]])<br><br>        w = np.maximum(<span class="hljs-number">0.0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)<br>        h = np.maximum(<span class="hljs-number">0.0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)<br>        inter = w * h<br>        ovr = inter / (areas[i] + areas[order[<span class="hljs-number">1</span>:]] - inter)      <span class="hljs-comment"># 无处不在的IoU计算~~~</span><br><br>        inds = np.where(ovr &lt;= thresh)[<span class="hljs-number">0</span>]     <span class="hljs-comment"># 这个操作可以对代码断点调试理解下，结合step-3，我们希望剔除所有与当前top-1 bbox IoU &gt; thresh的冗余bbox，那么保留下来的bbox，自然就是ovr &lt;= thresh的非冗余bbox，其inds保留下来，作进一步筛选</span><br>        order = order[inds + <span class="hljs-number">1</span>]   <span class="hljs-comment"># 保留有效bbox，就是这轮NMS未被抑制掉的幸运儿，为什么 + 1？因为ind = 0就是这轮NMS的top-1，剩余有效bbox在IoU计算中与top-1做的计算，inds对应回原数组，自然要做 +1 的映射，接下来就是step-4的循环</span><br><br>    <span class="hljs-keyword">return</span> keep    <span class="hljs-comment"># 最终NMS结果返回</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    dets = np.array([[<span class="hljs-number">100</span>,<span class="hljs-number">120</span>,<span class="hljs-number">170</span>,<span class="hljs-number">200</span>,<span class="hljs-number">0.98</span>],<br>                     [<span class="hljs-number">20</span>,<span class="hljs-number">40</span>,<span class="hljs-number">80</span>,<span class="hljs-number">90</span>,<span class="hljs-number">0.99</span>],<br>                     [<span class="hljs-number">20</span>,<span class="hljs-number">38</span>,<span class="hljs-number">82</span>,<span class="hljs-number">88</span>,<span class="hljs-number">0.96</span>],<br>                     [<span class="hljs-number">200</span>,<span class="hljs-number">380</span>,<span class="hljs-number">282</span>,<span class="hljs-number">488</span>,<span class="hljs-number">0.9</span>],<br>                     [<span class="hljs-number">19</span>,<span class="hljs-number">38</span>,<span class="hljs-number">75</span>,<span class="hljs-number">91</span>, <span class="hljs-number">0.8</span>]])<br><br>    py_cpu_nms(dets, <span class="hljs-number">0.5</span>)<br></code></pre></td></tr></table></figure><p><strong>2.2 bbox_utils.py</strong></p><p>同样是RFBNet中的nms代码，用pytorch实现的，其实和2.1小节中的NMS操作完全一致；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Original author: Francisco Massa:</span><br><span class="hljs-comment"># https://github.com/fmassa/object-detection.torch</span><br><span class="hljs-comment"># Ported to PyTorch by Max deGroot (02/01/2017)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">nms</span>(<span class="hljs-params">boxes, scores, overlap=<span class="hljs-number">0.5</span>, top_k=<span class="hljs-number">200</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Apply non-maximum suppression at test time to avoid detecting too many</span><br><span class="hljs-string">    overlapping bounding boxes for a given object. ---- 这里面有一个细节，NMS仅用于测试阶段，为什么不用于训练阶段呢？可以评论留言下，我就不解释了，嘿嘿~~~</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].</span><br><span class="hljs-string">        scores: (tensor) The class predscores for the img, Shape:[num_priors].</span><br><span class="hljs-string">        overlap: (float) The overlap thresh for suppressing unnecessary boxes.</span><br><span class="hljs-string">        top_k: (int) The Maximum number of box preds to consider.</span><br><span class="hljs-string">    Return:</span><br><span class="hljs-string">        The indices of the kept boxes with respect to num_priors.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    keep = torch.Tensor(scores.size(<span class="hljs-number">0</span>)).fill_(<span class="hljs-number">0</span>).long()<br>    <span class="hljs-keyword">if</span> boxes.numel() == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> keep<br>    x1 = boxes[:, <span class="hljs-number">0</span>]<br>    y1 = boxes[:, <span class="hljs-number">1</span>]<br>    x2 = boxes[:, <span class="hljs-number">2</span>]<br>    y2 = boxes[:, <span class="hljs-number">3</span>]<br>    area = torch.mul(x2 - x1, y2 - y1)    <span class="hljs-comment"># IoU初步准备</span><br>    v, idx = scores.sort(<span class="hljs-number">0</span>)  <span class="hljs-comment"># sort in ascending order，对应step-2，不过是升序操作，非降序</span><br>    <span class="hljs-comment"># I = I[v &gt;= 0.01]</span><br>    idx = idx[-top_k:]  <span class="hljs-comment"># indices of the top-k largest vals，依然是升序的结果</span><br>    xx1 = boxes.new()<br>    yy1 = boxes.new()<br>    xx2 = boxes.new()<br>    yy2 = boxes.new()<br>    w = boxes.new()<br>    h = boxes.new()<br><br>    <span class="hljs-comment"># keep = torch.Tensor()</span><br>    count = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> idx.numel() &gt; <span class="hljs-number">0</span>:   <span class="hljs-comment"># 对应step-4，若所有pred bbox都处理完毕，就可以结束循环啦~</span><br>        i = idx[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># index of current largest val，top-1 score box，因为是升序的，所有返回index = -1的最后一个元素即可</span><br>        <span class="hljs-comment"># keep.append(i)</span><br>        keep[count] = i<br>        count += <span class="hljs-number">1</span>    <span class="hljs-comment"># 不仅记数NMS保留的bbox个数，也作为index存储bbox</span><br>        <span class="hljs-keyword">if</span> idx.size(<span class="hljs-number">0</span>) == <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">break</span><br>        idx = idx[:-<span class="hljs-number">1</span>]  <span class="hljs-comment"># remove kept element from view，top-1已保存，不需要了~~~</span><br>        <span class="hljs-comment"># load bboxes of next highest vals</span><br>        torch.index_select(x1, <span class="hljs-number">0</span>, idx, out=xx1)<br>        torch.index_select(y1, <span class="hljs-number">0</span>, idx, out=yy1)<br>        torch.index_select(x2, <span class="hljs-number">0</span>, idx, out=xx2)<br>        torch.index_select(y2, <span class="hljs-number">0</span>, idx, out=yy2)<br>        <span class="hljs-comment"># store element-wise max with next highest score</span><br>        xx1 = torch.clamp(xx1, <span class="hljs-built_in">min</span>=x1[i])   <span class="hljs-comment"># 对应 np.maximum(x1[i], x1[order[1:]]) </span><br>        yy1 = torch.clamp(yy1, <span class="hljs-built_in">min</span>=y1[i])<br>        xx2 = torch.clamp(xx2, <span class="hljs-built_in">max</span>=x2[i])<br>        yy2 = torch.clamp(yy2, <span class="hljs-built_in">max</span>=y2[i])<br>        w.resize_as_(xx2)<br>        h.resize_as_(yy2)<br>        w = xx2 - xx1<br>        h = yy2 - yy1<br>        <span class="hljs-comment"># check sizes of xx1 and xx2.. after each iteration</span><br>        w = torch.clamp(w, <span class="hljs-built_in">min</span>=<span class="hljs-number">0.0</span>)    <span class="hljs-comment"># clamp函数可以去查查，类似max、mini的操作</span><br>        h = torch.clamp(h, <span class="hljs-built_in">min</span>=<span class="hljs-number">0.0</span>)<br>        inter = w*h<br>        <span class="hljs-comment"># IoU = i / (area(a) + area(b) - i)     </span><br>        <span class="hljs-comment"># 以下两步操作做了个优化，area已经计算好了，就可以直接根据idx读取结果了，area[i]同理，避免了不必要的冗余计算</span><br>        rem_areas = torch.index_select(area, <span class="hljs-number">0</span>, idx)  <span class="hljs-comment"># load remaining areas)</span><br>        union = (rem_areas - inter) + area[i]     <span class="hljs-comment"># 就是area(a) + area(b) - i</span><br>        IoU = inter/union  <span class="hljs-comment"># store result in iou，# IoU来啦~~~</span><br>        <span class="hljs-comment"># keep only elements with an IoU &lt;= overlap</span><br>        idx = idx[IoU.le(overlap)]   <span class="hljs-comment"># 这一轮NMS操作，IoU阈值小于overlap的idx，就是需要保留的bbox，其他的就直接忽略吧，并进行下一轮计算</span><br>    <span class="hljs-keyword">return</span> keep, count<br></code></pre></td></tr></table></figure><p><strong>2.2 cpu_nms.pyx</strong></p><p>同样在RGBNet项目中，下面就是优化后的NNS操作，以及soft-NMS操作，我就不细讲了~~~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># --------------------------------------------------------</span><br><span class="hljs-comment"># Fast R-CNN</span><br><span class="hljs-comment"># Copyright (c) 2015 Microsoft</span><br><span class="hljs-comment"># Licensed under The MIT License [see LICENSE for details]</span><br><span class="hljs-comment"># Written by Ross Girshick</span><br><span class="hljs-comment"># --------------------------------------------------------</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>cimport numpy <span class="hljs-keyword">as</span> np<br><br>cdef inline np.float32_t <span class="hljs-built_in">max</span>(np.float32_t a, np.float32_t b):<br>    <span class="hljs-keyword">return</span> a <span class="hljs-keyword">if</span> a &gt;= b <span class="hljs-keyword">else</span> b<br><br>cdef inline np.float32_t <span class="hljs-built_in">min</span>(np.float32_t a, np.float32_t b):<br>    <span class="hljs-keyword">return</span> a <span class="hljs-keyword">if</span> a &lt;= b <span class="hljs-keyword">else</span> b<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cpu_nms</span>(<span class="hljs-params">np.ndarray[np.float32_t, ndim=<span class="hljs-number">2</span>] dets, np.<span class="hljs-built_in">float</span> thresh</span>):<br>    cdef np.ndarray[np.float32_t, ndim=<span class="hljs-number">1</span>] x1 = dets[:, <span class="hljs-number">0</span>]<br>    cdef np.ndarray[np.float32_t, ndim=<span class="hljs-number">1</span>] y1 = dets[:, <span class="hljs-number">1</span>]<br>    cdef np.ndarray[np.float32_t, ndim=<span class="hljs-number">1</span>] x2 = dets[:, <span class="hljs-number">2</span>]<br>    cdef np.ndarray[np.float32_t, ndim=<span class="hljs-number">1</span>] y2 = dets[:, <span class="hljs-number">3</span>]<br>    cdef np.ndarray[np.float32_t, ndim=<span class="hljs-number">1</span>] scores = dets[:, <span class="hljs-number">4</span>]<br><br>    cdef np.ndarray[np.float32_t, ndim=<span class="hljs-number">1</span>] areas = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)<br>    cdef np.ndarray[np.int_t, ndim=<span class="hljs-number">1</span>] order = scores.argsort()[::-<span class="hljs-number">1</span>]<br><br>    cdef <span class="hljs-built_in">int</span> ndets = dets.shape[<span class="hljs-number">0</span>]<br>    cdef np.ndarray[np.int_t, ndim=<span class="hljs-number">1</span>] suppressed = \<br>            np.zeros((ndets), dtype=np.<span class="hljs-built_in">int</span>)<br><br>    <span class="hljs-comment"># nominal indices</span><br>    cdef <span class="hljs-built_in">int</span> _i, _j<br>    <span class="hljs-comment"># sorted indices</span><br>    cdef <span class="hljs-built_in">int</span> i, j<br>    <span class="hljs-comment"># temp variables for box i&#x27;s (the box currently under consideration)</span><br>    cdef np.float32_t ix1, iy1, ix2, iy2, iarea<br>    <span class="hljs-comment"># variables for computing overlap with box j (lower scoring box)</span><br>    cdef np.float32_t xx1, yy1, xx2, yy2<br>    cdef np.float32_t w, h<br>    cdef np.float32_t inter, ovr<br><br>    keep = []<br>    <span class="hljs-keyword">for</span> _i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(ndets):<br>        i = order[_i]<br>        <span class="hljs-keyword">if</span> suppressed[i] == <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">continue</span><br>        keep.append(i)<br>        ix1 = x1[i]<br>        iy1 = y1[i]<br>        ix2 = x2[i]<br>        iy2 = y2[i]<br>        iarea = areas[i]<br>        <span class="hljs-keyword">for</span> _j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(_i + <span class="hljs-number">1</span>, ndets):<br>            j = order[_j]<br>            <span class="hljs-keyword">if</span> suppressed[j] == <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">continue</span><br>            xx1 = <span class="hljs-built_in">max</span>(ix1, x1[j])<br>            yy1 = <span class="hljs-built_in">max</span>(iy1, y1[j])<br>            xx2 = <span class="hljs-built_in">min</span>(ix2, x2[j])<br>            yy2 = <span class="hljs-built_in">min</span>(iy2, y2[j])<br>            w = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)<br>            h = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)<br>            inter = w * h<br>            ovr = inter / (iarea + areas[j] - inter)<br>            <span class="hljs-keyword">if</span> ovr &gt;= thresh:<br>                suppressed[j] = <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">return</span> keep<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cpu_soft_nms</span>(<span class="hljs-params">np.ndarray[<span class="hljs-built_in">float</span>, ndim=<span class="hljs-number">2</span>] boxes, <span class="hljs-built_in">float</span> sigma=<span class="hljs-number">0.5</span>, <span class="hljs-built_in">float</span> Nt=<span class="hljs-number">0.3</span>, <span class="hljs-built_in">float</span> threshold=<span class="hljs-number">0.001</span>, unsigned <span class="hljs-built_in">int</span> method=<span class="hljs-number">0</span></span>):<br>    cdef unsigned <span class="hljs-built_in">int</span> N = boxes.shape[<span class="hljs-number">0</span>]<br>    cdef <span class="hljs-built_in">float</span> iw, ih, box_area<br>    cdef <span class="hljs-built_in">float</span> ua<br>    cdef <span class="hljs-built_in">int</span> pos = <span class="hljs-number">0</span><br>    cdef <span class="hljs-built_in">float</span> maxscore = <span class="hljs-number">0</span><br>    cdef <span class="hljs-built_in">int</span> maxpos = <span class="hljs-number">0</span><br>    cdef <span class="hljs-built_in">float</span> x1,x2,y1,y2,tx1,tx2,ty1,ty2,ts,area,weight,ov<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):<br>        maxscore = boxes[i, <span class="hljs-number">4</span>]<br>        maxpos = i<br><br>        tx1 = boxes[i,<span class="hljs-number">0</span>]<br>        ty1 = boxes[i,<span class="hljs-number">1</span>]<br>        tx2 = boxes[i,<span class="hljs-number">2</span>]<br>        ty2 = boxes[i,<span class="hljs-number">3</span>]<br>        ts = boxes[i,<span class="hljs-number">4</span>]<br><br>        pos = i + <span class="hljs-number">1</span><br><span class="hljs-comment"># get max box</span><br>        <span class="hljs-keyword">while</span> pos &lt; N:<br>            <span class="hljs-keyword">if</span> maxscore &lt; boxes[pos, <span class="hljs-number">4</span>]:<br>                maxscore = boxes[pos, <span class="hljs-number">4</span>]<br>                maxpos = pos<br>            pos = pos + <span class="hljs-number">1</span><br><br><span class="hljs-comment"># add max box as a detection </span><br>        boxes[i,<span class="hljs-number">0</span>] = boxes[maxpos,<span class="hljs-number">0</span>]<br>        boxes[i,<span class="hljs-number">1</span>] = boxes[maxpos,<span class="hljs-number">1</span>]<br>        boxes[i,<span class="hljs-number">2</span>] = boxes[maxpos,<span class="hljs-number">2</span>]<br>        boxes[i,<span class="hljs-number">3</span>] = boxes[maxpos,<span class="hljs-number">3</span>]<br>        boxes[i,<span class="hljs-number">4</span>] = boxes[maxpos,<span class="hljs-number">4</span>]<br><br><span class="hljs-comment"># swap ith box with position of max box</span><br>        boxes[maxpos,<span class="hljs-number">0</span>] = tx1<br>        boxes[maxpos,<span class="hljs-number">1</span>] = ty1<br>        boxes[maxpos,<span class="hljs-number">2</span>] = tx2<br>        boxes[maxpos,<span class="hljs-number">3</span>] = ty2<br>        boxes[maxpos,<span class="hljs-number">4</span>] = ts<br><br>        tx1 = boxes[i,<span class="hljs-number">0</span>]<br>        ty1 = boxes[i,<span class="hljs-number">1</span>]<br>        tx2 = boxes[i,<span class="hljs-number">2</span>]<br>        ty2 = boxes[i,<span class="hljs-number">3</span>]<br>        ts = boxes[i,<span class="hljs-number">4</span>]<br><br>        pos = i + <span class="hljs-number">1</span><br><span class="hljs-comment"># NMS iterations, note that N changes if detection boxes fall below threshold</span><br>        <span class="hljs-keyword">while</span> pos &lt; N:<br>            x1 = boxes[pos, <span class="hljs-number">0</span>]<br>            y1 = boxes[pos, <span class="hljs-number">1</span>]<br>            x2 = boxes[pos, <span class="hljs-number">2</span>]<br>            y2 = boxes[pos, <span class="hljs-number">3</span>]<br>            s = boxes[pos, <span class="hljs-number">4</span>]<br><br>            area = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)<br>            iw = (<span class="hljs-built_in">min</span>(tx2, x2) - <span class="hljs-built_in">max</span>(tx1, x1) + <span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> iw &gt; <span class="hljs-number">0</span>:<br>                ih = (<span class="hljs-built_in">min</span>(ty2, y2) - <span class="hljs-built_in">max</span>(ty1, y1) + <span class="hljs-number">1</span>)<br>                <span class="hljs-keyword">if</span> ih &gt; <span class="hljs-number">0</span>:<br>                    ua = <span class="hljs-built_in">float</span>((tx2 - tx1 + <span class="hljs-number">1</span>) * (ty2 - ty1 + <span class="hljs-number">1</span>) + area - iw * ih)<br>                    ov = iw * ih / ua <span class="hljs-comment">#iou between max box and detection box</span><br><br>                    <span class="hljs-keyword">if</span> method == <span class="hljs-number">1</span>: <span class="hljs-comment"># linear</span><br>                        <span class="hljs-keyword">if</span> ov &gt; Nt: <br>                            weight = <span class="hljs-number">1</span> - ov<br>                        <span class="hljs-keyword">else</span>:<br>                            weight = <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> method == <span class="hljs-number">2</span>: <span class="hljs-comment"># gaussian</span><br>                        weight = np.exp(-(ov * ov)/sigma)<br>                    <span class="hljs-keyword">else</span>: <span class="hljs-comment"># original NMS</span><br>                        <span class="hljs-keyword">if</span> ov &gt; Nt: <br>                            weight = <span class="hljs-number">0</span><br>                        <span class="hljs-keyword">else</span>:<br>                            weight = <span class="hljs-number">1</span><br><br>                    boxes[pos, <span class="hljs-number">4</span>] = weight*boxes[pos, <span class="hljs-number">4</span>]<br>    <br>    <span class="hljs-comment"># if box score falls below threshold, discard the box by swapping with last box</span><br>    <span class="hljs-comment"># update N</span><br>                    <span class="hljs-keyword">if</span> boxes[pos, <span class="hljs-number">4</span>] &lt; threshold:<br>                        boxes[pos,<span class="hljs-number">0</span>] = boxes[N-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]<br>                        boxes[pos,<span class="hljs-number">1</span>] = boxes[N-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<br>                        boxes[pos,<span class="hljs-number">2</span>] = boxes[N-<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]<br>                        boxes[pos,<span class="hljs-number">3</span>] = boxes[N-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>]<br>                        boxes[pos,<span class="hljs-number">4</span>] = boxes[N-<span class="hljs-number">1</span>, <span class="hljs-number">4</span>]<br>                        N = N - <span class="hljs-number">1</span><br>                        pos = pos - <span class="hljs-number">1</span><br><br>            pos = pos + <span class="hljs-number">1</span><br><br>    keep = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]<br>    <span class="hljs-keyword">return</span> keep<br></code></pre></td></tr></table></figure><p><strong>参考代码：</strong></p><p><a href="https://link.zhihu.com/?target=https://github.com/ruinmessi/RFBNet">https://github.com/ruinmessi/RFBNet</a>：RFBNet</p><p><a href="https://link.zhihu.com/?target=https://github.com/rbgirshick/py-faster-rcnn">https://github.com/rbgirshick/py-faster-rcnn</a>：学习一百遍都不为过的faster rcnn</p><p>NMS_demo.py：<a href="https://github.com/humengdoudou/object_detection_mAP/blob/master/NMS_demo.py">https://github.com/humengdoudou/object_detection_mAP/blob/master/NMS_demo.py</a></p><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/49481833">目标检测番外篇(3)_NMS</a></li><li><a href="https://zhuanlan.zhihu.com/p/64423753">浅谈NMS的多种实现</a></li></ul><h2 id="NMS及其变体"><a href="#NMS及其变体" class="headerlink" title="NMS及其变体"></a>NMS及其变体</h2><ul><li><p>NMS</p></li><li><p>Soft-NMS</p></li><li><p>Softer-NMS</p></li><li><p>IoU-guided NMS</p></li><li><p>ConvNMS</p></li><li><p>Pure NMS</p></li><li><p>Yes-Net</p></li><li><p>LNMS</p></li><li><p>INMS</p></li><li><p>Polygon NMS</p></li><li><p>MNMS</p></li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/70771042">Detection基础模块之（三）NMS及变体</a></li><li><a href="https://zhuanlan.zhihu.com/p/28129034">NMS也能玩出花样来……</a></li><li><a href="https://zhuanlan.zhihu.com/p/50126479">目标检测之非极大值抑制(NMS)各种变体</a></li></ul><h2 id="R-CNN-系列"><a href="#R-CNN-系列" class="headerlink" title="R-CNN 系列"></a>R-CNN 系列</h2><h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h4 id="Faster-R-CNN-为什么用smooth-l1-loss，和l2有什么区别？"><a href="#Faster-R-CNN-为什么用smooth-l1-loss，和l2有什么区别？" class="headerlink" title="Faster R-CNN 为什么用smooth l1 loss，和l2有什么区别？"></a>Faster R-CNN 为什么用smooth l1 loss，和l2有什么区别？</h4><h2 id="SSD-算法"><a href="#SSD-算法" class="headerlink" title="SSD 算法"></a>SSD 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/65484308">SSD 论文原文完整翻译</a></li></ul><h2 id="YOLO系列（V1-V5）"><a href="#YOLO系列（V1-V5）" class="headerlink" title="YOLO系列（V1-V5）"></a>YOLO系列（V1-V5）</h2><h3 id="YOLOV1"><a href="#YOLOV1" class="headerlink" title="YOLOV1"></a>YOLOV1</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="YOLOv2算法"><a href="#YOLOv2算法" class="headerlink" title="YOLOv2算法"></a>YOLOv2算法</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="YOLOv3算法"><a href="#YOLOv3算法" class="headerlink" title="YOLOv3算法"></a>YOLOv3算法</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="YOLOv4算法"><a href="#YOLOv4算法" class="headerlink" title="YOLOv4算法"></a>YOLOv4算法</h3><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/138824273">目标检测面试指南之YOLOV4</a></li></ul><h3 id="YOLOv5算法"><a href="#YOLOv5算法" class="headerlink" title="YOLOv5算法"></a>YOLOv5算法</h3><h3 id="YOLOv1-YOLOv5的发展"><a href="#YOLOv1-YOLOv5的发展" class="headerlink" title="YOLOv1-YOLOv5的发展"></a>YOLOv1-YOLOv5的发展</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="YOLOv2和YOLOv3的损失函数区别"><a href="#YOLOv2和YOLOv3的损失函数区别" class="headerlink" title="YOLOv2和YOLOv3的损失函数区别"></a>YOLOv2和YOLOv3的损失函数区别</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/hancoder/article/details/87994678">YOLOv1，YOLOv2，YOLOv3解读</a></li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="RetinaNet（Focal-loss）"><a href="#RetinaNet（Focal-loss）" class="headerlink" title="RetinaNet（Focal loss）"></a>RetinaNet（Focal loss）</h2><p>《Focal Loss for Dense Object Detection》</p><ul><li>arXiv：<a href="https://arxiv.org/abs/1708.02002">https://arxiv.org/abs/1708.02002</a></li></ul><p>清华大学孔涛博士在知乎上这么写道：</p><p>目标的检测和定位中一个很困难的问题是，如何从数以万计的候选窗口中挑选包含目标物的物体。只有候选窗口足够多，才能保证模型的 Recall。</p><p>目前，目标检测框架主要有两种：</p><p>一种是 one-stage ，例如 YOLO、SSD 等，这一类方法速度很快，但识别精度没有 two-stage 的高，其中一个很重要的原因是，利用一个分类器很难既把负样本抑制掉，又把目标分类好。</p><p>另外一种目标检测框架是 two-stage ，以 Faster RCNN 为代表，这一类方法识别准确度和定位精度都很高，但存在着计算效率低，资源占用大的问题。</p><p>Focal Loss 从优化函数的角度上来解决这个问题，实验结果非常 solid，很赞的工作。</p><p>何恺明团队提出了用 Focal Loss 函数来训练。</p><p>因为，他在训练过程中发现，类别失衡是影响 one-stage 检测器准确度的主要原因。那么，如果能将“类别失衡”这个因素解决掉，one-stage 不就能达到比较高的识别精度了吗？</p><p>于是在研究中，何恺明团队采用 Focal Loss 函数来消除“类别失衡”这个主要障碍。</p><p>结果怎样呢？</p><p>为了评估该损失的有效性，该团队设计并训练了一个简单的密集目标检测器—RetinaNet。试验结果证明，当使用 Focal Loss 训练时，RetinaNet 不仅能赶上 one-stage 检测器的检测速度，而且还在准确度上超越了当前所有最先进的 two-stage 检测器。</p><p><strong>参考</strong></p><ul><li><a href="https://www.zhihu.com/question/63581984">如何评价Kaiming的Focal Loss for Dense Object Detection？</a></li><li><a href="https://zhuanlan.zhihu.com/p/28442066">首发 | 何恺明团队提出 Focal Loss，目标检测精度高达39.1AP，打破现有记录</a></li></ul><h2 id="FPN-特征金字塔网络"><a href="#FPN-特征金字塔网络" class="headerlink" title="FPN 特征金字塔网络"></a>FPN 特征金字塔网络</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Faster-R-CNN的RPN网络"><a href="#Faster-R-CNN的RPN网络" class="headerlink" title="Faster R-CNN的RPN网络"></a>Faster R-CNN的RPN网络</h2><p>RPN结构说明： </p><ol><li><p>从基础网络提取的第五卷积层特征进入RPN后分为两个分支，其中一个分支进行针对feature map（上图conv-5-3共有512个feature-map）的每一个位置预测共（9*4&#x3D;36）个参数，其中9代表的是每一个位置预设的9种形状的anchor-box，4对应的是每一个anchor-box的预测值（该预测值表示的是预设anchor-box到ground-truth-box之间的变换参数），上图中指向rpn-bbox-pred层的箭头上面的数字36即是代表了上述的36个参数，所以rpn-bbox-pred层的feature-map数量是36，而每一张feature-map的形状（大小）实际上跟conv5-3一模一样的；</p></li><li><p>另一分支预测该anchor-box所框定的区域属于前景和背景的概率（网上很对博客说的是，指代该点属于前景背景的概率，那样是不对的，不然怎么会有18个feature-map输出呢？否则2个就足够了），前景背景的真值给定是根据当前像素（anchor-box中心）是否在ground-truth-box内；</p></li><li><p>上图RPN-data(python)运算框内所进行的操作是读取图像信息（原始宽高），groun-truth boxes的信息（bounding-box的位置，形状，类别）等，作好相应的转换，输入到下面的层当中。</p></li><li><p>要注意的是RPN内部有两个loss层，一个是BBox的loss,该loss通过减小ground-truth-box与预测的anchor-box之间的差异来进行参数学习，从而使RPN网络中的权重能够学习到预测box的能力。实现细节是每一个位置的anchor-box与ground-truth里面的box进行比较，选择IOU最大的一个作为该anchor-box的真值，若没有，则将之class设为背景（概率值0，否则1），这样背景的anchor-box的损失函数中每个box乘以其class的概率后就不会对bbox的损失函数造成影响。另一个loss是class-loss,该处的loss是指代的前景背景并不是实际的框中物体类别，它的存在可以使得在最后生成roi时能快速过滤掉预测值是背景的box。也可实现bbox的预测函数不受影响，使得anchor-box能（专注于）正确的学习前景框的预测，正如前所述。所以，综合来讲，整个RPN的作用就是替代了以前的selective-search方法，因为网络内的运算都是可GPU加速的，所以一下子提升了ROI生成的速度。可以将RPN理解为一个预测前景背景，并将前景框定的一个网络，并进行单独的训练，实际上论文里面就有一个分阶段训练的训练策略，实际上就是这个原因。</p></li><li><p>最后经过非极大值抑制，RPN层产生的输出是一系列的ROI-data，它通过ROI的相对映射关系，将conv5-3中的特征已经存入ROI-data中，以供后面的分类网使用。</p></li></ol><p>另外两个loss层的说明：<br>也许你注意到了，最后还有两个loss层，这里的class-loss指代的不再是前景背景loss，而是真正的类别loss了，这个应该就很好理解了。而bbox-loss则是因为rpn提取的只是前景背景的预测，往往很粗糙，这里其实是通过ROI-pooling后加上两层全连接实现更精细的box修正（这里其实是我猜的）。<br>ROI-Pooing的作用是为了将不同大小的Roi映射（重采样）成统一的大小输入到全连接层去。</p><p>以上。</p><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/mllearnertj/article/details/53709766">Faster-Rcnn中RPN（Region Proposal Network）的理解</a></li></ul><h2 id="ROI-Pooling、ROI-Align和ROI-Warping对比"><a href="#ROI-Pooling、ROI-Align和ROI-Warping对比" class="headerlink" title="ROI Pooling、ROI Align和ROI Warping对比"></a>ROI Pooling、ROI Align和ROI Warping对比</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/lanyuxuan100/article/details/71124596">Mask-RCNN中的ROIAlign, ROIPooling及ROIWarp对比</a></li></ul><h2 id="DeepLab系列（V1-V3-）"><a href="#DeepLab系列（V1-V3-）" class="headerlink" title="DeepLab系列（V1-V3+）"></a>DeepLab系列（V1-V3+）</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="U-Net神经网络为什么会在医学图像分割表现好？"><a href="#U-Net神经网络为什么会在医学图像分割表现好？" class="headerlink" title="U-Net神经网络为什么会在医学图像分割表现好？"></a>U-Net神经网络为什么会在医学图像分割表现好？</h2><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/269914775">U-Net神经网络为什么会在医学图像分割表现好？</a></li></ul><h2 id="Scene-Parsing和Semantic-Segmentation有什么不同"><a href="#Scene-Parsing和Semantic-Segmentation有什么不同" class="headerlink" title="Scene Parsing和Semantic Segmentation有什么不同?"></a>Scene Parsing和Semantic Segmentation有什么不同?</h2><p><strong>参考资料</strong></p><ul><li><a href="https://www.zhihu.com/question/57726518">Scene Parsing和Semantic Segmentation有什么不同?</a></li></ul><h2 id="CenterNet"><a href="#CenterNet" class="headerlink" title="CenterNet"></a>CenterNet</h2><p>CornerNet介绍</p><h3 id="CornerPooling是怎么做的？"><a href="#CornerPooling是怎么做的？" class="headerlink" title="CornerPooling是怎么做的？"></a>CornerPooling是怎么做的？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p><strong>参考资料</strong></p><ul><li><a href="https://zhuanlan.zhihu.com/p/438625445">Transformer面试题总结101道题</a></li><li><a href="https://zhuanlan.zhihu.com/p/363466672">transformer面试题的简单回答</a></li><li><a href="https://zhuanlan.zhihu.com/p/148656446">史上最全Transformer面试题系列（一）：灵魂20问帮你彻底搞定Transformer-干货！</a></li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul><li><input disabled="" type="checkbox"> 目标检测方向</li><li><input disabled="" type="checkbox"> 图像分割方向</li><li><input disabled="" type="checkbox"> 目标跟踪方向</li><li><input disabled="" type="checkbox"> 人脸（检测&amp;识别&amp;关键点）</li><li><input disabled="" type="checkbox"> OCR方向</li><li><input disabled="" type="checkbox"> SLAM方向</li><li><input disabled="" type="checkbox"> 超分辨率</li><li><input disabled="" type="checkbox"> 医疗影响方向</li><li><input disabled="" type="checkbox"> Re-ID</li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>计算机视觉</tag>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传统图像处理</title>
    <link href="/2022/07/19/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    <url>/2022/07/19/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="传统图像处理"><a href="#传统图像处理" class="headerlink" title="传统图像处理"></a>传统图像处理</h1><h2 id="颜色空间"><a href="#颜色空间" class="headerlink" title="颜色空间"></a>颜色空间</h2><ul><li><strong>RGB</strong></li><li><strong>HSI</strong></li><li><strong>CMYK</strong></li><li><strong>YUV</strong></li></ul><p>OpenCV 读取图像存储的顺序为什么是 BGR，而不是 RGB？</p><h2 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><blockquote><p>先引入两个问题。<br> 1.图像为什么要滤波？<br> 答：a.消除图像在数字化过程中产生或者混入的噪声。<br> b.提取图片对象的特征作为图像识别的特征模式。<br> 2.滤波器该如何去理解?<br> 答：滤波器可以想象成一个包含加权系数的窗口或者说一个镜片，当使用滤波器去平滑处理图像的时候，就是把通过这个窗口或者镜片去看这个图像。</p></blockquote><p>滤波器分为很多种，有方框滤波、均值滤波、高斯滤波等。</p><p><strong>高斯滤波是一种线性平滑滤波，适用于消除高斯噪声。</strong>所以在讲高斯滤波之前，先解释一下什么是高斯噪声？</p><p><strong>1 高斯噪声</strong></p><p>首先，<strong>噪声</strong>在图像当中常表现为一引起较强视觉效果的孤立像素点或像素块。简单来说，噪声的出现会给图像带来干扰，让图像变得不清楚。<br><strong>高斯噪声</strong>就是它的概率密度函数服从高斯分布（即正态分布）的一类噪声。如果一个噪声，它的幅度分布服从高斯分布，而它的功率谱密度又是均匀分布的，则称它为高斯白噪声。高斯白噪声的二阶矩不相关，一阶矩为常数，是指先后信号在时间上的相关性。</p><p><strong>高斯滤波器是根据高斯函数的形状来选择权值的线性平滑滤波器</strong><br> 所以接下来再讲解一下高斯函数和高斯核。</p><p><strong>2 高斯函数</strong></p><p><img src="/2022/07/19/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/DLIB-0024.png"></p><p>注：σ的大小决定了高斯函数的宽度。</p><p><strong>3 高斯核</strong></p><p>理论上，高斯分布在所有定义域上都有非负值，这就需要一个无限大的卷积核。实际上，仅需要取均值周围3倍标准差内的值，以外部份直接去掉即可。<br> <strong>高斯滤波的重要两步就是先找到高斯模板然后再进行卷积</strong>，模板（mask在查阅中有的地方也称作掩膜或者是高斯核）。所以这个时候需要知道它怎么来？又怎么用？<br> 举个栗子：<br> 假定中心点的坐标是（0,0），那么取距离它最近的8个点坐标，为了计算，需要设定σ的值。假定σ&#x3D;1.5，则模糊半径为1的高斯模板就算如下</p><p><img src="/2022/07/19/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/DLIB-0025.png"></p><p> 这个时候我们我们还要确保这九个点加起来为1（这个是高斯模板的特性），这9个点的权重总和等于0.4787147，因此上面9个值还要分别除以0.4787147，得到最终的高斯模板。</p><p><img src="/2022/07/19/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/DLIB-0026.png"></p><p><strong>4 高斯滤波计算</strong></p><p>有了高斯模板，那么高斯滤波的计算便顺风顺水了。<br>举个栗子：假设现有9个像素点，灰度值（0-255）的高斯滤波计算如下：</p><p><img src="/2022/07/19/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/DLIB-0027.png"></p><p>参考来源：（<a href="https://blog.csdn.net/nima1994/article/details/79776802%EF%BC%89">https://blog.csdn.net/nima1994/article/details/79776802）</a></p><p>将这9个值加起来，就是中心点的高斯滤波的值。<br> 对所有点重复这个过程，就得到了高斯模糊后的图像。</p><p><strong>5 高斯滤波步骤</strong></p><p>综上可以总结一下步骤：</p><blockquote><p>（1）移动相关核的中心元素，使它位于输入图像待处理像素的正上方<br> （2）将输入图像的像素值作为权重，乘以相关核<br> （3）将上面各步得到的结果相加做为输出<br> <strong>简单来说就是根据高斯分布得到高斯模板然后做卷积相加的一个过程。</strong></p></blockquote><p><strong>参考资料</strong></p><ul><li><a href="https://www.jianshu.com/p/73e6ccbd8f3f">简单易懂的高斯滤波</a></li><li><a href="https://www.cnblogs.com/qiqibaby/p/5289977.html">图像滤波之高斯滤波介绍</a></li></ul><h2 id="腐蚀和膨胀"><a href="#腐蚀和膨胀" class="headerlink" title="腐蚀和膨胀"></a>腐蚀和膨胀</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="开运算和闭运算"><a href="#开运算和闭运算" class="headerlink" title="开运算和闭运算"></a>开运算和闭运算</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="如何求一张图片的均值？"><a href="#如何求一张图片的均值？" class="headerlink" title="如何求一张图片的均值？"></a>如何求一张图片的均值？</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="线性插值"><a href="#线性插值" class="headerlink" title="线性插值"></a>线性插值</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="双线性插值"><a href="#双线性插值" class="headerlink" title="双线性插值"></a>双线性插值</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="透视变换"><a href="#透视变换" class="headerlink" title="透视变换"></a>透视变换</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="常见的边缘检测算子"><a href="#常见的边缘检测算子" class="headerlink" title="常见的边缘检测算子"></a>常见的边缘检测算子</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Sobel-算法"><a href="#Sobel-算法" class="headerlink" title="Sobel 算法"></a>Sobel 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Canny-算法"><a href="#Canny-算法" class="headerlink" title="Canny 算法"></a>Canny 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Hough-变换原理（直线和圆检测）"><a href="#Hough-变换原理（直线和圆检测）" class="headerlink" title="Hough 变换原理（直线和圆检测）"></a>Hough 变换原理（直线和圆检测）</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="找轮廓（findCountours）"><a href="#找轮廓（findCountours）" class="headerlink" title="找轮廓（findCountours）"></a>找轮廓（findCountours）</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="单应性（homography）原理"><a href="#单应性（homography）原理" class="headerlink" title="单应性（homography）原理"></a>单应性（homography）原理</h2><p>TODO</p><h2 id="二维高斯滤波能否分解成一维操作"><a href="#二维高斯滤波能否分解成一维操作" class="headerlink" title="二维高斯滤波能否分解成一维操作"></a>二维高斯滤波能否分解成一维操作</h2><p>答：可以分解。</p><p>二维高斯滤波分解为两次一维高斯滤波，高斯二维公式可以推导为X轴与Y轴上的一维高斯公式。</p><p>即使用一维高斯核先对图像逐行滤波，再对中间结果逐列滤波。</p><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/qq_36359022/article/details/80188873">快速高斯滤波、高斯模糊、高斯平滑(二维卷积分步为一维卷积)</a></li></ul><h2 id="图像去噪算法"><a href="#图像去噪算法" class="headerlink" title="图像去噪算法"></a>图像去噪算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="HOG-算法"><a href="#HOG-算法" class="headerlink" title="HOG 算法"></a>HOG 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="高斯滤波-1"><a href="#高斯滤波-1" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="均值滤波"><a href="#均值滤波" class="headerlink" title="均值滤波"></a>均值滤波</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="中值滤波"><a href="#中值滤波" class="headerlink" title="中值滤波"></a>中值滤波</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="双边滤波"><a href="#双边滤波" class="headerlink" title="双边滤波"></a>双边滤波</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="图像中的低频信息和高频信息"><a href="#图像中的低频信息和高频信息" class="headerlink" title="图像中的低频信息和高频信息"></a>图像中的低频信息和高频信息</h2><p>图像频率：图像中灰度变化剧烈程度的指标</p><ul><li>低频信息（低频分量）表示图像中灰度值变化缓慢的区域，对应着图像中大块平坦的区域。</li><li>高频信息（高频分量）表示图像中灰度值变化剧烈的区域，对应着图像的边缘（轮廓）、噪声以及细节部分。</li></ul><p>低频分量：主要对整幅图像强度的综合度量</p><p>高频分量：主要对图像边缘和轮廓的度量</p><p>从傅里叶变换的角度，将图像从灰度分布转化为频率分布。</p><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/Chaolei3/article/details/79443520">理解图像中的低频分量和高频分量</a></li></ul><h2 id="引导滤波"><a href="#引导滤波" class="headerlink" title="引导滤波"></a>引导滤波</h2><p><strong>参考资料</strong></p><ul><li><a href="https://blog.csdn.net/sinat_36264666/article/details/77990790">【拜小白opencv】33-平滑处理6——引导滤波&#x2F;导向滤波（Guided Filter）</a></li></ul><h2 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="相机标定方法与流程"><a href="#相机标定方法与流程" class="headerlink" title="相机标定方法与流程"></a>相机标定方法与流程</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="分水岭算法"><a href="#分水岭算法" class="headerlink" title="分水岭算法"></a>分水岭算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="RANSAC-算法"><a href="#RANSAC-算法" class="headerlink" title="RANSAC 算法"></a>RANSAC 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="Bundle-Adjustment（BA）算法"><a href="#Bundle-Adjustment（BA）算法" class="headerlink" title="Bundle Adjustment（BA）算法"></a>Bundle Adjustment（BA）算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="L-M-算法"><a href="#L-M-算法" class="headerlink" title="L-M 算法"></a>L-M 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="SIFT-算法"><a href="#SIFT-算法" class="headerlink" title="SIFT 算法"></a>SIFT 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="SIFT-特征为什么能实现尺度不变性？"><a href="#SIFT-特征为什么能实现尺度不变性？" class="headerlink" title="SIFT 特征为什么能实现尺度不变性？"></a>SIFT 特征为什么能实现尺度不变性？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h3 id="SIFT特征是如何保持旋转不变性的？"><a href="#SIFT特征是如何保持旋转不变性的？" class="headerlink" title="SIFT特征是如何保持旋转不变性的？"></a>SIFT特征是如何保持旋转不变性的？</h3><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="SURF-算法"><a href="#SURF-算法" class="headerlink" title="SURF 算法"></a>SURF 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="ORB-算法"><a href="#ORB-算法" class="headerlink" title="ORB 算法"></a>ORB 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="LSD-算法"><a href="#LSD-算法" class="headerlink" title="LSD 算法"></a>LSD 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="LBP-算法"><a href="#LBP-算法" class="headerlink" title="LBP 算法"></a>LBP 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="KCF-算法"><a href="#KCF-算法" class="headerlink" title="KCF 算法"></a>KCF 算法</h2><ul><li><input disabled="" type="checkbox"> TODO</li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2>]]></content>
    
    
    <categories>
      
      <category>图像</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
